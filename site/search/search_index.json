{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"tmt","text":"<p>Welcome to the Test Management Tool documentation!</p> <p>The tmt python module and command line tool implement the specification which allows to store all test metadata directly within a git repository. It provides an elegant and comfortable way to manage tests and safely execute them across different environments.</p> <p>Check the Overview to get a high-level summary of available functionality, follow our guide which will help you with the first steps and teach you how to efficiently use the tool, check out the stories which motivated the effort, consult the specification to get detailed information about supported features, get inspired by many examples demonstrating the usage on real-life scenarios.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Guide</li> <li>Specification</li> <li>Plugins</li> <li>Examples</li> <li>Stories</li> <li>Questions</li> <li>Contribute</li> <li>Code</li> <li>Releases</li> </ul>"},{"location":"guide/","title":"Guide","text":"<p>This guide will show you the way through the dense forest of available <code>tmt</code> features, commands and options. But don't be afraid, we will start slowly, with the simple examples first. And then, when your eyes get accustomed to the shadow of omni-present metadata trees, we will slowly dive deeper and deeper so that you don't miss any essential functionality which could make your life smarter, brighter and more joyful. Let's go, follow me...</p>"},{"location":"guide/#the-first-steps","title":"The First Steps","text":"<p>Installing the main package with the core functionality is quite straightforward. No worry, the <code>/stories/install/minimal</code> package has just a few dependencies:</p> <pre><code>sudo dnf install -y tmt\n</code></pre> <p>Enabling a simple smoke test in the continuous integration should be a joy. Just a couple of concise commands, assuming you are in your project git repository:</p> <pre><code>tmt init --template mini\nvim plans/example.fmf\n</code></pre> <p>Open the example plan in your favorite editor and adjust the smoke test script as needed. Your very first plan can look like this:</p> <pre><code>summary: Basic smoke test\nexecute:\n    script: foo --version\n</code></pre> <p>Now you're ready to create a new pull request to check out how it's working. During push, remote usually shows a direct link to the page with a Create button, so now it's only two clicks away:</p> <pre><code>git add .\ngit checkout -b smoke-test\ngit commit -m \"Enable a simple smoke test\"\ngit push origin -u smoke-test\n</code></pre> <p>But perhaps, you are a little bit impatient and would like to see the results faster. Sure, let's try the smoke test here and now, directly on your localhost:</p> <pre><code>tmt --feeling-safe run --all provision --how local\n</code></pre> <p>Note that the extra <code>--feeling-safe</code> option is needed for the <code>/plugins/provision/local</code> provision plugin as it can be dangerous to execute unknown code directly on your system. If you're afraid that the test could break your machine or just want to keep your environment clean, run it in a container instead:</p> <pre><code>sudo dnf install -y tmt+provision-container\ntmt run -a provision -h container\n</code></pre> <p>Or even in a full virtual machine if the container environment is not enough. We'll use the <code>libvirt</code> to start a new virtual machine on your localhost. Be ready for a bit more dependencies here:</p> <pre><code>sudo dnf install -y tmt+provision-virtual\ntmt run -a provision -h virtual\n</code></pre> <p>Don't care about the disk space? Simply install <code>tmt+all</code> and you'll get <code>/stories/install/all</code> available functionality at hand. Check the help to list all supported provision methods:</p> <pre><code>sudo dnf install tmt+all\ntmt run provision --help\n</code></pre> <p>Now when you've met your <code>--help</code> friend you know everything you need to get around without getting lost in the forest of available options:</p> <pre><code>tmt --help\ntmt run --help\ntmt run provision --help\ntmt run provision --how container --help\n</code></pre> <p>Go on and explore. Don't be shy and ask, <code>--help</code> is eager to answer all your questions ;-)</p>"},{"location":"guide/#under-the-hood","title":"Under The Hood","text":"<p>Now let's have a brief look under the hood. For storing all config data we're using the Flexible Metadata Format. In short, it is a <code>yaml</code> format extended with a couple of nice features like <code>inheritance</code> or <code>elasticity</code> which help to maintain even large data efficiently without unnecessary duplication.</p>"},{"location":"guide/#trees","title":"Trees","text":"<p>The data are organized into trees. Similarly as with <code>git</code>, there is a special <code>.fmf</code> directory which marks the root of the fmf metadata tree. Use the <code>init</code> command to initialize it:</p> <pre><code>tmt init\n</code></pre> <p>Do not forget to include this special <code>.fmf</code> directory in your commits, it is essential for building the fmf tree structure which is created from all <code>*.fmf</code> files discovered under the fmf root.</p>"},{"location":"guide/#plans","title":"Plans","text":"<p>As we've seen above, in order to enable testing the following plan is just enough:</p> <pre><code>execute:\n    script: foo --version\n</code></pre> <p>Store these two lines in a <code>*.fmf</code> file and that's it. Name and location of the file is completely up to you, plans are recognized by the <code>execute</code> key which is required. Once the newly created plan is submitted to the CI system test script will be executed.</p> <p>By the way, there are several basic templates available which can be applied already during the <code>init</code> by using the <code>--template</code> option or the short version <code>-t</code>. The minimal template, which includes just a simple plan skeleton, is the fastest way to get started:</p> <pre><code>tmt init -t mini\n</code></pre> <p><code>/spec/plans</code> are used to enable testing and group relevant tests together. They describe how to <code>/spec/plans/discover</code> tests for execution, how to <code>/spec/plans/provision</code> the environment, how to <code>/spec/plans/prepare</code> it for testing, how to <code>/spec/plans/execute</code> tests, <code>/spec/plans/report</code> results and finally how to <code>/spec/plans/finish</code> the test job.</p> <p>Here's an example of a slightly more complex plan which changes the default provision method to container to speed up the testing process and ensures that an additional package is installed before the testing starts:</p> <pre><code>provision:\n    how: container\n    image: fedora:33\nprepare:\n    how: install\n    package: wget\nexecute:\n    how: tmt\n    script: wget http://example.org/\n</code></pre> <p>Note that each of the steps above uses the <code>how</code> keyword to choose the desired method which should be applied. Steps can provide multiple implementations which enables you to choose the best one for your use case. For example to prepare the guest it's possible to use the <code>/plugins/prepare/install</code> method for simple package installations, <code>/plugins/prepare/ansible</code> for more complex system setup or <code>/plugins/prepare/shell</code> for arbitrary shell commands.</p>"},{"location":"guide/#tests","title":"Tests","text":"<p>Very often testing is much more complex than running just a single shell script. There might be many scenarios covered by individual scripts. For these cases the <code>discover</code> step can be instructed to explore available tests from fmf metadata as well. The plan will look like this:</p> <pre><code>discover:\n    how: fmf\nexecute:\n    how: tmt\n</code></pre> <p><code>/spec/tests</code>, identified by the required key <code>test</code>, define attributes which are closely related to individual test cases such as the <code>/spec/tests/test</code> script, <code>/spec/tests/framework</code>, directory <code>/spec/tests/path</code> where the test should be executed, maximum test <code>/spec/tests/duration</code> or packages <code>required&lt;/spec/tests/require&gt;</code> to run the test. Here's an example of test metadata:</p> <pre><code>summary: Fetch an example web page\ntest: wget http://example.org/\nrequire: wget\nduration: 1m\n</code></pre> <p>Instead of writing the plan and test metadata manually, you might want to simply apply the <code>base</code> template which contains the plan mentioned above together with a test example including both test metadata and test script skeleton for inspiration:</p> <pre><code>tmt init --template base\n</code></pre> <p>Similar to plans, it is possible to choose an arbitrary name for the test. Just make sure the <code>test</code> key is defined. However, to organize the metadata efficiently it is recommended to keep tests and plans under separate folders, e.g. <code>tests</code> and <code>plans</code>. This will also allow you to use <code>inheritance</code> to prevent unnecessary data duplication.</p>"},{"location":"guide/#stories","title":"Stories","text":"<p>It's always good to start with a \"why\". Or, even better, with a story which can describe more context behind the motivation. <code>/spec/stories</code> can be used to track implementation, test and documentation coverage for individual features or requirements. Thanks to this you can track everything in one place, including the project implementation progress. Stories are identified by the <code>story</code> attribute which every story has to define or inherit.</p> <p>An example story can look like this:</p> <pre><code>story:\n    As a user I want to see more detailed information for\n    particular command.\nexample:\n  - tmt tests show -v\n  - tmt tests show -vvv\n  - tmt tests show --verbose\n</code></pre> <p>In order to start experimenting with the complete set of examples covering all metadata levels, use the <code>full</code> template which creates a test, a plan and a story:</p> <pre><code>tmt init -t full\n</code></pre>"},{"location":"guide/#core","title":"Core","text":"<p>Finally, there are certain metadata keys which can be used across all levels. <code>/spec/core</code> attributes cover general metadata such as <code>/spec/core/summary</code> or <code>/spec/core/description</code> for describing the content, the <code>/spec/core/enabled</code> attribute for disabling and enabling tests, plans and stories and the <code>/spec/core/link</code> key which can be used for tracking relations between objects.</p> <p>Here's how the story above could be extended with the core attributes <code>description</code> and <code>link</code>:</p> <pre><code>description:\n    Different verbose levels can be enabled by using the\n    option several times.\nlink:\n  - implemented-by: /tmt/cli.py\n  - documented-by: /tmt/cli.py\n  - verified-by: /tests/core/dry\n</code></pre> <p>Last but not least, the core attribute <code>/spec/core/adjust</code> provides a flexible way to adjust metadata based on the <code>/spec/context</code>. But this is rather a large topic, so let's keep it for another time.</p>"},{"location":"guide/#organize-data","title":"Organize Data","text":"<p>In the previous chapter we've learned what <code>/spec/tests</code>, <code>/spec/plans</code> and <code>/spec/stories</code> are used for. Now the time has come to learn how to efficiently organize them in your repository. First we'll describe how to easily <code>create</code> new tests, plans and stories, how to use <code>lint</code> to verify that all metadata have correct syntax. Finally, we'll dive into <code>inheritance</code> and <code>elasticity</code> which can substantially help you to minimize data duplication.</p>"},{"location":"guide/#create","title":"Create","text":"<p>When working on the test coverage, one of the most common actions is creating new tests. Use <code>tmt test create</code> to simply create a new test based on a template:</p> <pre><code>$ tmt test create /tests/smoke\nTemplate (shell or beakerlib): shell\nDirectory '/home/psss/git/tmt/tests/smoke' created.\nTest metadata '/home/psss/git/tmt/tests/smoke/main.fmf' created.\nTest script '/home/psss/git/tmt/tests/smoke/test.sh' created.\n</code></pre> <p>As for now there are two test templates available, <code>shell</code> for simple scripts written in shell and <code>beakerlib</code> with a basic skeleton demonstrating essential functions of this shell-level testing framework. If you want to be faster, specify the desired template directly on the command line using <code>--template</code> or <code>-t</code>:</p> <pre><code>$ tmt test create --template shell /tests/smoke\n$ tmt test create -t beakerlib /tests/smoke\n</code></pre> <p>To create multiple tests at once, you can specify multiple names at the same time:</p> <pre><code>$ tmt tests create -t shell /tests/core /tests/base /tests/full\n</code></pre> <p>If you'd like to link relevant issues when creating a test, specify the links via <code>[RELATION:]TARGET</code> on the command line using <code>--link</code>:</p> <pre><code>$ tmt test create /tests/smoke --link foo\n$ tmt test create /tests/smoke --link foo --link verifies:https://foo.com/a/b/c\n</code></pre> <p>In a similar way, the <code>tmt plan create</code> command can be used to create a new plan with templates:</p> <pre><code>tmt plan create --template mini /plans/smoke\ntmt plan create -t full /plans/features\n</code></pre> <p>When creating many plans, for example when migrating the whole test coverage from a different tooling, it might be handy to override default template content directly from the command line. For this use individual step options such as <code>--discover</code> and provide desired data in the <code>yaml</code> format:</p> <pre><code>tmt plan create /plans/custom --template mini \\\n    --discover '{how: \"fmf\", name: \"internal\", url: \"https://internal/repo\"}' \\\n    --discover '{how: \"fmf\", name: \"external\", url: \"https://external/repo\"}'\n</code></pre> <p>Now it will be no surprise for you that for creating a new story the <code>tmt story create</code> command can be used with the very same possibility to choose the right template:</p> <pre><code>tmt story create --template full /stories/usability\n</code></pre> <p>Sometimes you forget something, or just things may go wrong and you need another try. In such case add <code>-f</code> or <code>--force</code> to quickly overwrite existing files with the right content.</p>"},{"location":"guide/#custom-templates","title":"Custom Templates","text":"<p>If you create new tests often, you might want to create a custom template in order to get quickly started with a new test skeleton tailored exactly to your needs. The same applies for plans and stories.</p> <p>Templates can be defined inside the config directory <code>TMT_CONFIG_DIR</code> under the <code>templates</code> subdirectory. If the config directory is not explicitly set, the default config directory <code>~/.config/tmt/templates</code> is used. Use the following directory structure when creating custom templates:</p> <ul> <li><code>~/.config/tmt/templates/story</code> for story metadata</li> <li><code>~/.config/tmt/templates/plan</code> for plan metadata</li> <li><code>~/.config/tmt/templates/test</code> for test metadata</li> <li><code>~/.config/tmt/templates/script</code> for test scripts</li> </ul> <p>We use Jinja for templates, so your template files must have the <code>.j2</code> file extension. You can also apply default Jinja filters to your templates.</p> <p>To use your custom templates, use the <code>--template</code> option with your template name. For example, if you have created a <code>feature.j2</code> story template:</p> <pre><code>tmt stories create --template feature /stories/download\ntmt stories create -t feature /stories/upload\n</code></pre> <p>In the very same way you can create your custom templates for new plans and tests. Tests are a bit special as they also need a script template in addition to the test metadata. By default, both test metadata and test script use the same template name, so for a <code>web</code> template the command line would look like this:</p> <pre><code>tmt tests create --template web /tests/server\ntmt tests create -t web /tests/client\n</code></pre> <p>If you want to use a different template for the test script, use the <code>--script</code> option. For example, it might be useful to have a separate <code>multihost.j2</code> template for complex scenarios where multiple guests are involved:</p> <pre><code>tmt tests create --template web --script multihost /tests/download\ntmt tests create -t web -s multihost /tests/upload\n</code></pre> <p>Sometimes it might be useful to maintain common templates on a single place and share them across the team. To use a remote template just provide the URL to the <code>--template</code> option. If you want to use a custom remote template for tests, you need to use both <code>--template</code> and <code>--script</code> options. For example:</p> <pre><code>tmt tests create \\\n    --template https://team.repo/web.j2 \\\n    --script https://team.repo/multihost.j2 \\\n    /tests/download\n</code></pre>"},{"location":"guide/#lint","title":"Lint","text":"<p>It is easy to introduce a syntax error to one of the fmf files and make the whole tree broken. The <code>tmt lint</code> command performs a set of <code>lint-checks</code> which compare the stored metadata against the specification and reports anything suspicious:</p> <pre><code>$ tmt lint /tests/execute/basic\n/tests/execute/basic\npass C000 fmf node passes schema validation\nwarn C001 summary should not exceed 50 characters\npass T001 correct keys are used\npass T002 test script is defined\npass T003 directory path is absolute\npass T004 test path '/home/psss/git/tmt/tests/execute/basic' does exist\nskip T005 legacy relevancy not detected\nskip T006 legacy 'coverage' field not detected\nskip T007 not a manual test\nskip T008 not a manual test\npass T009 all requirements have type field\n</code></pre> <p>There is a broad variety of options to control what checks are applied on tests, plans and stories:</p> <pre><code># Lint everything, everywhere\ntmt lint\n\n# Lint just selected plans\ntmt lint /plans/features\ntmt plans lint /plans/features\n\n# Change the set of checks applied - enable some, disable others\ntmt lint --enable-check T001 --disable-check C002\n</code></pre> <p>See the <code>lint-checks</code> page for the list of available checks or use the <code>--list-checks</code> option. For the full list of options, see <code>tmt lint --help</code>.</p> <pre><code># All checks tmt has for tests, plans and stories\ntmt lint --list-checks\n\n# All checks tmt has for tests\ntmt tests lint --list-checks\n</code></pre> <p>You should run <code>tmt lint</code> before pushing changes, ideally even before you commit your changes. You can set up pre-commit to do it for you. Add to your repository's <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n- repo: https://github.com/teemtee/tmt.git\n  rev: 1.29.0\n  hooks:\n  - id: tmt-lint\n</code></pre> <p>This will run <code>tmt lint --source</code> for all modified fmf files. There are hooks to just check tests <code>tmt-tests-lint</code>, plans <code>tmt-plans-lint</code> or stories <code>tmt-stories-lint</code> explicitly. From time to time you might want to run <code>pre-commit autoupdate</code> to refresh config to the latest version.</p>"},{"location":"guide/#inheritance","title":"Inheritance","text":"<p>The <code>fmf</code> format provides a nice flexibility regarding the file location. Tests, plans and stories can be placed arbitrarily in the repo. You can pick the location which best fits your project. However, it makes sense to group similar or closely related objects together. A thoughtful structure will not only make it easier to find things and more quickly understand the content, it also allows to prevent duplication of common metadata which would be otherwise repeated many times.</p> <p>Let's have a look at some tangible example. We create separate directories for tests and plans. Under each of them there is an additional level to group related tests or plans together:</p> <pre><code>\u251c\u2500\u2500 plans\n\u2502   \u251c\u2500\u2500 features\n\u2502   \u251c\u2500\u2500 install\n\u2502   \u251c\u2500\u2500 integration\n\u2502   \u251c\u2500\u2500 provision\n\u2502   \u251c\u2500\u2500 remote\n\u2502   \u2514\u2500\u2500 sanity\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 core\n    \u251c\u2500\u2500 full\n    \u251c\u2500\u2500 init\n    \u251c\u2500\u2500 lint\n    \u251c\u2500\u2500 login\n    \u251c\u2500\u2500 run\n    \u251c\u2500\u2500 steps\n    \u2514\u2500\u2500 unit\n</code></pre> <p>Vast majority of the tests is executed using a <code>./test.sh</code> script which is written in <code>beakerlib</code> framework and almost all tests require <code>tmt</code> package to be installed on the system. So the following test metadata are common:</p> <pre><code>test: ./test.sh\nframework: beakerlib\nrequire: [tmt]\n</code></pre> <p>Instead of repeating this information again and again for each test we place a <code>main.fmf</code> file at the top of the <code>tests</code> tree:</p> <pre><code>tests\n\u251c\u2500\u2500 main.fmf\n\u251c\u2500\u2500 core\n\u251c\u2500\u2500 full\n\u251c\u2500\u2500 init\n...\n</code></pre>"},{"location":"guide/#virtual-tests","title":"Virtual Tests","text":"<p>Sometimes it might be useful to reuse test code by providing different parameter or an environment variable to the same test script. In such cases inheritance allows to easily share the common setup:</p> <pre><code>test: ./test.sh\nrequire: curl\n\n/fast:\n    summary: Quick smoke test\n    tier: 1\n    duration: 1m\n    environment:\n        MODE: fast\n\n/full:\n    summary: Full test set\n    tier: 2\n    duration: 10m\n    environment:\n        MODE: full\n</code></pre> <p>In the example above, two tests are defined, both executing the same <code>test.sh</code> script but providing a different environment variable which instructs the test to perform a different set of actions.</p>"},{"location":"guide/#inherit-plans","title":"Inherit Plans","text":"<p>If several plans share similar content it is possible to use inheritance to prevent unnecessary duplication of the data:</p> <pre><code>discover:\n    how: fmf\n    url: https://github.com/teemtee/tmt\nprepare:\n    how: ansible\n    playbook: ansible/packages.yml\nexecute:\n    how: tmt\n\n/basic:\n    summary: Quick set of basic functionality tests\n    discover+:\n        filter: tier:1\n\n/features:\n    summary: Detailed tests for individual features\n    discover+:\n        filter: tier:2\n</code></pre> <p>Note that a <code>+</code> sign should be used if you want to extend the parent data instead of replacing them. See the fmf features documentation for a detailed description of the hierarchy, inheritance and merging attributes.</p>"},{"location":"guide/#elasticity","title":"Elasticity","text":"<p>Depending on the size of your project you can choose to store all configuration in just a single file or rather use multiple files to store each test, plan or story separately. For example, you can combine both the plan and tests like this:</p> <pre><code>/plan:\n    summary:\n        Verify that plugins are working\n    discover:\n        how: fmf\n    provision:\n        how: container\n    prepare:\n        how: install\n        package: did\n    execute:\n        how: tmt\n\n/tests:\n    /bugzilla:\n        test: did --bugzilla\n    /github:\n        test: did --github\n    /koji:\n        test: did --koji\n</code></pre> <p>Or you can put the plan in one file and tests into another one:</p> <pre><code># plan.fmf\nsummary:\n    Verify that plugins are working\ndiscover:\n    how: fmf\nprovision:\n    how: container\nprepare:\n    how: install\n    package: did\nexecute:\n    how: tmt\n</code></pre> <pre><code># tests.fmf\n/bugzilla:\n    test: did --bugzilla\n/github:\n    test: did --github\n/koji:\n    test: did --koji\n</code></pre> <p>Or even each test can be defined in a separate file:</p> <pre><code># tests/bugzilla.fmf\ntest: did --bugzilla\n</code></pre> <pre><code># tests/github.fmf\ntest: did --github\n</code></pre> <pre><code># tests/koji.fmf\ntest: did --koji\n</code></pre> <p>You can start with a single file when the project is still small. When some branch of the config grows too much, you can easily extract the large content into a new separate file.</p> <p>The <code>tree</code> built from the scattered files stay identical if the same name is used for the file or directory containing the data. For example, the <code>/tests/koji</code> test from the top <code>main.fmf</code> config could be moved to any of the following locations without any change to the resulting <code>fmf</code> tree:</p> <pre><code># tests.fmf\n/koji:\n    test: did --koji\n</code></pre> <pre><code># tests/main.fmf\n/koji:\n    test: did --koji\n</code></pre> <pre><code># tests/koji.fmf\ntest: did --koji\n</code></pre> <pre><code># tests/koji/main.fmf\ntest: did --koji\n</code></pre> <p>This gives you a nice flexibility to extend the metadata when and where needed as your project organically grows.</p>"},{"location":"guide/#link-issues","title":"Link Issues","text":"<p>You can link issues to the test or plan that covers it. This can be done either directly during creation of a new test or plan, or later using the <code>tmt link</code> command:</p> <pre><code>tmt link --link verifies:https://issues.redhat.com/browse/YOUR-ISSUE tests/core/smoke\n</code></pre> <p>In order to enable this feature, create a configuration file <code>.config/tmt/link.fmf</code> and define an <code>issue-tracker</code> section there. Once the configuration is present, it enables the linking on its own, no further action is needed. The section should have the following format:</p> <pre><code>issue-tracker:\n  - type: jira\n    url: https://issues.redhat.com\n    tmt-web-url: https://tmt.testing-farm.io/\n    token: &lt;YOUR_PERSONAL_JIRA_TOKEN&gt;\n</code></pre> <p>The <code>type</code> key specifies the type of the issue tracking service you want to link to (so far only Jira is supported). The <code>url</code> is the URL of said service. The <code>tmt-web-url</code> is the URL of the service that presents tmt metadata in a human-readable form. The <code>token</code> is a personal token that is used to authenticate the user. How to obtain this token is described here (please note that this can vary if you use custom Jira instance).</p> <p>Once the link is attached to the respective Jira, clicking on it will take you to the tmt web service with test or plan details. Here's an example test and plan. It is also possible to reference both test and plan in a single link.</p>"},{"location":"guide/#share-tests","title":"Share Tests","text":"<p>Tests can be shared across different repositories, significantly enhancing efficiency, reducing data duplication, and improving maintainability in the testing workflow.</p> <p>tmt allows references to external repositories directly within the <code>discover</code> step of the plan. By specifying the URL of a remote git repository, tmt can fetch and integrate tests defined within that repository.</p> <pre><code>discover:\n  # Fetch common tests from a shared repository\n  - name: core-tests\n    how: fmf\n    url: https://github.com/my-org/core-tests.git\n\n  # Discover tests located within this project's own repository\n  - name: project-specific\n    how: fmf\n</code></pre>"},{"location":"guide/#adjust-metadata","title":"Adjust Metadata","text":"<p>Sometimes metadata needs to be adjusted based on the context. For example, the user might want to enable a test only for a specific architecture or skip a plan when running in a container. The core attribute <code>/spec/core/adjust</code> provides a flexible way to achieve this. It allows to modify various attributes of the tests, plans, or stories depending on the current <code>/spec/context</code>.</p> <p>This feature helps with creating adaptable and reusable metadata, reducing the need for multiple versions of similar configurations. Rules can be defined to conditionally change attributes like <code>enabled</code>, <code>environment</code>, <code>require</code> or even the test script itself.</p> <pre><code># Disable a test for older distros\nenabled: true\nadjust:\n    enabled: false\n    when: distro &lt; fedora-33\n    because: the feature was added in Fedora 33\n</code></pre>"},{"location":"guide/#anchors-and-aliases","title":"Anchors and Aliases","text":"<p>When you need to specify the same variable multiple times in a single file, the <code>yaml</code> feature called Anchors and Aliases can come handy. You can define an anchor before an item to save it for future usage with an <code>alias</code>.</p> <pre><code># Example of an anchor:\ndiscover:\n    how: fmf\n    test: &amp;stable\n      - first\n      - second\n\n# Which you can then use later in the same file as an alias:\ndiscover:\n    how: fmf\n    exclude: *stable\n</code></pre>"},{"location":"guide/#git-metadata","title":"Git Metadata","text":"<p>In order to save space and bandwidth, the <code>.git</code> directory is not synced to the guest by default. If you want to have it available, use the respective <code>discover</code> step option to have it copied to the guest.</p> <pre><code>discover:\n  - name: Keep git for fmf discovery\n    how: fmf\n    sync-repo: true\n</code></pre> <pre><code>discover:\n  - name: Keep git for shell discovery\n    how: shell\n    keep-git-metadata: true\n</code></pre> <p>Note</p> <p>Git metadata cannot be copied for the <code>prepare</code> or <code>finish</code> steps yet.</p>"},{"location":"guide/#conditional-step-configuration","title":"Conditional step configuration","text":"<p>Sometimes, the plan is expected to cover a broad set of environments; however, some step configurations may not be applicable everywhere. While <code>/spec/core/adjust</code> can be used to construct the plan in this way, it soon becomes difficult to read.</p> <p>Using the <code>when</code> key makes it easier to restrict a step configuration to run only if any of the specified rules matches. The syntax is the same as in <code>adjust</code> and <code>/spec/context</code>.</p> <pre><code>prepare:\n  - name: Prepare config to run only on Fedora\n    when: distro == fedora\n    how: shell\n    script: ./fedora_specific.sh\n  - name: Runs always\n    how: shell\n    script: ./setup.sh\n  - name: More rules in 'when' key\n    how: shell\n    script: ./something.sh\n    when:\n    - arch != x86_64\n    - initiator == human &amp;&amp; distro == fedora\n</code></pre>"},{"location":"guide/#multihost-testing","title":"Multihost Testing","text":"<p>Support for basic server/client scenarios is now available.</p> <p>The <code>prepare</code>, <code>execute</code>, and <code>finish</code> steps are able to run a given task (test, preparation script, ansible playbook, etc.) on several guests at once. Tasks are assigned to provisioned guests by matching the <code>where</code> key from <code>discover&lt;/spec/plans/discover/where&gt;</code>, <code>prepare&lt;/spec/plans/prepare/where&gt;</code> and <code>finish&lt;/spec/plans/finish/where&gt;</code> phases with corresponding guests by their <code>key and role keys&lt;/spec/plans/provision/multihost&gt;</code>. Essentially, plan author tells tmt on which guest(s) a test or script should run by listing guest name(s) or guest role(s).</p> <p>The granularity of the multihost scenario is on the step phase level. The user may define multiple <code>discover</code>, <code>prepare</code> and <code>finish</code> phases, and everything in them will start on given guests at the same time when the previous phase completes. The practical effect is, tmt does not manage synchronization on the test level:</p> <pre><code>discover:\n  - name: server-setup\n    how: fmf\n    test:\n      - /tests/A\n    where:\n      - server\n\n  - name: tests\n    how: fmf\n    test:\n      - /tests/B\n      - /tests/C\n    where:\n      - server\n      - client\n</code></pre> <p>In this example, first, everything from the <code>server-setup</code> phase would run on guests called <code>server</code>, while guests with the name or role <code>client</code> would remain idle. When this phase completes, tmt would move to the next one, and run everything in <code>tests</code> on <code>server</code> and <code>client</code> guests. The phase would be started at the same time, more or less, but tmt will not even try to synchronize the execution of each test from this phase. <code>/tests/B</code> may still be running on <code>server</code> when <code>/tests/C</code> is already completed on <code>client</code>.</p> <p>tmt exposes information about guests and roles to all three steps in the form of files tests and scripts can parse or import. See the <code>/spec/plans/guest-topology</code> for details. Information from these files can be then used to contact other guests, connect to their services, synchronization, etc.</p> <p>tmt fully supports one test being executed multiple times. This is especially visible in the format of results, see <code>/spec/results</code>. Every test is assigned a \"serial number\", if the same test appears in multiple discover phases, each instance would be given a different serial number. The serial number and the guest from which a result comes from are then saved for each test result.</p> <p>Note</p> <p>As a well-mannered project, tmt of course has a battery of tests to make sure the multihost support does not break down. The <code>/tests/multihost/complete</code> test may serve as an inspiration for your experiments.</p>"},{"location":"guide/#rerunning-failed-tests-of-previously-executed-runs","title":"Rerunning failed tests of previously executed runs","text":"<p>Executing failed tests again after fixing them is now possible with <code>tmt run --all --again tests --failed-only</code>.</p> <p>This is only possible when you have the run directory available and <code>--id</code> argument provided (or use <code>--last</code>) as it needs the data from execute step to select only failed test cases. After new execute step, tmt will again merge the results from the previous run with the new ones to keep all the data for full report.</p> <pre><code>$ tmt run\n# Some tests fail, some pass\n\n$ tmt run --last --again discover tests --failed-only\n# Discover tests to rerun\n\n$ tmt run --all --last --again tests --failed-only\n# Run all failed tests again\n</code></pre>"},{"location":"guide/#synchronization-libraries","title":"Synchronization Libraries","text":"<p>The test-level synchronization, as described above, is not implemented, and this is probably not going to change any time soon. For the test-level synchronization, please use dedicated libraries, e.g. one of the following:</p> <ul> <li><code>RHTS support</code> in Beaker <code>rhts-sync-block</code> and     <code>rhts-sync-set</code>,</li> <li><code>a beakerlib library</code> by Ondrej Moris, utilizes a shared     storage, two-hosts only,</li> <li><code>a rhts-like distributed version</code> by Karel Srot,</li> <li><code>a native beakerlib library</code> by Dalibor Pospisil, a     distributed version of Ondrej Moris's library, supporting any     number of hosts.</li> <li><code>redis server</code> by Jan Scotka, a simple key-value exchange     solution between machines. The primary purpose is data     transfer. It is not a library prepared for synchronization,     but it's possible to use it as well. See the example to learn     how to set up a redis server and use it.</li> </ul>"},{"location":"guide/#current-limits","title":"Current Limits","text":"<p>Note</p> <p>For the most up-to-date list of issues related to multihost, our Github can display all issues with the <code>multihost</code> label.</p> <ul> <li>interaction between guests provisioned by different plugins. Think     \"a server from <code>podman</code> plugin vs client from <code>virtual</code>\".     This is not yet supported, see this issue.</li> </ul>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#description","title":"Description","text":"<p>The <code>tmt</code> tool provides a user-friendly way to work with tests. You can comfortably create new tests, safely and easily run tests across different environments, review test results, debug test code and enable tests in the CI using a consistent and concise config.</p> <p>The python module and command-line tool implement the Metadata Specification which allows storing all needed test execution data directly within a git repository. Together with possibility to reference remote repositories it makes it easy to share test coverage across projects and distros.</p> <p>The Flexible Metadata Format <code>fmf</code> is used to store data in both human and machine readable way close to the source code. Thanks to inheritance and elasticity metadata are organized in the structure efficiently, preventing unnecessary duplication.</p>"},{"location":"overview/#specification","title":"Specification","text":"<p>There are several metadata levels defined by the specification:</p> <p>Core attributes such as <code>summary</code> or <code>description</code> which are common across all levels are defined by the special L0 metadata.</p> <p>Tests, or L1 metadata, define attributes which are closely related to individual test cases such as <code>test</code> script, <code>framework</code>, directory <code>path</code> where the test should be executed, maximum test <code>duration</code> or packages required to run the test.</p> <p>Plans, also called L2 metadata, are used to group relevant tests and enable them in the CI. They describe how to <code>discover</code> tests for execution, how to <code>provision</code> the environment, how to <code>prepare</code> it for testing, how to <code>execute</code> tests and <code>report</code> test results.</p> <p>Stories, which implement the L3 metadata, can be used to track implementation, test and documentation coverage for individual features or requirements. Thanks to this you can track everything in one place, including the project implementation progress.</p>"},{"location":"overview/#synopsis","title":"Synopsis","text":"<p>Command line usage is straightforward:</p> <pre><code>tmt command [options]\n</code></pre>"},{"location":"overview/#examples","title":"Examples","text":"<p>Let's see which tests, plans and stories are available:</p> <pre><code>tmt\n</code></pre> <p>Initialize the metadata tree in the current directory, optionally with example content based on templates:</p> <pre><code>tmt init\ntmt init --template base\n</code></pre> <p>Run all or selected steps for each plan:</p> <pre><code>tmt run\ntmt run discover\ntmt run prepare execute\n</code></pre> <p>See any failures from a previous run:</p> <pre><code>tmt run --last report -vvv\n</code></pre> <p>Show test output while running:</p> <pre><code>tmt run -vvv\n</code></pre> <p>List tests, show details, check against the specification:</p> <pre><code>tmt tests ls\ntmt tests show\ntmt tests lint\n</code></pre> <p>Create a new test, import test metadata from other formats:</p> <pre><code>tmt test create\ntmt test import\n</code></pre> <p>List plans, show details, check against the specification:</p> <pre><code>tmt plans ls\ntmt plans show\ntmt plans lint\n</code></pre> <p>List stories, check details, show coverage status:</p> <pre><code>tmt stories ls\ntmt stories show\ntmt stories coverage\n</code></pre> <p>Many commands support regular expression filtering and other specific options:</p> <pre><code>tmt stories ls cli\ntmt stories show create\ntmt stories coverage --implemented\n</code></pre> <p>Check help message of individual commands for the full list of available options.</p>"},{"location":"overview/#options","title":"Options","text":"<p>Here is the list of the most frequently used commands and options.</p>"},{"location":"overview/#run","title":"Run","text":"<p>The <code>run</code> command is used to execute test steps. By default all test steps are run. See the L2 Metadata specification for detailed description of individual steps. Here is a brief overview:</p> <p>discover :   Gather information about test cases to be executed.</p> <p>provision :   Provision an environment for testing or use localhost.</p> <p>prepare :   Prepare the environment for testing.</p> <p>execute :   Run tests using the specified executor.</p> <p>report :   Provide test results overview and send reports.</p> <p>finish :   Perform the finishing tasks and clean up provisioned guests.</p>"},{"location":"overview/#tests","title":"Tests","text":"<p>Manage tests (L1 metadata). Check available tests, inspect their metadata, gather old metadata from various sources and stored them in the new fmf format.</p> <p>ls :   List available tests. show :   Show test details. lint :   Check tests against the L1 metadata specification. create :   Create a new test based on given template. import :   Convert old test metadata into the new fmf format.</p>"},{"location":"overview/#plans","title":"Plans","text":"<p>Manage test plans (L2 metadata). Search for available plans. Explore detailed test step configuration.</p> <p>ls :   List available plans. show :   Show plan details. lint :   Check plans against the L2 metadata specification.</p>"},{"location":"overview/#stories","title":"Stories","text":"<p>Manage user stories. Check available user stories. Explore coverage (test, implementation, documentation).</p> <p>ls :   List available stories. show :   Show story details. coverage :   Show code, test and docs coverage for given stories. export :   Export selected stories into desired format.</p>"},{"location":"overview/#utils","title":"Utils","text":"<p>Various utility options.</p> <p>--root PATH :   Path to the metadata tree, current directory used by default.</p> <p>--verbose :   Print additional information.</p> <p>--debug :   Turn on debugging output.</p> <p>--log-topic NAME :   Enable logging for a specific topic, useful for debugging particular     areas. For example, to see logs related to policy processing,     you can use:</p> <pre><code>```bash\ntmt --log-topic policy test export --policy ../policies/test/environment.yaml\n```\n</code></pre> <p>Check help message of individual commands for the full list of available options.</p>"},{"location":"overview/#install","title":"Install","text":"<p>The main <code>tmt</code> package provides the core features with a minimal set of dependencies:</p> <pre><code>sudo dnf install tmt\n</code></pre> <p>In order to enable additional functionality, such as particular provision or report plugins, install the respective subpackage:</p> <pre><code>sudo dnf install tmt+test-convert\nsudo dnf install tmt+provision-container\nsudo dnf install tmt+provision-virtual\n</code></pre> <p>If you don't care about disk space and want to have all available features right at hand install everything:</p> <pre><code>sudo dnf install tmt+all\n</code></pre> <p>For CentOS and RHEL, first make sure that you have available the EPEL repository. You might also have to enable additional repositories:</p> <pre><code>sudo dnf config-manager --enable crb         # CentOS 9\nsudo dnf config-manager --enable rhel-CRB    # RHEL 9\nsudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\n\nsudo dnf install tmt\n</code></pre> <p>For plugins which cannot work outside of VPN and so live within its walls you need to enable the internal copr repository first. Then you can install either everything or only those you need:</p> <pre><code>sudo dnf install tmt-redhat-all\nsudo dnf install tmt-redhat-*\n</code></pre> <p>Do you like to check the released bits as soon as they are out? Enable the <code>stable</code> copr repository and install from there:</p> <pre><code>sudo dnf copr enable @teemtee/stable\n</code></pre> <p>Impatient to try the fresh features as soon as they are merged into the <code>main</code> branch? Enable the <code>latest</code> copr repository:</p> <pre><code>sudo dnf copr enable @teemtee/latest\n</code></pre> <p>Not sure, just want to try out how it works? Experiment safely and easily inside a container:</p> <pre><code>podman run -it --rm quay.io/teemtee/tmt bash\npodman run -it --rm quay.io/teemtee/tmt-all bash\n</code></pre>"},{"location":"overview/#pip-install","title":"pip install","text":"<p>When installing using <code>pip</code> you might need to install additional packages on your system:</p> <pre><code>sudo dnf install gcc redhat-rpm-config\nsudo dnf install {python3,libvirt,krb5,libpq}-devel\npip install --user tmt\n</code></pre> <p>On other distributions than Fedora or RHEL the package names might be different. For example on Ubuntu to install all packages to have provision plugins working:</p> <pre><code>sudo apt install libkrb5-dev pkg-config libvirt-dev genisoimage qemu-kvm libvirt-daemon-system\npip install --user \"tmt[provision]\"\n</code></pre> <p>Note: You can omit the <code>--user</code> flag if in a virtual environment.</p>"},{"location":"overview/#shell-completion","title":"Shell Completion","text":"<p>The rpm package includes a system wide script which enables the command line completion for <code>bash</code> so no additional config should be needed. If you use a different installation method or prefer another shell, see the instructions below.</p> <p>For Bash, add this to <code>~/.bashrc</code>:</p> <pre><code>eval \"$(_TMT_COMPLETE=source_bash tmt)\"\n</code></pre> <p>For Zsh, add this to <code>~/.zshrc</code>:</p> <pre><code>eval \"$(_TMT_COMPLETE=source_zsh tmt)\"\n</code></pre> <p>For Fish, add this to <code>~/.config/fish/completions/tmt.fish</code>:</p> <pre><code>eval (env _TMT_COMPLETE=source_fish tmt)\n</code></pre> <p>Open a new shell to enable completion. Or run the <code>eval</code> command directly in your current shell to enable it temporarily.</p> <p>This is however run every time you start a shell which can cause some delay. To speed it up, write the generated script to a file and then source it from your shell's configuration file. All of this can be achieved using <code>tmt setup completion</code> command. By default, it outputs the completion script to the terminal but it can also add it to your <code>~/.bashrc</code> or <code>~/.zshrc</code> using the <code>--install</code> option:</p> <pre><code>tmt setup completion {bash, zsh, fish} --install\n</code></pre>"},{"location":"overview/#exit-codes","title":"Exit Codes","text":"<p>The following exit codes are returned from <code>tmt run</code>. Note that you can use the <code>--quiet</code> option to completely disable output and only check for the exit code.</p> <p>0 :   At least one test passed, there was no fail, warn or error. 1 :   There was a fail or warn identified, but no error. 2 :   Errors occurred during test execution. 3 :   No test results found. 4 :   Tests were executed, and all reported the <code>skip</code> result.</p>"},{"location":"overview/#variables","title":"Variables","text":"<p>The list of available environment variables which can be used to adjust the execution.</p>"},{"location":"overview/#command-variables","title":"Command Variables","text":"<p>The following environment variables can be used to modify behaviour of the <code>tmt</code> command.</p> <p>TMT_DEBUG :   Enable the desired debug level. Most of the commands support     levels from 1 to 3. However, some of the plugins go even     deeper when needed.</p> <p>TMT_PLUGINS :   Path to a directory with additional plugins. Multiple paths     separated with the <code>:</code> character can be provided as well.</p> <p>TMT_FEELING_SAFE :   Set this variable to <code>1</code> to enable potentially dangerous     operations such as executing tests directly on the test runner     using the <code>local</code> provision method. Use with caution, only     when you can fully trust the <code>tmt</code> metadata or if you know     what you are doing.</p> <p>TMT_CONFIG_DIR :   Path to an alternative directory with config files. By default     <code>~/.config/tmt</code> is used.</p> <p>TMT_WORKDIR_ROOT :   Path to root directory containing run workdirs. Defaults to     <code>/var/tmp/tmt</code>.</p> <p>NO_COLOR, TMT_NO_COLOR :   Disable colors in the output, both the actual output and     logging messages. Output only plain, non-colored text.</p> <pre><code>Two variables are accepted, one with the usual `TMT_`\nprefix, but tmt accepts also `NO_COLOR` to support the\nNO_COLOR effort, see https://no-color.org/ for more\ninformation.\n</code></pre> <p>TMT_FORCE_COLOR :   Enforce colors in the output, both the actual output and     logging messages. Might come handy when tmt's output streams     are not terminal-like, yet its output would be displayed by     tools with ANSI color support. This is often the case of     various CI systems.</p> <pre><code>Note that `TMT_FORCE_COLOR` takes priority over `NO_COLOR`\nand `TMT_NO_COLOR`. If user tries both to disable and enable\ncolorization, output would be colorized.\n</code></pre> <p>TMT_SHOW_TRACEBACK :   By default, when tmt reports an error, the corresponding     traceback is not printed out. By setting this variable, the     traceback and details would be shown:</p> <pre><code>TMT_SHOW_TRACEBACK=0 (or unset)\n:   Render only exception and its causes.\n\nTMT_SHOW_TRACEBACK=1\n:   Render also call stack for exception and each of its causes.\n\nTMT_SHOW_TRACEBACK=2\n:   Render also call stack for exception and each of its causes,\n    plus all local variables in each frame, trimmed to first 1024\n    characters of their values.\n\nTMT_SHOW_TRACEBACK=full\n:   Render everything that can be show: all causes, their call\n    stacks, all frames and all locals in their completeness.\n</code></pre> <p>TMT_OUTPUT_WIDTH :   By default, the output width of commands like <code>tmt * show</code> is constrained     to 79 characters. Set this variable to an integer to change the limit.</p> <p>TMT_GIT_CREDENTIALS_URL_&lt;suffix&gt;, TMT_GIT_CREDENTIALS_VALUE_&lt;suffix&gt; :   Variable pairs used to provide credentials to clone git repositories. This     is needed when working with private repositories. The suffix identifies     the pair and determines the order in which URL regexp is tried.</p> <pre><code>The `TMT_GIT_CREDENTIALS_URL_&lt;suffix&gt;` contains regexp to search against\nurl to clone. For first successful search the content of the\n`TMT_GIT_CREDENTIALS_VALUE_&lt;suffix&gt;` variable is used as the credential\nvalue. When it is set to an empty string, unmodified url is used.\n\nFor `GitLab` private repositories, you have three options for specifying\nthe credentials:\n\n*   [Personal Access Tokens](https://docs.gitlab.com/user/profile/personal_access_tokens/):\n\n    Good for user-specific permissions or service accounts. For read-only\n    access, use the `read_repository` scope:\n\n    ```\n    TMT_GIT_CREDENTIALS_URL_lab='gitlab.com/mysecretproject'\n    TMT_GIT_CREDENTIALS_VALUE_lab='your_gitlab_username:your_pat'\n    ```\n\n*   [Deploy Tokens](https://docs.gitlab.com/user/project/deploy_tokens/):\n\n    Best for automated read-only access. Project-specific, not tied to\n    a user, and provides strict read-only repository access:\n\n    ```\n    TMT_GIT_CREDENTIALS_URL_lab='gitlab.com/mysecretproject'\n    TMT_GIT_CREDENTIALS_VALUE_lab='gitlab+deploy-token-123:abcxyz123'\n    ```\n\n*   [OAuth2 Tokens](https://docs.gitlab.com/api/oauth2/):\n\n    Secure short-lived tokens with the `read_repository` scope:\n\n    ```\n    TMT_GIT_CREDENTIALS_URL_lab='gitlab.com/mysecretproject'\n    TMT_GIT_CREDENTIALS_VALUE_lab='oauth2:your_oauth2_token'\n    ```\n\nFor `GitHub` private repositories, you have only a single method\nfor specifying the cloning credentials:\n\n*   [OAuth Tokens](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/managing-deploy-keys#https-cloning-with-oauth-tokens):\n\n    You need to create a [personal access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens) and specify it without\n    your username. Both `classic` and `fine-grained` personal\n    access tokens can be used:\n\n    ```\n    TMT_GIT_CREDENTIALS_URL_hub='github.com/teemtee'\n    TMT_GIT_CREDENTIALS_VALUE_hub='personaltoken'\n    ```\n</code></pre> <p>TMT_GIT_CLONE_ATTEMPTS :   The maximum number of retries to clone a git repository if it     fails. By default, 3 attempts are done.</p> <p>TMT_GIT_CLONE_INTERVAL :   The interval (in seconds) to retry cloning a git repository     again, 10 seconds by default.</p> <p>TMT_GIT_CLONE_TIMEOUT :   Overall maximum time in seconds to clone a git repository. By     default, the limit is not set.</p> <p>TMT_BOOT_TIMEOUT :   How many seconds to wait for a guest to boot. Applies to provision     plugins that control the guest creation, e.g. <code>virtual</code>. By     default, it is 2 minutes.</p> <p>TMT_CONNECT_TIMEOUT :   How many seconds to wait for a connection to succeed after guest     boot. By default, it is 2 minutes.</p> <p>TMT_REBOOT_TIMEOUT :   How many seconds to wait for a connection to succeed after     guest reboot. By default, it is 10 minutes.</p> <p>TMT_SCRIPTS_DIR :   Destination directory for storing <code>tmt</code> scripts on the guest.     By default <code>/usr/local/bin</code> is used, except for guests using     <code>rpm-ostree</code>, where <code>/var/lib/tmt/scripts</code> is used. See the     tmt internal test executor documentation for more details     on the scripts installed on the guest.</p> <p>TMT_SSH_* :   Every environment variable in this format would be treated as an SSH     option, and passed to the <code>-o</code> option of <code>ssh</code> command. See     <code>man 5 ssh_config</code> for the list of all options.</p> <pre><code>The environment variable name would be converted into an SSH option,\ne.g. `export TMT_SSH_CONNECTION_ATTEMPTS=5` would become\n`-oConnectionAttempts=5`. `export TMT_SSH_ConnectionAttempts=5`\nwould also be accepted.\n\nSSH options provided via environment variables will be overruled by\nguest-specific `ssh-options` key.\n</code></pre> <p>TMT_REPORT_ARTIFACTS_URL :   Link to test artifacts provided for report plugins.</p> <p>TMT_POLICY_FILE :   Location of a file with policy rules for modification of test     metadata keys. Both absolute and relative paths are accepted; a     relative path is interpreted either against the current working     directory, or against the policy root directory if it was specified.</p> <pre><code>See [tmt policy specification](spec/policy.html) for more details on policies.\n</code></pre> <p>TMT_POLICY_NAME :   Name of the file with policy rules for modification of test metadata     keys. The name would be extended with <code>.yaml</code> suffix, and tmt will     try to locate it under the policy root directory.</p> <pre><code>See [tmt policy specification](spec/policy.html) for more details on policies.\n</code></pre> <p>TMT_POLICY_ROOT :   If set, policy files must be located under this directory. Policy     specified by its name is searched under this directory only, and     policy specified by its filepath will be allowed only if the     filepath is under this directory.</p> <pre><code>See [tmt policy specification](spec/policy.html) for more details on policies.\n</code></pre>"},{"location":"overview/#step-variables","title":"Step Variables","text":"<p>The following environment variables are provided to the environment during <code>prepare</code>, <code>execute</code> and <code>finish</code> steps:</p> <p>TMT_TREE :   The full path of the working directory where the metadata tree     is copied. This usually contains the whole git repository where     tmt plans are located in. Notice that it might not contain tmt     tests if tmt plans and tests are in different git repositories.</p> <p>TMT_PLAN_DATA :   Path to the common directory used for storing logs and other     artifacts related to the whole plan execution. It is pulled     back from the guest and available for inspection after the     plan is completed.</p> <p>TMT_PLAN_ENVIRONMENT_FILE :   Path to the file containing environment variables that should     be sourced after prepare and execute steps. These variables will     be accessible for all subsequent steps and have lower priority     than variables specified by the <code>environment</code> key,     <code>environment-file</code> key, or the command line. Variables inside     the file have to be in the format of <code>NAME=VALUE</code> and each     variable should be on a separate line.</p> <pre><code>Example of the file content:\n\n```\nCOUNT=1\nVARIABLE=VALUE\nANOTHER_VARIABLE=ANOTHER_VALUE\n```\n</code></pre> <p>TMT_VERSION :   The version of tmt.</p>"},{"location":"overview/#test-variables","title":"Test Variables","text":"<p>The following environment variables are provided to the test during the execution:</p> <p>TMT_TEST_NAME :   The test name, as a resolved FMF object name starting with <code>/</code>     from the root of the hierarchy.</p> <p>TMT_TEST_DATA :   Path to the directory where test can store logs and other     artifacts generated during its execution. These will be pulled     back from the guest and available for inspection after the     test execution is finished.</p> <p>TMT_TEST_SERIAL_NUMBER :   The serial number of running test in the whole plan. Each test     is assigned its own serial number.</p> <p>TMT_TEST_ITERATION_ID :   The iteration ID is a combination of a unique run ID and the test     serial number. The value is different for each new test execution.</p> <p>TMT_TEST_METADATA :   Path to a YAML-formatted file with test metadata collected     during the <code>discover</code> step.</p> <p>TMT_SOURCE_DIR :   Path to directory with downloaded and extracted sources if     the <code>dist-git-source</code> option was used in the <code>discover</code>     step.</p> <p>TMT_REBOOT_COUNT :   During the test execution the <code>tmt-reboot</code> command can be     used to request reboot of the guest. This variable contains     number of reboots which already happened during the test.     Value is set to <code>0</code> if no reboot occurred.</p> <pre><code>In order to keep backward-compatibility with older tests,\n`rhts-reboot` and `rstrnt-reboot` commands are supported\nfor requesting the reboot, variables `REBOOTCOUNT` and\n`RSTRNT_REBOOTCOUNT` contain number of reboots as well.\n</code></pre> <p>TMT_TEST_RESTART_COUNT :   This variable contains number of times the test was restarted. Such     restarts may be consequence of guest reboot, in which case     <code>TMT_REBOOT_COUNT</code> gets incremented as well, or test crashed and     has been restarted. Value is set to <code>0</code> when the test starts for     the first time.</p> <p>TMT_TOPOLOGY_BASH, TMT_TOPOLOGY_YAML :   Paths of files describing existing guests, their roles and the     guest on which the test is running. Format of these files     is described in the <code>Guest Topology Format</code> section of the     plan specification.</p> <p>TMT_TEST_PIDFILE, TMT_TEST_PIDFILE_LOCK :   Path to a file storing the test process pid and path to its     reboot-request file, separated by a space. The \"LOCK\" variable     then holds path to a locking file which must be acquired before     making any changes to the pid file.</p> <p>TMT_TEST_PIDFILE_ROOT :   By default, the test pidfile file is stored in <code>/var/tmp</code>     directory. If specified, the directory in this variable would be     used instead. The directory permissions should follow the pattern     of temporary directory permissions, e.g. <code>chmod 1777</code>, to     allow access to users with all privilege levels.</p>"},{"location":"overview/#plugin-variables","title":"Plugin Variables","text":"<p>Each plugin option can be also specified via environment variable. Variables follow a naming scheme utilizing plugin name, step it belongs to, and the option name:</p> <p><code>TMT_PLUGIN_${STEP}_${PLUGIN}_${OPTION}</code></p> <p>All values are upper-cased, with dashes (<code>-</code>) replaced by underscores (<code>_</code>).</p> <p>For example, an execute plugin \"tmt\" would run with verbosity equal to <code>-vvv</code>:</p> <pre><code>TMT_PLUGIN_EXECUTE_TMT_VERBOSE=3 tmt run ... execute -h tmt ...\n</code></pre> <p>Command-line takes precedence over environment variables, therefore <code>-v</code> would undo the effect of environment variable, and reduce verbosity to one level only:</p> <pre><code>TMT_PLUGIN_EXECUTE_TMT_VERBOSE=3 tmt run ... execute -h tmt -v ...\n</code></pre> <p>Environment variables - just like command-line options - take precedence over values stored in files. For example, consider the following discover step:</p> <pre><code>discover:\n    how: fmf\n    url: https://example.org/\n</code></pre> <p>The following commands would override the URL:</p> <pre><code>tmt run ... discover -h fmf --url https://actual.org/ ...\n</code></pre> <pre><code>TMT_PLUGIN_DISCOVER_FMF_URL=https://actual.org/ tmt run ...\n</code></pre> <p>For setting flag-like option, 0 and 1 are the expected value. For example, an interactive mode would be enabled in this run:</p> <pre><code>TMT_PLUGIN_EXECUTE_TMT_INTERACTIVE=1 tmt run ... execute -h tmt ...\n</code></pre> <p>Note</p> <p>The following applies to situations when a plugin is specified on the command line only. Keys of plugins specified in fmf files would not be modified. This is a limit of the current implementation, and will be addressed in the future:</p> <pre><code># Here the verbosity will not be increased since the plugin is\n# not mentioned on the command line:\n$ TMT_PLUGIN_DISCOVER_FMF_VERBOSE=2 tmt run -a\n\n# Here the environment variable will take effect:\n$ TMT_PLUGIN_DISCOVER_FMF_VERBOSE=2 tmt run -a discover -h fmf ...\n</code></pre> <p>Several plugins (<code>report -h reportportal</code>, <code>report -h polarion</code>, <code>execute -h tmt</code>) allow selected variables to be processed, even when plugin is not specified on the command line.</p>"},{"location":"overview/#regular-expressions","title":"Regular Expressions","text":"<p>Many specification keys and command line options accept regular expressions, e.g. to filter a set of tests, <code>tmt run ... test --name '^/foo'</code>. Whenever tmt works with regular expressions, the following rules apply.</p> <p>Python implementation :   Since tmt is implemented in Python, Python's re package is     used for handling regular expressions. It comes with Python     standard library, and it is widely used and well documented.     For the deep dive into supported syntax, see     Regular Expression Syntax section, for a gentler     introduction there is a Regular Expression HOWTO.</p> <p>Search versus match :   There are two ways how to check whether a regular expression     matches a string: \"match\" or \"search\":</p> <pre><code>*   in the \"match\" mode, the pattern must match from the very\n    beginning of the string. For example, `foo.ar` would match\n    `foobar` but not `/foobar`. It works in a \"starts with\"\n    fashion.\n*   on the other hand, the \"search\" mode is more similar to\n    \"contains\" approach, and allows pattern to match anywhere in\n    the string. In this mode, `foo.ar` would match both\n    `foobar` and `/foobar`.\n\nIn both modes, any characters may follow the matching pattern,\ne.g. regular expression `foo.bar` is the same as\n`foo.bar.*`.\n\ntmt sticks to the \"search\" mode by default. But, to improve\nuser experience, some keys and command line options do use the\n\"match\" mode. Such keys and options will note this in their\ndocumentation or help texts.\n</code></pre>"},{"location":"overview/#links","title":"Links","text":"<ul> <li>Git: https://github.com/teemtee/tmt</li> <li>Docs: https://tmt.readthedocs.io/</li> <li>Stories: https://tmt.readthedocs.io/en/stable/stories.html</li> <li>Issues: https://github.com/teemtee/tmt/issues</li> <li>Releases: https://tmt.readthedocs.io/en/stable/releases.html</li> <li>Copr: https://copr.fedorainfracloud.org/coprs/g/teemtee/stable/</li> <li>PIP: https://pypi.org/project/tmt/</li> <li>Quay: https://quay.io/organization/teemtee</li> <li>Metadata Specification: https://tmt.readthedocs.io/en/stable/spec.html</li> <li>Flexible Metadata Format: https://fmf.readthedocs.io/</li> <li>Testing Farm: https://docs.testing-farm.io/</li> <li>Packit: https://packit.dev/testing-farm/</li> </ul>"},{"location":"overview/#authors","title":"Authors","text":"<p>Petr \u0160pl\u00edchal, Miro Hron\u010dok, Alexander Sosedkin, Luk\u00e1\u0161 Zachar, Petr Men\u0161\u00edk, Leo\u0161 Pol, Miroslav Vadkerti, Pavel Valena, Jakub Heger, Honza Hor\u00e1k, Rachel Sibley, Franti\u0161ek Ne\u010das, Michal Ruprich, Martin Kyral, Milo\u0161 Prchl\u00edk, Tom\u00e1\u0161 Navr\u00e1til, Franti\u0161ek Lachman, Patrik Kis, Ondrej Mosn\u00e1\u010dek, Andrea Fickov\u00e1, Denis Karpelevich, Michal Srb, Jan \u0160\u010dotka, Artem Zhukov, Vinzenz Feenstra, Inessa Vasilevskaya, \u0160t\u011bp\u00e1n N\u011bmec, Robin Hack, Yulia Kopkova, Ondrej Mori\u0161, Martin Zelen\u00fd, Karel \u0160rot, Franti\u0161ek Zatloukal, Simon Walter, Petr Maty\u00e1\u0161, Yariv Rachmani, Pavel Cahyna, Martin Litwora, Brian Grech, Vojt\u011bch Eichler, Philip Daly, Vector Li, Evgeny Fedin, Guy Inger, Adri\u00e1n Toma\u0161ov, Jan Havl\u00edn, Luk\u00e1\u0161 Kotek, Daniel Dibl\u00edk, Laura Barcziova, Mari\u00e1n Kon\u010dek, Marcin Sobczyk, Ji\u0159\u00ed Jab\u016frek, Huijing Hei, Tibor Dudl\u00e1k, Jan Mack\u016f, Filip V\u00e1gner, Martin Hoyer, Iveta \u010cesalov\u00e1, Yi Zhang, Zhaojuan Guo, Nat\u00e1lia Bub\u00e1kov\u00e1, Michal Josef \u0160pa\u010dek, Ji\u0159\u00ed Popelka, Matej Focko, Yulia Kopkova, Tom\u00e1\u0161 Bajer, Carlos Rodriguez-Fernandez, James Molet, Cristian Le, Lili Nie, Martin \u010cerm\u00e1k, Michael Vogt, Qinghua Cheng, Michael Engel, Anatoli Babenia, Colin Walters, Link Dupont, Mario Casquero, Martin Kluso\u0148, Pavel Holica, Otto \u0160abart, Ismail Ibrahim Quwarah, Sergei Petrosian, Tom Koscielniak, Han Han, Luigi Pellecchia, Siteshwar Vashisht, Chris Kyrouac, Xiaofeng Wang, Coiby Xu, Michal Posp\u00ed\u0161il, Wayne Sun, Evgeni Vakhonin, Mike Stowell, Therese Cornell and Mingyu Shi.</p>"},{"location":"overview/#copyright","title":"Copyright","text":"<p>Copyright Red Hat</p> <p>This program is free software; you can redistribute it and/or modify it under the terms of the MIT License.</p>"},{"location":"plugins/","title":"Plugins","text":"<p>This section documents the available plugins for each step.</p> <ul> <li>Discover</li> <li>Provision</li> <li>Prepare</li> <li>Execute</li> <li>Report</li> <li>Finish</li> </ul>"},{"location":"plugins/discover/","title":"Discover","text":"<p>Gather information about test cases to be executed.</p>"},{"location":"plugins/discover/#fmf","title":"fmf","text":""},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf","title":"<code>tmt.steps.discover.fmf.DiscoverFmf</code>","text":"<p>               Bases: <code>DiscoverPlugin[DiscoverFmfStepData]</code></p> <p>Discover available tests from fmf metadata.</p> <p>By default all available tests from the current repository are used so the minimal configuration looks like this:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n</code></pre> <p>Full config example:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    url: https://github.com/teemtee/tmt\n    ref: main\n    path: /fmf/root\n    test: /tests/basic\n    filter: 'tier: 1'\n</code></pre> <p>If no <code>ref</code> is provided, the default branch from the origin is used.</p> <p>Dist Git ^^^^^^^^</p> <p>For DistGit repo one can download sources and use code from them in the tests. Sources are extracted into <code>$TMT_SOURCE_DIR</code> path, patches are applied by default. See options to install build dependencies or to just download sources without applying patches. To apply patches, special <code>prepare</code> phase with order <code>60</code> is added, and <code>prepare</code> step has to be enabled for it to run.</p> <p>It can be used together with <code>ref</code>, <code>path</code> and <code>url</code>, however <code>ref</code> is not possible without using <code>url</code>.</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    dist-git-source: true\n</code></pre> <p>Name Filter ^^^^^^^^^^^</p> <p>Use the <code>test</code> key to limit which tests should be executed by providing regular expression matching the test name:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    test: ^/tests/area/.*\n</code></pre> <p>.. code-block:: shell</p> <pre><code>tmt run discover --how fmf --verbose --test \"^/tests/core.*\"\n</code></pre> <p>When several regular expressions are provided, tests matching each regular expression are concatenated. In this way it is possible to execute a single test multiple times:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    test:\n      - ^/test/one$\n      - ^/test/two$\n      - ^/special/setup$\n      - ^/test/one$\n      - ^/test/two$\n</code></pre> <p>.. code-block:: shell</p> <pre><code>tmt run discover -h fmf -v -t '^/test/one$' -t '^/special/setup$' -t '^/test/two$'\n</code></pre> <p>The <code>include</code> key also allows to select tests by name, with two important distinctions from the <code>test</code> key:</p> <ul> <li> <p>The original test :ref:<code>/spec/core/order</code> is preserved so it does   not matter in which order tests are listed under the <code>include</code>   key.</p> </li> <li> <p>Test duplication is not allowed, so even if a test name is   repeated several times, test will be executed only once.</p> </li> </ul> <p>Finally, the <code>exclude</code> key can be used to specify regular expressions matching tests which should be skipped during the discovery.</p> <p>The <code>test</code>, <code>include</code> and <code>exclude</code> keys use search mode for matching patterns. See the :ref:<code>regular-expressions</code> section for detailed information about how exactly the regular expressions are handled.</p> <p>Link Filter ^^^^^^^^^^^</p> <p>Selecting tests containing specified link is possible using <code>link</code> key accepting <code>RELATION:TARGET</code> format of values. Regular expressions are supported for both relation and target part of the value. Relation can be omitted to target match any relation.</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    link: verifies:.*issue/850$\n</code></pre> <p>Advanced Filter ^^^^^^^^^^^^^^^</p> <p>The <code>filter</code> key can be used to apply an advanced filter based on test metadata attributes. These can be especially useful when tests are grouped by the :ref:<code>/spec/core/tag</code> or :ref:<code>/spec/core/tier</code> keys:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    filter: tier:3 &amp; tag:provision\n</code></pre> <p>.. code-block:: shell</p> <pre><code>tmt run discover --how fmf --filter \"tier:3 &amp; tag:provision\"\n</code></pre> <p>See the <code>pydoc fmf.filter</code> documentation for more details about the supported syntax and available operators.</p> <p>Modified Tests ^^^^^^^^^^^^^^</p> <p>It is also possible to limit tests only to those that have changed in git since a given revision. This can be particularly useful when testing changes to tests themselves (e.g. in a pull request CI).</p> <p>Related keys: <code>modified-only</code>, <code>modified-url</code>, <code>modified-ref</code></p> <p>Example to compare local repo against upstream <code>main</code> branch:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    modified-only: True\n    modified-url: https://github.com/teemtee/tmt\n    modified-ref: reference/main\n</code></pre> <p>Note that internally the modified tests are appended to the list specified via <code>test</code>, so those tests will also be selected even if not modified.</p> <p>Adjust Tests ^^^^^^^^^^^^</p> <p>Use the <code>adjust-tests</code> key to modify the discovered tests' metadata directly from the plan. For example, extend the test duration for slow hardware or modify the list of required packages when you do not have write access to the remote test repository. The value should follow the <code>adjust</code> rules syntax.</p> <p>The following example adds an <code>avc</code> check for each discovered test, doubles its duration and replaces each occurrence of the word <code>python3.11</code> in the list of required packages.</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: fmf\n    adjust-tests:\n      - check+:\n          - how: avc\n      - duration+: '*2'\n        because: Slow system under test\n        when: arch == i286\n      - require~:\n          - '/python3.11/python3.12/'\n</code></pre> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>@tmt.steps.provides_method('fmf')\nclass DiscoverFmf(tmt.steps.discover.DiscoverPlugin[DiscoverFmfStepData]):\n    \"\"\"\n    Discover available tests from fmf metadata.\n\n    By default all available tests from the current repository are used\n    so the minimal configuration looks like this:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n\n    Full config example:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            url: https://github.com/teemtee/tmt\n            ref: main\n            path: /fmf/root\n            test: /tests/basic\n            filter: 'tier: 1'\n\n    If no ``ref`` is provided, the default branch from the origin is used.\n\n\n    Dist Git\n    ^^^^^^^^\n\n    For DistGit repo one can download sources and use code from them in\n    the tests. Sources are extracted into ``$TMT_SOURCE_DIR`` path,\n    patches are applied by default. See options to install build\n    dependencies or to just download sources without applying patches.\n    To apply patches, special ``prepare`` phase with order ``60`` is\n    added, and ``prepare`` step has to be enabled for it to run.\n\n    It can be used together with ``ref``, ``path`` and ``url``,\n    however ``ref`` is not possible without using ``url``.\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            dist-git-source: true\n\n    Name Filter\n    ^^^^^^^^^^^\n\n    Use the ``test`` key to limit which tests should be executed by\n    providing regular expression matching the test name:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            test: ^/tests/area/.*\n\n    .. code-block:: shell\n\n        tmt run discover --how fmf --verbose --test \"^/tests/core.*\"\n\n    When several regular expressions are provided, tests matching each\n    regular expression are concatenated. In this way it is possible to\n    execute a single test multiple times:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            test:\n              - ^/test/one$\n              - ^/test/two$\n              - ^/special/setup$\n              - ^/test/one$\n              - ^/test/two$\n\n    .. code-block:: shell\n\n        tmt run discover -h fmf -v -t '^/test/one$' -t '^/special/setup$' -t '^/test/two$'\n\n    The ``include`` key also allows to select tests by name, with two\n    important distinctions from the ``test`` key:\n\n    * The original test :ref:`/spec/core/order` is preserved so it does\n      not matter in which order tests are listed under the ``include``\n      key.\n\n    * Test duplication is not allowed, so even if a test name is\n      repeated several times, test will be executed only once.\n\n    Finally, the ``exclude`` key can be used to specify regular\n    expressions matching tests which should be skipped during the\n    discovery.\n\n    The ``test``, ``include`` and ``exclude`` keys use search mode for\n    matching patterns. See the :ref:`regular-expressions` section for\n    detailed information about how exactly the regular expressions are\n    handled.\n\n    Link Filter\n    ^^^^^^^^^^^\n\n    Selecting tests containing specified link is possible using ``link``\n    key accepting ``RELATION:TARGET`` format of values. Regular\n    expressions are supported for both relation and target part of the\n    value. Relation can be omitted to target match any relation.\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            link: verifies:.*issue/850$\n\n    Advanced Filter\n    ^^^^^^^^^^^^^^^\n\n    The ``filter`` key can be used to apply an advanced filter based on\n    test metadata attributes. These can be especially useful when tests\n    are grouped by the :ref:`/spec/core/tag` or :ref:`/spec/core/tier`\n    keys:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            filter: tier:3 &amp; tag:provision\n\n    .. code-block:: shell\n\n        tmt run discover --how fmf --filter \"tier:3 &amp; tag:provision\"\n\n    See the ``pydoc fmf.filter`` documentation for more details about\n    the supported syntax and available operators.\n\n    Modified Tests\n    ^^^^^^^^^^^^^^\n\n    It is also possible to limit tests only to those that have changed\n    in git since a given revision. This can be particularly useful when\n    testing changes to tests themselves (e.g. in a pull request CI).\n\n    Related keys: ``modified-only``, ``modified-url``, ``modified-ref``\n\n    Example to compare local repo against upstream ``main`` branch:\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            modified-only: True\n            modified-url: https://github.com/teemtee/tmt\n            modified-ref: reference/main\n\n    Note that internally the modified tests are appended to the list\n    specified via ``test``, so those tests will also be selected even if\n    not modified.\n\n    Adjust Tests\n    ^^^^^^^^^^^^\n\n    Use the ``adjust-tests`` key to modify the discovered tests'\n    metadata directly from the plan. For example, extend the test\n    duration for slow hardware or modify the list of required packages\n    when you do not have write access to the remote test repository.\n    The value should follow the ``adjust`` rules syntax.\n\n    The following example adds an ``avc`` check for each discovered\n    test, doubles its duration and replaces each occurrence of the word\n    ``python3.11`` in the list of required packages.\n\n    .. code-block:: yaml\n\n        discover:\n            how: fmf\n            adjust-tests:\n              - check+:\n                  - how: avc\n              - duration+: '*2'\n                because: Slow system under test\n                when: arch == i286\n              - require~:\n                  - '/python3.11/python3.12/'\n    \"\"\"\n\n    _data_class = DiscoverFmfStepData\n\n    # Options which require .git to be present for their functionality\n    _REQUIRES_GIT = (\n        \"ref\",\n        \"modified-url\",\n        \"modified-only\",\n        \"fmf-id\",\n    )\n\n    @property\n    def is_in_standalone_mode(self) -&gt; bool:\n        \"\"\"\n        Enable standalone mode when listing fmf ids\n        \"\"\"\n\n        if self.opt('fmf_id'):\n            return True\n        return super().is_in_standalone_mode\n\n    def get_git_root(self, directory: Path) -&gt; Path:\n        \"\"\"\n        Find git root of the path\n        \"\"\"\n\n        output = self.run(\n            Command(\"git\", \"rev-parse\", \"--show-toplevel\"),\n            cwd=directory,\n            ignore_dry=True,\n        )\n        assert output.stdout is not None\n        return Path(output.stdout.strip(\"\\n\"))\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Discover available tests\n        \"\"\"\n\n        super().go(logger=logger)\n\n        # Check url and path, prepare test directory\n        url = self.get('url')\n        # FIXME: cast() - typeless \"dispatcher\" method\n        path = Path(cast(str, self.get('path'))) if self.get('path') else None\n        # Save the test directory so that others can reference it\n        ref = self.get('ref')\n        assert self.workdir is not None\n        self.testdir = self.workdir / 'tests'\n        sourcedir = self.workdir / 'source'\n        dist_git_source = self.get('dist-git-source', False)\n        dist_git_merge = self.get('dist-git-merge', False)\n\n        # No tests are selected in some cases\n        self._tests: list[tmt.Test] = []\n\n        # Self checks\n        if dist_git_source and not dist_git_merge and (ref or url):\n            raise tmt.utils.DiscoverError(\n                \"Cannot manipulate with dist-git without the `--dist-git-merge` option.\"\n            )\n\n        self.log_import_plan_details()\n\n        # Clone provided git repository (if url given) with disabled\n        # prompt to ignore possibly missing or private repositories\n        if url:\n            self.info('url', url, 'green')\n            self.debug(f\"Clone '{url}' to '{self.testdir}'.\")\n            # Shallow clone to speed up testing and\n            # minimize data transfers if ref is not provided\n            tmt.utils.git.git_clone(\n                url=url,\n                destination=self.testdir,\n                shallow=ref is None,\n                env=Environment({\"GIT_ASKPASS\": EnvVarValue(\"echo\")}),\n                logger=self._logger,\n            )\n            git_root = self.testdir\n        # Copy git repository root to workdir\n        else:\n            if path is not None:\n                fmf_root: Optional[Path] = path\n            else:\n                fmf_root = Path(self.step.plan.fmf_root) if self.step.plan.fmf_root else None\n            requires_git = self.opt('sync-repo') or any(\n                self.get(opt) for opt in self._REQUIRES_GIT\n            )\n            # Path for distgit sources cannot be checked until the\n            # they are extracted\n            if path and not path.is_dir() and not dist_git_source:\n                raise tmt.utils.DiscoverError(f\"Provided path '{path}' is not a directory.\")\n            if dist_git_source:\n                # Ensure we're in a git repo when extracting dist-git sources\n                try:\n                    git_root = self.get_git_root(Path(self.step.plan.node.root))\n                except tmt.utils.RunError:\n                    assert self.step.plan.my_run is not None  # narrow type\n                    assert self.step.plan.my_run.tree is not None  # narrow type\n                    raise tmt.utils.DiscoverError(f\"{self.step.plan.node.root} is not a git repo\")\n            else:\n                if fmf_root is None:\n                    raise tmt.utils.DiscoverError(\"No metadata found in the current directory.\")\n                # Check git repository root (use fmf root if not found)\n                try:\n                    git_root = self.get_git_root(fmf_root)\n                except tmt.utils.RunError:\n                    self.debug(f\"Git root not found, using '{fmf_root}.'\")\n                    git_root = fmf_root\n                # Set path to relative path from the git root to fmf root\n                path = fmf_root.resolve().relative_to(\n                    git_root.resolve() if requires_git else fmf_root.resolve()\n                )\n\n            # And finally copy the git/fmf root directory to testdir\n            # (for dist-git case only when merge explicitly requested)\n            if requires_git:\n                directory: Path = git_root\n            else:\n                assert fmf_root is not None  # narrow type\n                directory = fmf_root\n            self.info('directory', directory, 'green')\n            if not dist_git_source or dist_git_merge:\n                self.debug(f\"Copy '{directory}' to '{self.testdir}'.\")\n                if not self.is_dry_run:\n                    tmt.utils.filesystem.copy_tree(directory, self.testdir, self._logger)\n\n        # Prepare path of the dynamic reference\n        try:\n            ref = tmt.base.resolve_dynamic_ref(\n                logger=self._logger,\n                workdir=self.testdir,\n                ref=ref,\n                plan=self.step.plan,\n            )\n        except tmt.utils.FileError as error:\n            raise tmt.utils.DiscoverError(str(error))\n\n        # Checkout revision if requested\n        if ref:\n            self.info('ref', ref, 'green')\n            self.debug(f\"Checkout ref '{ref}'.\")\n            self.run(Command('git', 'checkout', '-f', ref), cwd=self.testdir)\n\n        # Show current commit hash if inside a git repository\n        if self.testdir.is_dir():\n            with contextlib.suppress(tmt.utils.RunError, AttributeError):\n                self.verbose(\n                    'hash',\n                    tmt.utils.git.git_hash(directory=self.testdir, logger=self._logger),\n                    'green',\n                )\n\n        # Dist-git source processing during discover step\n        if dist_git_source:\n            try:\n                distgit_dir = self.testdir if ref else git_root\n                self.process_distgit_source(distgit_dir, sourcedir)\n                return\n            except Exception as error:\n                raise tmt.utils.DiscoverError(\"Failed to process 'dist-git-source'.\") from error\n\n        # Discover tests\n        self.do_the_discovery(path)\n\n        # Apply tmt run policy\n        if self.step.plan.my_run is not None:\n            for policy in self.step.plan.my_run.policies:\n                policy.apply_to_tests(tests=self._tests, logger=self._logger)\n\n    def process_distgit_source(self, distgit_dir: Path, sourcedir: Path) -&gt; None:\n        \"\"\"\n        Process dist-git source during the discover step.\n        \"\"\"\n\n        self.download_distgit_source(\n            distgit_dir=distgit_dir,\n            target_dir=sourcedir,\n            handler_name=self.get('dist-git-type'),\n        )\n\n        # Copy rest of files so TMT_SOURCE_DIR has patches, sources and spec file\n        # FIXME 'worktree' could be used as sourcedir when 'url' is not set\n        tmt.utils.filesystem.copy_tree(\n            distgit_dir,\n            sourcedir,\n            self._logger,\n        )\n\n        # patch &amp; rediscover will happen later in the prepare step\n        if not self.get('dist-git-download-only'):\n            # Check if prepare is enabled, warn user if not\n            if not self.step.plan.prepare.enabled:\n                self.warn(\"Sources will not be extracted, prepare step is not enabled.\")\n\n            insert_to_prepare_step(\n                discover_plugin=self,\n                sourcedir=sourcedir,\n            )\n\n        # merge or not, detect later\n        self.step.plan.discover.extract_tests_later = True\n        self.info(\"Tests will be discovered after dist-git patching in prepare.\")\n\n    def do_the_discovery(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"\n        Discover the tests\n        \"\"\"\n\n        # Original path might adjusted already in go()\n        if path is None:\n            path = Path(cast(str, self.get('path'))) if self.get('path') else None\n        prune = self.get('prune')\n        # Adjust path and optionally show\n        if path is None or path.resolve() == Path.cwd().resolve():\n            path = Path('')\n        else:\n            self.info('path', path, 'green')\n\n        # Prepare the whole tree path\n        tree_path = self.testdir / path.unrooted()\n        if not tree_path.is_dir() and not self.is_dry_run:\n            raise tmt.utils.DiscoverError(f\"Metadata tree path '{path}' not found.\")\n\n        # Show filters and test names if provided\n        # Check the 'test --filter' option first, then from discover\n        filters = list(tmt.base.Test._opt('filters') or self.get('filter', []))\n        for filter_ in filters:\n            self.info('filter', filter_, 'green')\n        # Names of tests selected by --test option\n        names = self.get('test', [])\n        if names:\n            self.info('tests', fmf.utils.listed(names), 'green')\n\n        # Check the 'test --link' option first, then from discover\n        # FIXME: cast() - typeless \"dispatcher\" method\n        raw_link_needles = cast(list[str], tmt.Test._opt('links', []) or self.get('link', []))\n        link_needles = [\n            tmt.base.LinkNeedle.from_spec(raw_needle) for raw_needle in raw_link_needles\n        ]\n\n        for link_needle in link_needles:\n            self.info('link', str(link_needle), 'green')\n\n        excludes = list(tmt.base.Test._opt('exclude') or self.data.exclude)\n        includes = list(tmt.base.Test._opt('include') or self.data.include)\n\n        # Filter only modified tests if requested\n        modified_only = self.get('modified-only')\n        modified_url = self.get('modified-url')\n        if modified_url:\n            previous = modified_url\n            modified_url = tmt.utils.git.clonable_git_url(modified_url)\n            self.info('modified-url', modified_url, 'green')\n            if previous != modified_url:\n                self.debug(f\"Original url was '{previous}'.\")\n            self.debug(f\"Fetch also '{modified_url}' as 'reference'.\")\n            self.run(\n                Command('git', 'remote', 'add', 'reference', modified_url),\n                cwd=self.testdir,\n            )\n            self.run(\n                Command('git', 'fetch', 'reference'),\n                cwd=self.testdir,\n            )\n        if modified_only:\n            modified_ref = self.get(\n                'modified-ref',\n                tmt.utils.git.default_branch(repository=self.testdir, logger=self._logger),\n            )\n            self.info('modified-ref', modified_ref, 'green')\n            ref_commit = self.run(\n                Command('git', 'rev-parse', '--short', str(modified_ref)),\n                cwd=self.testdir,\n            )\n            assert ref_commit.stdout is not None\n            self.verbose('modified-ref hash', ref_commit.stdout.strip(), 'green')\n            output = self.run(\n                Command(\n                    'git', 'log', '--format=', '--stat', '--name-only', f\"{modified_ref}..HEAD\"\n                ),\n                cwd=self.testdir,\n            )\n            if output.stdout:\n                directories = [Path(name).parent for name in output.stdout.split('\\n')]\n                modified = {\n                    f\"^/{re.escape(str(directory))}\" for directory in directories if directory\n                }\n                if not modified:\n                    # Nothing was modified, do not select anything\n                    return\n                self.debug(f\"Limit to modified test dirs: {modified}\", level=3)\n                names.extend(modified)\n            else:\n                self.debug(f\"No modified directories between '{modified_ref}..HEAD' found.\")\n                # Nothing was modified, do not select anything\n                return\n\n        # Initialize the metadata tree, search for available tests\n        self.debug(f\"Check metadata tree in '{tree_path}'.\")\n        if self.is_dry_run:\n            return\n        tree = tmt.Tree(\n            logger=self._logger,\n            path=tree_path,\n            fmf_context=self.step.plan._fmf_context,\n            additional_rules=self.data.adjust_tests,\n        )\n        self._tests = tree.tests(\n            filters=filters,\n            names=names,\n            conditions=[\"manual is False\"],\n            unique=False,\n            links=link_needles,\n            includes=includes,\n            excludes=excludes,\n        )\n\n        if prune:\n            # Save fmf metadata\n            clonedir = self.clone_dirpath / 'tests'\n            clone_tree_path = clonedir / path.unrooted()\n            for file_path in tmt.utils.filter_paths(tree_path, [r'\\.fmf']):\n                tmt.utils.filesystem.copy_tree(\n                    file_path,\n                    clone_tree_path / file_path.relative_to(tree_path),\n                    self._logger,\n                )\n\n            # Save upgrade plan\n            upgrade_path = self.get('upgrade_path')\n            if upgrade_path:\n                upgrade_path = f\"{upgrade_path.lstrip('/')}.fmf\"\n                (clone_tree_path / upgrade_path).parent.mkdir(parents=True, exist_ok=True)\n                shutil.copyfile(tree_path / upgrade_path, clone_tree_path / upgrade_path)\n                shutil.copymode(tree_path / upgrade_path, clone_tree_path / upgrade_path)\n\n        # Prefix tests and handle library requires\n        for test in self._tests:\n            # Propagate `where` key\n            test.where = cast(tmt.steps.discover.DiscoverStepData, self.data).where\n\n            if prune:\n                # Save only current test data\n                assert test.path is not None  # narrow type\n                relative_test_path = test.path.unrooted()\n                tmt.utils.filesystem.copy_tree(\n                    tree_path / relative_test_path,\n                    clone_tree_path / relative_test_path,\n                    self._logger,\n                )\n\n                # Copy all parent main.fmf files\n                parent_dir = relative_test_path\n                while parent_dir.resolve() != Path.cwd().resolve():\n                    parent_dir = parent_dir.parent\n                    if (tree_path / parent_dir / 'main.fmf').exists():\n                        # Ensure parent directory exists\n                        (clone_tree_path / parent_dir).mkdir(parents=True, exist_ok=True)\n                        shutil.copyfile(\n                            tree_path / parent_dir / 'main.fmf',\n                            clone_tree_path / parent_dir / 'main.fmf',\n                        )\n\n            # Prefix test path with 'tests' and possible 'path' prefix\n            assert test.path is not None  # narrow type\n            test.path = Path('/tests') / path.unrooted() / test.path.unrooted()\n            # Check for possible required beakerlib libraries\n            if test.require or test.recommend:\n                test.require, test.recommend, _ = tmt.libraries.dependencies(\n                    original_require=test.require,\n                    original_recommend=test.recommend,\n                    parent=self,\n                    logger=self._logger,\n                    source_location=self.testdir,\n                    target_location=clonedir if prune else self.testdir,\n                )\n\n        if prune:\n            # Clean self.testdir and copy back only required tests and files from clonedir\n            # This is to have correct paths in tests\n            shutil.rmtree(self.testdir, ignore_errors=True)\n            tmt.utils.filesystem.copy_tree(clonedir, self.testdir, self._logger)\n\n        # Cleanup clone directories\n        if self.clone_dirpath.exists():\n            shutil.rmtree(self.clone_dirpath, ignore_errors=True)\n\n    def post_dist_git(self, created_content: list[Path]) -&gt; None:\n        \"\"\"\n        Discover tests after dist-git applied patches\n        \"\"\"\n\n        # Directory to copy out from sources\n        dist_git_extract = self.get('dist-git-extract', None)\n        dist_git_init = self.get('dist-git-init', False)\n        dist_git_merge = self.get('dist-git-merge', False)\n        dist_git_remove_fmf_root = self.get('dist-git-remove-fmf-root', False)\n\n        assert self.workdir is not None  # narrow type\n        sourcedir = self.workdir / 'source'\n\n        # '/' means everything which was extracted from the srpm and do not flatten\n        # glob otherwise\n        if dist_git_extract and dist_git_extract != '/':\n            try:\n                dist_git_extract = Path(\n                    glob.glob(str(sourcedir / dist_git_extract.lstrip('/')))[0]\n                )\n            except IndexError:\n                raise tmt.utils.DiscoverError(\n                    f\"Couldn't glob '{dist_git_extract}' within extracted sources.\"\n                )\n        if dist_git_init:\n            if dist_git_extract == '/' or not dist_git_extract:\n                dist_git_extract = '/'\n                location = sourcedir\n            else:\n                location = dist_git_extract\n            # User specified location or 'root' of extracted sources\n            if not (Path(location) / '.fmf').is_dir() and not self.is_dry_run:\n                fmf.Tree.init(location)\n        elif dist_git_remove_fmf_root:\n            try:\n                extracted_fmf_root = tmt.utils.find_fmf_root(\n                    sourcedir,\n                    ignore_paths=[sourcedir],\n                )[0]\n            except tmt.utils.MetadataError:\n                self.warn(\"No fmf root to remove, there isn't one already.\")\n            if not self.is_dry_run:\n                shutil.rmtree((dist_git_extract or extracted_fmf_root) / '.fmf')\n        if not dist_git_extract:\n            try:\n                top_fmf_root = tmt.utils.find_fmf_root(sourcedir, ignore_paths=[sourcedir])[0]\n            except tmt.utils.MetadataError:\n                dist_git_extract = '/'  # Copy all extracted files as well (but later)\n                if not dist_git_merge:\n                    self.warn(\n                        \"Extracted sources do not contain fmf root, \"\n                        \"merging with plan data. Avoid this warning by \"\n                        \"explicit use of the '--dist-git-merge' option.\"\n                    )\n                    # FIXME - Deprecate this behavior?\n                    git_root = self.get_git_root(Path(self.step.plan.node.root))\n                    self.debug(f\"Copy '{git_root}' to '{self.testdir}'.\")\n                    if not self.is_dry_run:\n                        tmt.utils.filesystem.copy_tree(git_root, self.testdir, self._logger)\n\n        # Copy extracted sources into testdir\n        if not self.is_dry_run:\n            flatten = True\n            if dist_git_extract == '/':\n                flatten = False\n                copy_these = created_content\n            elif dist_git_extract:\n                copy_these = [dist_git_extract.relative_to(sourcedir)]\n            else:\n                copy_these = [top_fmf_root.relative_to(sourcedir)]\n            for to_copy in copy_these:\n                src = sourcedir / to_copy\n                if src.is_dir():\n                    tmt.utils.filesystem.copy_tree(\n                        sourcedir / to_copy,\n                        self.testdir if flatten else self.testdir / to_copy,\n                        self._logger,\n                    )\n                else:\n                    shutil.copyfile(src, self.testdir / to_copy)\n\n        # Discover tests\n        self.do_the_discovery()\n\n        # Add TMT_SOURCE_DIR variable for each test\n        for test in self._tests:\n            test.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n        # Apply tmt run policy\n        if self.step.plan.my_run is not None:\n            for policy in self.step.plan.my_run.policies:\n                policy.apply_to_tests(tests=self._tests, logger=self._logger)\n\n        # Inject newly found tests into parent discover at the right position\n        # FIXME\n        # Prefix test name only if multiple plugins configured\n        prefix = f'/{self.name}' if len(self.step.phases()) &gt; 1 else ''\n        # Check discovered tests, modify test name/path\n        for test_origin in self.tests(enabled=True):\n            test = test_origin.test\n\n            test.name = f\"{prefix}{test.name}\"\n            test.path = Path(f\"/{self.safe_name}{test.path}\")\n            # Update test environment with plan environment\n            test.environment.update(self.step.plan.environment)\n            self.step.plan.discover._tests[self.name].append(test)\n            test.serial_number = self.step.plan.draw_test_serial_number(test)\n        self.step.save()\n        self.step.summary()\n\n    def tests(\n        self, *, phase_name: Optional[str] = None, enabled: Optional[bool] = None\n    ) -&gt; list[tmt.steps.discover.TestOrigin]:\n        \"\"\"\n        Return all discovered tests\n        \"\"\"\n\n        if phase_name is not None and phase_name != self.name:\n            return []\n\n        if enabled is None:\n            return [\n                tmt.steps.discover.TestOrigin(test=test, phase=self.name) for test in self._tests\n            ]\n\n        return [\n            tmt.steps.discover.TestOrigin(test=test, phase=self.name)\n            for test in self._tests\n            if test.enabled is enabled\n        ]\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.is_in_standalone_mode","title":"<code>is_in_standalone_mode</code>  <code>property</code>","text":"<p>Enable standalone mode when listing fmf ids</p>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.do_the_discovery","title":"<code>do_the_discovery(path=None)</code>","text":"<p>Discover the tests</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def do_the_discovery(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"\n    Discover the tests\n    \"\"\"\n\n    # Original path might adjusted already in go()\n    if path is None:\n        path = Path(cast(str, self.get('path'))) if self.get('path') else None\n    prune = self.get('prune')\n    # Adjust path and optionally show\n    if path is None or path.resolve() == Path.cwd().resolve():\n        path = Path('')\n    else:\n        self.info('path', path, 'green')\n\n    # Prepare the whole tree path\n    tree_path = self.testdir / path.unrooted()\n    if not tree_path.is_dir() and not self.is_dry_run:\n        raise tmt.utils.DiscoverError(f\"Metadata tree path '{path}' not found.\")\n\n    # Show filters and test names if provided\n    # Check the 'test --filter' option first, then from discover\n    filters = list(tmt.base.Test._opt('filters') or self.get('filter', []))\n    for filter_ in filters:\n        self.info('filter', filter_, 'green')\n    # Names of tests selected by --test option\n    names = self.get('test', [])\n    if names:\n        self.info('tests', fmf.utils.listed(names), 'green')\n\n    # Check the 'test --link' option first, then from discover\n    # FIXME: cast() - typeless \"dispatcher\" method\n    raw_link_needles = cast(list[str], tmt.Test._opt('links', []) or self.get('link', []))\n    link_needles = [\n        tmt.base.LinkNeedle.from_spec(raw_needle) for raw_needle in raw_link_needles\n    ]\n\n    for link_needle in link_needles:\n        self.info('link', str(link_needle), 'green')\n\n    excludes = list(tmt.base.Test._opt('exclude') or self.data.exclude)\n    includes = list(tmt.base.Test._opt('include') or self.data.include)\n\n    # Filter only modified tests if requested\n    modified_only = self.get('modified-only')\n    modified_url = self.get('modified-url')\n    if modified_url:\n        previous = modified_url\n        modified_url = tmt.utils.git.clonable_git_url(modified_url)\n        self.info('modified-url', modified_url, 'green')\n        if previous != modified_url:\n            self.debug(f\"Original url was '{previous}'.\")\n        self.debug(f\"Fetch also '{modified_url}' as 'reference'.\")\n        self.run(\n            Command('git', 'remote', 'add', 'reference', modified_url),\n            cwd=self.testdir,\n        )\n        self.run(\n            Command('git', 'fetch', 'reference'),\n            cwd=self.testdir,\n        )\n    if modified_only:\n        modified_ref = self.get(\n            'modified-ref',\n            tmt.utils.git.default_branch(repository=self.testdir, logger=self._logger),\n        )\n        self.info('modified-ref', modified_ref, 'green')\n        ref_commit = self.run(\n            Command('git', 'rev-parse', '--short', str(modified_ref)),\n            cwd=self.testdir,\n        )\n        assert ref_commit.stdout is not None\n        self.verbose('modified-ref hash', ref_commit.stdout.strip(), 'green')\n        output = self.run(\n            Command(\n                'git', 'log', '--format=', '--stat', '--name-only', f\"{modified_ref}..HEAD\"\n            ),\n            cwd=self.testdir,\n        )\n        if output.stdout:\n            directories = [Path(name).parent for name in output.stdout.split('\\n')]\n            modified = {\n                f\"^/{re.escape(str(directory))}\" for directory in directories if directory\n            }\n            if not modified:\n                # Nothing was modified, do not select anything\n                return\n            self.debug(f\"Limit to modified test dirs: {modified}\", level=3)\n            names.extend(modified)\n        else:\n            self.debug(f\"No modified directories between '{modified_ref}..HEAD' found.\")\n            # Nothing was modified, do not select anything\n            return\n\n    # Initialize the metadata tree, search for available tests\n    self.debug(f\"Check metadata tree in '{tree_path}'.\")\n    if self.is_dry_run:\n        return\n    tree = tmt.Tree(\n        logger=self._logger,\n        path=tree_path,\n        fmf_context=self.step.plan._fmf_context,\n        additional_rules=self.data.adjust_tests,\n    )\n    self._tests = tree.tests(\n        filters=filters,\n        names=names,\n        conditions=[\"manual is False\"],\n        unique=False,\n        links=link_needles,\n        includes=includes,\n        excludes=excludes,\n    )\n\n    if prune:\n        # Save fmf metadata\n        clonedir = self.clone_dirpath / 'tests'\n        clone_tree_path = clonedir / path.unrooted()\n        for file_path in tmt.utils.filter_paths(tree_path, [r'\\.fmf']):\n            tmt.utils.filesystem.copy_tree(\n                file_path,\n                clone_tree_path / file_path.relative_to(tree_path),\n                self._logger,\n            )\n\n        # Save upgrade plan\n        upgrade_path = self.get('upgrade_path')\n        if upgrade_path:\n            upgrade_path = f\"{upgrade_path.lstrip('/')}.fmf\"\n            (clone_tree_path / upgrade_path).parent.mkdir(parents=True, exist_ok=True)\n            shutil.copyfile(tree_path / upgrade_path, clone_tree_path / upgrade_path)\n            shutil.copymode(tree_path / upgrade_path, clone_tree_path / upgrade_path)\n\n    # Prefix tests and handle library requires\n    for test in self._tests:\n        # Propagate `where` key\n        test.where = cast(tmt.steps.discover.DiscoverStepData, self.data).where\n\n        if prune:\n            # Save only current test data\n            assert test.path is not None  # narrow type\n            relative_test_path = test.path.unrooted()\n            tmt.utils.filesystem.copy_tree(\n                tree_path / relative_test_path,\n                clone_tree_path / relative_test_path,\n                self._logger,\n            )\n\n            # Copy all parent main.fmf files\n            parent_dir = relative_test_path\n            while parent_dir.resolve() != Path.cwd().resolve():\n                parent_dir = parent_dir.parent\n                if (tree_path / parent_dir / 'main.fmf').exists():\n                    # Ensure parent directory exists\n                    (clone_tree_path / parent_dir).mkdir(parents=True, exist_ok=True)\n                    shutil.copyfile(\n                        tree_path / parent_dir / 'main.fmf',\n                        clone_tree_path / parent_dir / 'main.fmf',\n                    )\n\n        # Prefix test path with 'tests' and possible 'path' prefix\n        assert test.path is not None  # narrow type\n        test.path = Path('/tests') / path.unrooted() / test.path.unrooted()\n        # Check for possible required beakerlib libraries\n        if test.require or test.recommend:\n            test.require, test.recommend, _ = tmt.libraries.dependencies(\n                original_require=test.require,\n                original_recommend=test.recommend,\n                parent=self,\n                logger=self._logger,\n                source_location=self.testdir,\n                target_location=clonedir if prune else self.testdir,\n            )\n\n    if prune:\n        # Clean self.testdir and copy back only required tests and files from clonedir\n        # This is to have correct paths in tests\n        shutil.rmtree(self.testdir, ignore_errors=True)\n        tmt.utils.filesystem.copy_tree(clonedir, self.testdir, self._logger)\n\n    # Cleanup clone directories\n    if self.clone_dirpath.exists():\n        shutil.rmtree(self.clone_dirpath, ignore_errors=True)\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.get_git_root","title":"<code>get_git_root(directory)</code>","text":"<p>Find git root of the path</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def get_git_root(self, directory: Path) -&gt; Path:\n    \"\"\"\n    Find git root of the path\n    \"\"\"\n\n    output = self.run(\n        Command(\"git\", \"rev-parse\", \"--show-toplevel\"),\n        cwd=directory,\n        ignore_dry=True,\n    )\n    assert output.stdout is not None\n    return Path(output.stdout.strip(\"\\n\"))\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.go","title":"<code>go(*, logger=None)</code>","text":"<p>Discover available tests</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Discover available tests\n    \"\"\"\n\n    super().go(logger=logger)\n\n    # Check url and path, prepare test directory\n    url = self.get('url')\n    # FIXME: cast() - typeless \"dispatcher\" method\n    path = Path(cast(str, self.get('path'))) if self.get('path') else None\n    # Save the test directory so that others can reference it\n    ref = self.get('ref')\n    assert self.workdir is not None\n    self.testdir = self.workdir / 'tests'\n    sourcedir = self.workdir / 'source'\n    dist_git_source = self.get('dist-git-source', False)\n    dist_git_merge = self.get('dist-git-merge', False)\n\n    # No tests are selected in some cases\n    self._tests: list[tmt.Test] = []\n\n    # Self checks\n    if dist_git_source and not dist_git_merge and (ref or url):\n        raise tmt.utils.DiscoverError(\n            \"Cannot manipulate with dist-git without the `--dist-git-merge` option.\"\n        )\n\n    self.log_import_plan_details()\n\n    # Clone provided git repository (if url given) with disabled\n    # prompt to ignore possibly missing or private repositories\n    if url:\n        self.info('url', url, 'green')\n        self.debug(f\"Clone '{url}' to '{self.testdir}'.\")\n        # Shallow clone to speed up testing and\n        # minimize data transfers if ref is not provided\n        tmt.utils.git.git_clone(\n            url=url,\n            destination=self.testdir,\n            shallow=ref is None,\n            env=Environment({\"GIT_ASKPASS\": EnvVarValue(\"echo\")}),\n            logger=self._logger,\n        )\n        git_root = self.testdir\n    # Copy git repository root to workdir\n    else:\n        if path is not None:\n            fmf_root: Optional[Path] = path\n        else:\n            fmf_root = Path(self.step.plan.fmf_root) if self.step.plan.fmf_root else None\n        requires_git = self.opt('sync-repo') or any(\n            self.get(opt) for opt in self._REQUIRES_GIT\n        )\n        # Path for distgit sources cannot be checked until the\n        # they are extracted\n        if path and not path.is_dir() and not dist_git_source:\n            raise tmt.utils.DiscoverError(f\"Provided path '{path}' is not a directory.\")\n        if dist_git_source:\n            # Ensure we're in a git repo when extracting dist-git sources\n            try:\n                git_root = self.get_git_root(Path(self.step.plan.node.root))\n            except tmt.utils.RunError:\n                assert self.step.plan.my_run is not None  # narrow type\n                assert self.step.plan.my_run.tree is not None  # narrow type\n                raise tmt.utils.DiscoverError(f\"{self.step.plan.node.root} is not a git repo\")\n        else:\n            if fmf_root is None:\n                raise tmt.utils.DiscoverError(\"No metadata found in the current directory.\")\n            # Check git repository root (use fmf root if not found)\n            try:\n                git_root = self.get_git_root(fmf_root)\n            except tmt.utils.RunError:\n                self.debug(f\"Git root not found, using '{fmf_root}.'\")\n                git_root = fmf_root\n            # Set path to relative path from the git root to fmf root\n            path = fmf_root.resolve().relative_to(\n                git_root.resolve() if requires_git else fmf_root.resolve()\n            )\n\n        # And finally copy the git/fmf root directory to testdir\n        # (for dist-git case only when merge explicitly requested)\n        if requires_git:\n            directory: Path = git_root\n        else:\n            assert fmf_root is not None  # narrow type\n            directory = fmf_root\n        self.info('directory', directory, 'green')\n        if not dist_git_source or dist_git_merge:\n            self.debug(f\"Copy '{directory}' to '{self.testdir}'.\")\n            if not self.is_dry_run:\n                tmt.utils.filesystem.copy_tree(directory, self.testdir, self._logger)\n\n    # Prepare path of the dynamic reference\n    try:\n        ref = tmt.base.resolve_dynamic_ref(\n            logger=self._logger,\n            workdir=self.testdir,\n            ref=ref,\n            plan=self.step.plan,\n        )\n    except tmt.utils.FileError as error:\n        raise tmt.utils.DiscoverError(str(error))\n\n    # Checkout revision if requested\n    if ref:\n        self.info('ref', ref, 'green')\n        self.debug(f\"Checkout ref '{ref}'.\")\n        self.run(Command('git', 'checkout', '-f', ref), cwd=self.testdir)\n\n    # Show current commit hash if inside a git repository\n    if self.testdir.is_dir():\n        with contextlib.suppress(tmt.utils.RunError, AttributeError):\n            self.verbose(\n                'hash',\n                tmt.utils.git.git_hash(directory=self.testdir, logger=self._logger),\n                'green',\n            )\n\n    # Dist-git source processing during discover step\n    if dist_git_source:\n        try:\n            distgit_dir = self.testdir if ref else git_root\n            self.process_distgit_source(distgit_dir, sourcedir)\n            return\n        except Exception as error:\n            raise tmt.utils.DiscoverError(\"Failed to process 'dist-git-source'.\") from error\n\n    # Discover tests\n    self.do_the_discovery(path)\n\n    # Apply tmt run policy\n    if self.step.plan.my_run is not None:\n        for policy in self.step.plan.my_run.policies:\n            policy.apply_to_tests(tests=self._tests, logger=self._logger)\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.post_dist_git","title":"<code>post_dist_git(created_content)</code>","text":"<p>Discover tests after dist-git applied patches</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def post_dist_git(self, created_content: list[Path]) -&gt; None:\n    \"\"\"\n    Discover tests after dist-git applied patches\n    \"\"\"\n\n    # Directory to copy out from sources\n    dist_git_extract = self.get('dist-git-extract', None)\n    dist_git_init = self.get('dist-git-init', False)\n    dist_git_merge = self.get('dist-git-merge', False)\n    dist_git_remove_fmf_root = self.get('dist-git-remove-fmf-root', False)\n\n    assert self.workdir is not None  # narrow type\n    sourcedir = self.workdir / 'source'\n\n    # '/' means everything which was extracted from the srpm and do not flatten\n    # glob otherwise\n    if dist_git_extract and dist_git_extract != '/':\n        try:\n            dist_git_extract = Path(\n                glob.glob(str(sourcedir / dist_git_extract.lstrip('/')))[0]\n            )\n        except IndexError:\n            raise tmt.utils.DiscoverError(\n                f\"Couldn't glob '{dist_git_extract}' within extracted sources.\"\n            )\n    if dist_git_init:\n        if dist_git_extract == '/' or not dist_git_extract:\n            dist_git_extract = '/'\n            location = sourcedir\n        else:\n            location = dist_git_extract\n        # User specified location or 'root' of extracted sources\n        if not (Path(location) / '.fmf').is_dir() and not self.is_dry_run:\n            fmf.Tree.init(location)\n    elif dist_git_remove_fmf_root:\n        try:\n            extracted_fmf_root = tmt.utils.find_fmf_root(\n                sourcedir,\n                ignore_paths=[sourcedir],\n            )[0]\n        except tmt.utils.MetadataError:\n            self.warn(\"No fmf root to remove, there isn't one already.\")\n        if not self.is_dry_run:\n            shutil.rmtree((dist_git_extract or extracted_fmf_root) / '.fmf')\n    if not dist_git_extract:\n        try:\n            top_fmf_root = tmt.utils.find_fmf_root(sourcedir, ignore_paths=[sourcedir])[0]\n        except tmt.utils.MetadataError:\n            dist_git_extract = '/'  # Copy all extracted files as well (but later)\n            if not dist_git_merge:\n                self.warn(\n                    \"Extracted sources do not contain fmf root, \"\n                    \"merging with plan data. Avoid this warning by \"\n                    \"explicit use of the '--dist-git-merge' option.\"\n                )\n                # FIXME - Deprecate this behavior?\n                git_root = self.get_git_root(Path(self.step.plan.node.root))\n                self.debug(f\"Copy '{git_root}' to '{self.testdir}'.\")\n                if not self.is_dry_run:\n                    tmt.utils.filesystem.copy_tree(git_root, self.testdir, self._logger)\n\n    # Copy extracted sources into testdir\n    if not self.is_dry_run:\n        flatten = True\n        if dist_git_extract == '/':\n            flatten = False\n            copy_these = created_content\n        elif dist_git_extract:\n            copy_these = [dist_git_extract.relative_to(sourcedir)]\n        else:\n            copy_these = [top_fmf_root.relative_to(sourcedir)]\n        for to_copy in copy_these:\n            src = sourcedir / to_copy\n            if src.is_dir():\n                tmt.utils.filesystem.copy_tree(\n                    sourcedir / to_copy,\n                    self.testdir if flatten else self.testdir / to_copy,\n                    self._logger,\n                )\n            else:\n                shutil.copyfile(src, self.testdir / to_copy)\n\n    # Discover tests\n    self.do_the_discovery()\n\n    # Add TMT_SOURCE_DIR variable for each test\n    for test in self._tests:\n        test.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n    # Apply tmt run policy\n    if self.step.plan.my_run is not None:\n        for policy in self.step.plan.my_run.policies:\n            policy.apply_to_tests(tests=self._tests, logger=self._logger)\n\n    # Inject newly found tests into parent discover at the right position\n    # FIXME\n    # Prefix test name only if multiple plugins configured\n    prefix = f'/{self.name}' if len(self.step.phases()) &gt; 1 else ''\n    # Check discovered tests, modify test name/path\n    for test_origin in self.tests(enabled=True):\n        test = test_origin.test\n\n        test.name = f\"{prefix}{test.name}\"\n        test.path = Path(f\"/{self.safe_name}{test.path}\")\n        # Update test environment with plan environment\n        test.environment.update(self.step.plan.environment)\n        self.step.plan.discover._tests[self.name].append(test)\n        test.serial_number = self.step.plan.draw_test_serial_number(test)\n    self.step.save()\n    self.step.summary()\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.process_distgit_source","title":"<code>process_distgit_source(distgit_dir, sourcedir)</code>","text":"<p>Process dist-git source during the discover step.</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def process_distgit_source(self, distgit_dir: Path, sourcedir: Path) -&gt; None:\n    \"\"\"\n    Process dist-git source during the discover step.\n    \"\"\"\n\n    self.download_distgit_source(\n        distgit_dir=distgit_dir,\n        target_dir=sourcedir,\n        handler_name=self.get('dist-git-type'),\n    )\n\n    # Copy rest of files so TMT_SOURCE_DIR has patches, sources and spec file\n    # FIXME 'worktree' could be used as sourcedir when 'url' is not set\n    tmt.utils.filesystem.copy_tree(\n        distgit_dir,\n        sourcedir,\n        self._logger,\n    )\n\n    # patch &amp; rediscover will happen later in the prepare step\n    if not self.get('dist-git-download-only'):\n        # Check if prepare is enabled, warn user if not\n        if not self.step.plan.prepare.enabled:\n            self.warn(\"Sources will not be extracted, prepare step is not enabled.\")\n\n        insert_to_prepare_step(\n            discover_plugin=self,\n            sourcedir=sourcedir,\n        )\n\n    # merge or not, detect later\n    self.step.plan.discover.extract_tests_later = True\n    self.info(\"Tests will be discovered after dist-git patching in prepare.\")\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.fmf.DiscoverFmf.tests","title":"<code>tests(*, phase_name=None, enabled=None)</code>","text":"<p>Return all discovered tests</p> Source code in <code>tmt/steps/discover/fmf.py</code> <pre><code>def tests(\n    self, *, phase_name: Optional[str] = None, enabled: Optional[bool] = None\n) -&gt; list[tmt.steps.discover.TestOrigin]:\n    \"\"\"\n    Return all discovered tests\n    \"\"\"\n\n    if phase_name is not None and phase_name != self.name:\n        return []\n\n    if enabled is None:\n        return [\n            tmt.steps.discover.TestOrigin(test=test, phase=self.name) for test in self._tests\n        ]\n\n    return [\n        tmt.steps.discover.TestOrigin(test=test, phase=self.name)\n        for test in self._tests\n        if test.enabled is enabled\n    ]\n</code></pre>"},{"location":"plugins/discover/#shell","title":"shell","text":""},{"location":"plugins/discover/#tmt.steps.discover.shell.DiscoverShell","title":"<code>tmt.steps.discover.shell.DiscoverShell</code>","text":"<p>               Bases: <code>DiscoverPlugin[DiscoverShellData]</code></p> <p>Use provided list of shell script tests.</p> <p>List of test cases to be executed can be defined manually directly in the plan as a list of dictionaries containing test <code>name</code> and actual <code>test</code> script. It is also possible to define here any other test metadata such as the <code>duration</code> or a <code>path</code> to the test. The default duration for tests defined directly in the discover step is <code>1h</code>.</p> <p>Example config:</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: shell\n    tests:\n      - name: /help/main\n        test: tmt --help\n      - name: /help/test\n        test: tmt test --help\n      - name: /help/smoke\n        test: ./smoke.sh\n        path: /tests/shell\n</code></pre> <p>For DistGit repo one can download sources and use code from them in the tests. Sources are extracted into <code>$TMT_SOURCE_DIR</code> path, patches are applied by default. See options to install build dependencies or to just download sources without applying patches. To apply patches, special <code>prepare</code> phase with order <code>60</code> is added, and <code>prepare</code> step has to be enabled for it to run.</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: shell\n    dist-git-source: true\n    tests:\n      - name: /upstream\n        test: cd $TMT_SOURCE_DIR/*/tests &amp;&amp; make test\n</code></pre> <p>To clone a remote repository and use it as a source specify <code>url</code>. It accepts also <code>ref</code> to checkout provided reference. Dynamic reference feature is supported as well.</p> <p>.. code-block:: yaml</p> <pre><code>discover:\n    how: shell\n    url: https://github.com/teemtee/tmt.git\n    ref: \"1.18.0\"\n    tests:\n      - name: first test\n        test: ./script-from-the-repo.sh\n</code></pre> Source code in <code>tmt/steps/discover/shell.py</code> <pre><code>@tmt.steps.provides_method('shell')\nclass DiscoverShell(tmt.steps.discover.DiscoverPlugin[DiscoverShellData]):\n    \"\"\"\n    Use provided list of shell script tests.\n\n    List of test cases to be executed can be defined manually directly\n    in the plan as a list of dictionaries containing test ``name`` and\n    actual ``test`` script. It is also possible to define here any other\n    test metadata such as the ``duration`` or a ``path`` to the test.\n    The default duration for tests defined directly in the discover step\n    is ``1h``.\n\n    Example config:\n\n    .. code-block:: yaml\n\n        discover:\n            how: shell\n            tests:\n              - name: /help/main\n                test: tmt --help\n              - name: /help/test\n                test: tmt test --help\n              - name: /help/smoke\n                test: ./smoke.sh\n                path: /tests/shell\n\n    For DistGit repo one can download sources and use code from them in\n    the tests. Sources are extracted into ``$TMT_SOURCE_DIR`` path,\n    patches are applied by default. See options to install build\n    dependencies or to just download sources without applying patches.\n    To apply patches, special ``prepare`` phase with order ``60`` is\n    added, and ``prepare`` step has to be enabled for it to run.\n\n    .. code-block:: yaml\n\n        discover:\n            how: shell\n            dist-git-source: true\n            tests:\n              - name: /upstream\n                test: cd $TMT_SOURCE_DIR/*/tests &amp;&amp; make test\n\n    To clone a remote repository and use it as a source specify ``url``.\n    It accepts also ``ref`` to checkout provided reference. Dynamic\n    reference feature is supported as well.\n\n    .. code-block:: yaml\n\n        discover:\n            how: shell\n            url: https://github.com/teemtee/tmt.git\n            ref: \"1.18.0\"\n            tests:\n              - name: first test\n                test: ./script-from-the-repo.sh\n    \"\"\"\n\n    _data_class = DiscoverShellData\n\n    _tests: list[tmt.base.Test] = []\n\n    def show(self, keys: Optional[list[str]] = None) -&gt; None:\n        \"\"\"\n        Show config details\n        \"\"\"\n\n        super().show([])\n\n        if self.data.tests:\n            click.echo(tmt.utils.format('tests', [test.name for test in self.data.tests]))\n\n    def fetch_remote_repository(\n        self,\n        url: Optional[str],\n        ref: Optional[str],\n        testdir: Path,\n        keep_git_metadata: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Fetch remote git repo from given url to testdir\n        \"\"\"\n\n        # Nothing to do if no url provided\n        if not url:\n            return\n\n        # Clone first - it might clone dist git\n        self.info('url', url, 'green')\n        tmt.utils.git.git_clone(\n            url=url,\n            destination=testdir,\n            shallow=ref is None,\n            env=Environment({\"GIT_ASKPASS\": EnvVarValue(\"echo\")}),\n            logger=self._logger,\n        )\n\n        # Resolve possible dynamic references\n        try:\n            ref = tmt.base.resolve_dynamic_ref(\n                logger=self._logger, workdir=testdir, ref=ref, plan=self.step.plan\n            )\n        except tmt.utils.FileError as error:\n            raise tmt.utils.DiscoverError(str(error))\n\n        # Checkout revision if requested\n        if ref:\n            self.info('ref', ref, 'green')\n            self.debug(f\"Checkout ref '{ref}'.\")\n            self.run(Command('git', 'checkout', '-f', ref), cwd=testdir)\n\n        # Log where HEAD leads to\n        self.debug('hash', tmt.utils.git.git_hash(directory=testdir, logger=self._logger))\n\n        # Remove .git so that it's not copied to the SUT\n        # if 'keep-git-metadata' option is not specified\n        if not keep_git_metadata:\n            shutil.rmtree(testdir / '.git')\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Discover available tests\n        \"\"\"\n\n        super().go(logger=logger)\n        tests = fmf.Tree({'summary': 'tests'})\n\n        assert self.workdir is not None\n        testdir = self.workdir / \"tests\"\n\n        self.log_import_plan_details()\n\n        # dist-git related\n        sourcedir = self.workdir / 'source'\n\n        # Fetch remote repository related\n\n        # Git metadata are necessary for dist_git_source\n        keep_git_metadata = True if self.data.dist_git_source else self.data.keep_git_metadata\n\n        if self.data.url:\n            self.fetch_remote_repository(self.data.url, self.data.ref, testdir, keep_git_metadata)\n        else:\n            # Symlink tests directory to the plan work tree\n            assert self.step.plan.worktree  # narrow type\n\n            relative_path = self.step.plan.worktree.relative_to(self.workdir)\n            testdir.symlink_to(relative_path)\n\n            if keep_git_metadata:\n                # Copy .git which is excluded when worktree is initialized\n                tree_root = Path(self.step.plan.node.root)\n                # If exists, git_root can be only the same or parent of fmf_root\n                git_root = tmt.utils.git.git_root(fmf_root=tree_root, logger=self._logger)\n                if git_root:\n                    if git_root != tree_root:\n                        raise tmt.utils.DiscoverError(\n                            \"The 'keep-git-metadata' option can be \"\n                            \"used only when fmf root is the same as git root.\"\n                        )\n                    self.run(Command(\"rsync\", \"-ar\", f\"{git_root}/.git\", testdir))\n\n        # Check and process each defined shell test\n        for data in self.data.tests:\n            # Create data copy (we want to keep original data for save()\n            data = copy.deepcopy(data)\n            # Extract name, make sure it is present\n            # TODO: can this ever happen? With annotations, `name: str` and `test: str`, nothing\n            # should ever assign `None` there and pass the test.\n            if not data.name:\n                raise tmt.utils.SpecificationError(\n                    f\"Missing test name in '{self.step.plan.name}'.\"\n                )\n            # Make sure that the test script is defined\n            if not data.test:\n                raise tmt.utils.SpecificationError(\n                    f\"Missing test script in '{self.step.plan.name}'.\"\n                )\n            # Prepare path to the test working directory (tree root by default)\n            data.path = f\"/tests{data.path}\" if data.path else '/tests'\n            # Apply default test duration unless provided\n            if not data.duration:\n                data.duration = tmt.base.DEFAULT_TEST_DURATION_L2\n            # Add source dir path variable\n            if self.data.dist_git_source:\n                data.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n            # Create a simple fmf node, with correct name. Emit only keys and values\n            # that are no longer default. Do not add `name` itself into the node,\n            # it's not a supported test key, and it's given to the node itself anyway.\n            # Note the exception for `duration` key - it's expected in the output\n            # even if it still has its default value.\n            test_fmf_keys: dict[str, Any] = {\n                key: value\n                for key, value in data.to_spec().items()\n                if key != 'name' and (key == 'duration' or value != data.default(key))\n            }\n            tests.child(data.name, test_fmf_keys)\n\n        if self.data.dist_git_source:\n            assert self.step.plan.my_run is not None  # narrow type\n            assert self.step.plan.my_run.tree is not None  # narrow type\n            assert self.step.plan.my_run.tree.root is not None  # narrow type\n            try:\n                run_result = self.run(\n                    Command(\"git\", \"rev-parse\", \"--show-toplevel\"),\n                    cwd=testdir if self.data.url else self.step.plan.my_run.tree.root,\n                    ignore_dry=True,\n                )\n                assert run_result.stdout is not None\n                git_root = Path(run_result.stdout.strip('\\n'))\n            except tmt.utils.RunError:\n                assert self.step.plan.my_run is not None  # narrow type\n                assert self.step.plan.my_run.tree is not None  # narrow type\n                raise tmt.utils.DiscoverError(\n                    f\"Directory '{self.step.plan.my_run.tree.root}' is not a git repository.\"\n                )\n            try:\n                self.download_distgit_source(\n                    distgit_dir=git_root,\n                    target_dir=sourcedir,\n                    handler_name=self.data.dist_git_type,\n                )\n                # Copy rest of files so TMT_SOURCE_DIR has patches, sources and spec file\n                # FIXME 'worktree' could be used as sourcedir when 'url' is not set\n                shutil.copytree(git_root, sourcedir, symlinks=True, dirs_exist_ok=True)\n\n                if self.data.dist_git_download_only:\n                    self.debug(\"Do not extract sources as 'download_only' is set.\")\n                else:\n                    # Check if prepare is enabled, warn user if not\n                    if not self.step.plan.prepare.enabled:\n                        self.warn(\"Sources will not be extracted, prepare step is not enabled.\")\n                    insert_to_prepare_step(\n                        discover_plugin=self,\n                        sourcedir=sourcedir,\n                    )\n\n            except Exception as error:\n                raise tmt.utils.DiscoverError(\"Failed to process 'dist-git-source'.\") from error\n\n        # Use a tmt.Tree to apply possible command line filters\n        self._tests = tmt.Tree(logger=self._logger, tree=tests).tests(\n            conditions=[\"manual is False\"], sort=False\n        )\n\n        # Propagate `where` key and TMT_SOURCE_DIR\n        for test in self._tests:\n            test.where = cast(tmt.steps.discover.DiscoverStepData, self.data).where\n            if self.data.dist_git_source:\n                test.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n        # Apply tmt run policy\n        if self.step.plan.my_run is not None:\n            for policy in self.step.plan.my_run.policies:\n                policy.apply_to_tests(tests=self._tests, logger=self._logger)\n\n    def tests(\n        self, *, phase_name: Optional[str] = None, enabled: Optional[bool] = None\n    ) -&gt; list[tmt.steps.discover.TestOrigin]:\n        if phase_name is not None and phase_name != self.name:\n            return []\n\n        if enabled is None:\n            return [\n                tmt.steps.discover.TestOrigin(test=test, phase=self.name) for test in self._tests\n            ]\n\n        return [\n            tmt.steps.discover.TestOrigin(test=test, phase=self.name)\n            for test in self._tests\n            if test.enabled is enabled\n        ]\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.shell.DiscoverShell.fetch_remote_repository","title":"<code>fetch_remote_repository(url, ref, testdir, keep_git_metadata=False)</code>","text":"<p>Fetch remote git repo from given url to testdir</p> Source code in <code>tmt/steps/discover/shell.py</code> <pre><code>def fetch_remote_repository(\n    self,\n    url: Optional[str],\n    ref: Optional[str],\n    testdir: Path,\n    keep_git_metadata: bool = False,\n) -&gt; None:\n    \"\"\"\n    Fetch remote git repo from given url to testdir\n    \"\"\"\n\n    # Nothing to do if no url provided\n    if not url:\n        return\n\n    # Clone first - it might clone dist git\n    self.info('url', url, 'green')\n    tmt.utils.git.git_clone(\n        url=url,\n        destination=testdir,\n        shallow=ref is None,\n        env=Environment({\"GIT_ASKPASS\": EnvVarValue(\"echo\")}),\n        logger=self._logger,\n    )\n\n    # Resolve possible dynamic references\n    try:\n        ref = tmt.base.resolve_dynamic_ref(\n            logger=self._logger, workdir=testdir, ref=ref, plan=self.step.plan\n        )\n    except tmt.utils.FileError as error:\n        raise tmt.utils.DiscoverError(str(error))\n\n    # Checkout revision if requested\n    if ref:\n        self.info('ref', ref, 'green')\n        self.debug(f\"Checkout ref '{ref}'.\")\n        self.run(Command('git', 'checkout', '-f', ref), cwd=testdir)\n\n    # Log where HEAD leads to\n    self.debug('hash', tmt.utils.git.git_hash(directory=testdir, logger=self._logger))\n\n    # Remove .git so that it's not copied to the SUT\n    # if 'keep-git-metadata' option is not specified\n    if not keep_git_metadata:\n        shutil.rmtree(testdir / '.git')\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.shell.DiscoverShell.go","title":"<code>go(*, logger=None)</code>","text":"<p>Discover available tests</p> Source code in <code>tmt/steps/discover/shell.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Discover available tests\n    \"\"\"\n\n    super().go(logger=logger)\n    tests = fmf.Tree({'summary': 'tests'})\n\n    assert self.workdir is not None\n    testdir = self.workdir / \"tests\"\n\n    self.log_import_plan_details()\n\n    # dist-git related\n    sourcedir = self.workdir / 'source'\n\n    # Fetch remote repository related\n\n    # Git metadata are necessary for dist_git_source\n    keep_git_metadata = True if self.data.dist_git_source else self.data.keep_git_metadata\n\n    if self.data.url:\n        self.fetch_remote_repository(self.data.url, self.data.ref, testdir, keep_git_metadata)\n    else:\n        # Symlink tests directory to the plan work tree\n        assert self.step.plan.worktree  # narrow type\n\n        relative_path = self.step.plan.worktree.relative_to(self.workdir)\n        testdir.symlink_to(relative_path)\n\n        if keep_git_metadata:\n            # Copy .git which is excluded when worktree is initialized\n            tree_root = Path(self.step.plan.node.root)\n            # If exists, git_root can be only the same or parent of fmf_root\n            git_root = tmt.utils.git.git_root(fmf_root=tree_root, logger=self._logger)\n            if git_root:\n                if git_root != tree_root:\n                    raise tmt.utils.DiscoverError(\n                        \"The 'keep-git-metadata' option can be \"\n                        \"used only when fmf root is the same as git root.\"\n                    )\n                self.run(Command(\"rsync\", \"-ar\", f\"{git_root}/.git\", testdir))\n\n    # Check and process each defined shell test\n    for data in self.data.tests:\n        # Create data copy (we want to keep original data for save()\n        data = copy.deepcopy(data)\n        # Extract name, make sure it is present\n        # TODO: can this ever happen? With annotations, `name: str` and `test: str`, nothing\n        # should ever assign `None` there and pass the test.\n        if not data.name:\n            raise tmt.utils.SpecificationError(\n                f\"Missing test name in '{self.step.plan.name}'.\"\n            )\n        # Make sure that the test script is defined\n        if not data.test:\n            raise tmt.utils.SpecificationError(\n                f\"Missing test script in '{self.step.plan.name}'.\"\n            )\n        # Prepare path to the test working directory (tree root by default)\n        data.path = f\"/tests{data.path}\" if data.path else '/tests'\n        # Apply default test duration unless provided\n        if not data.duration:\n            data.duration = tmt.base.DEFAULT_TEST_DURATION_L2\n        # Add source dir path variable\n        if self.data.dist_git_source:\n            data.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n        # Create a simple fmf node, with correct name. Emit only keys and values\n        # that are no longer default. Do not add `name` itself into the node,\n        # it's not a supported test key, and it's given to the node itself anyway.\n        # Note the exception for `duration` key - it's expected in the output\n        # even if it still has its default value.\n        test_fmf_keys: dict[str, Any] = {\n            key: value\n            for key, value in data.to_spec().items()\n            if key != 'name' and (key == 'duration' or value != data.default(key))\n        }\n        tests.child(data.name, test_fmf_keys)\n\n    if self.data.dist_git_source:\n        assert self.step.plan.my_run is not None  # narrow type\n        assert self.step.plan.my_run.tree is not None  # narrow type\n        assert self.step.plan.my_run.tree.root is not None  # narrow type\n        try:\n            run_result = self.run(\n                Command(\"git\", \"rev-parse\", \"--show-toplevel\"),\n                cwd=testdir if self.data.url else self.step.plan.my_run.tree.root,\n                ignore_dry=True,\n            )\n            assert run_result.stdout is not None\n            git_root = Path(run_result.stdout.strip('\\n'))\n        except tmt.utils.RunError:\n            assert self.step.plan.my_run is not None  # narrow type\n            assert self.step.plan.my_run.tree is not None  # narrow type\n            raise tmt.utils.DiscoverError(\n                f\"Directory '{self.step.plan.my_run.tree.root}' is not a git repository.\"\n            )\n        try:\n            self.download_distgit_source(\n                distgit_dir=git_root,\n                target_dir=sourcedir,\n                handler_name=self.data.dist_git_type,\n            )\n            # Copy rest of files so TMT_SOURCE_DIR has patches, sources and spec file\n            # FIXME 'worktree' could be used as sourcedir when 'url' is not set\n            shutil.copytree(git_root, sourcedir, symlinks=True, dirs_exist_ok=True)\n\n            if self.data.dist_git_download_only:\n                self.debug(\"Do not extract sources as 'download_only' is set.\")\n            else:\n                # Check if prepare is enabled, warn user if not\n                if not self.step.plan.prepare.enabled:\n                    self.warn(\"Sources will not be extracted, prepare step is not enabled.\")\n                insert_to_prepare_step(\n                    discover_plugin=self,\n                    sourcedir=sourcedir,\n                )\n\n        except Exception as error:\n            raise tmt.utils.DiscoverError(\"Failed to process 'dist-git-source'.\") from error\n\n    # Use a tmt.Tree to apply possible command line filters\n    self._tests = tmt.Tree(logger=self._logger, tree=tests).tests(\n        conditions=[\"manual is False\"], sort=False\n    )\n\n    # Propagate `where` key and TMT_SOURCE_DIR\n    for test in self._tests:\n        test.where = cast(tmt.steps.discover.DiscoverStepData, self.data).where\n        if self.data.dist_git_source:\n            test.environment['TMT_SOURCE_DIR'] = EnvVarValue(sourcedir)\n\n    # Apply tmt run policy\n    if self.step.plan.my_run is not None:\n        for policy in self.step.plan.my_run.policies:\n            policy.apply_to_tests(tests=self._tests, logger=self._logger)\n</code></pre>"},{"location":"plugins/discover/#tmt.steps.discover.shell.DiscoverShell.show","title":"<code>show(keys=None)</code>","text":"<p>Show config details</p> Source code in <code>tmt/steps/discover/shell.py</code> <pre><code>def show(self, keys: Optional[list[str]] = None) -&gt; None:\n    \"\"\"\n    Show config details\n    \"\"\"\n\n    super().show([])\n\n    if self.data.tests:\n        click.echo(tmt.utils.format('tests', [test.name for test in self.data.tests]))\n</code></pre>"},{"location":"plugins/execute/","title":"Execute","text":"<p>Run tests using the specified executor.</p>"},{"location":"plugins/execute/#tmt","title":"tmt","text":""},{"location":"plugins/execute/#tmt.steps.execute.internal.ExecuteInternal","title":"<code>tmt.steps.execute.internal.ExecuteInternal</code>","text":"<p>               Bases: <code>ExecutePlugin[ExecuteInternalData]</code></p> <p>Use the internal tmt executor to execute tests.</p> <p>The internal tmt executor runs tests on the guest one by one directly from the tmt code which shows testing :ref:<code>/stories/cli/steps/execute/progress</code> and supports :ref:<code>/stories/cli/steps/execute/interactive</code> debugging as well. This is the default execute step implementation. Test result is based on the script exit code (for shell tests) or the results file (for beakerlib tests).</p> <p>The executor provides the following shell scripts which can be used by the tests for certain operations.</p> <p><code>tmt-file-submit</code> - archive the given file in the tmt test data directory. See the :ref:<code>/stories/features/report-log</code> section for more details.</p> <p><code>tmt-reboot</code> - soft reboot the machine from inside the test. After reboot the execution starts from the test which rebooted the machine. An environment variable <code>TMT_REBOOT_COUNT</code> is provided which the test can use to handle the reboot. The variable holds the number of reboots performed by the test. For more information see the :ref:<code>/stories/features/reboot</code> feature documentation.</p> <p><code>tmt-report-result</code> - generate a result report file from inside the test. Can be called multiple times by the test. The generated report file will be overwritten if a higher hierarchical result is reported by the test. The hierarchy is as follows: SKIP, PASS, WARN, FAIL. For more information see the :ref:<code>/stories/features/report-result</code> feature documentation.</p> <p><code>tmt-abort</code> - generate an abort file from inside the test. This will set the current test result to failed and terminate the execution of subsequent tests. For more information see the :ref:<code>/stories/features/abort</code> feature documentation.</p> <p>The scripts are hosted by default in the <code>/usr/local/bin</code> directory, except for guests using <code>rpm-ostree</code>, where <code>/var/lib/tmt/scripts</code> is used. The directory can be forced using the <code>TMT_SCRIPTS_DIR</code> environment variable. Note that for guests using <code>rpm-ostree</code>, the directory is added to executable paths using the system-wide <code>/etc/profile.d/tmt.sh</code> profile script.</p> <p>.. warning::</p> <pre><code>Please be aware that for guests using ``rpm-ostree``\nthe provided scripts will only be available in a shell that\nloads the profile scripts. This is the default for\n``bash``-like shells, but might not work for others.\n</code></pre> Source code in <code>tmt/steps/execute/internal.py</code> <pre><code>@tmt.steps.provides_method('tmt')\nclass ExecuteInternal(tmt.steps.execute.ExecutePlugin[ExecuteInternalData]):\n    \"\"\"\n    Use the internal tmt executor to execute tests.\n\n    The internal tmt executor runs tests on the guest one by one directly\n    from the tmt code which shows testing :ref:`/stories/cli/steps/execute/progress`\n    and supports :ref:`/stories/cli/steps/execute/interactive` debugging as well.\n    This is the default execute step implementation. Test result is based on the\n    script exit code (for shell tests) or the results file (for beakerlib tests).\n\n    The executor provides the following shell scripts which can be used by the tests\n    for certain operations.\n\n    ``tmt-file-submit`` - archive the given file in the tmt test data directory.\n    See the :ref:`/stories/features/report-log` section for more details.\n\n    ``tmt-reboot`` - soft reboot the machine from inside the test. After reboot\n    the execution starts from the test which rebooted the machine.\n    An environment variable ``TMT_REBOOT_COUNT`` is provided which\n    the test can use to handle the reboot. The variable holds the\n    number of reboots performed by the test. For more information\n    see the :ref:`/stories/features/reboot` feature documentation.\n\n    ``tmt-report-result`` - generate a result report file from inside the test.\n    Can be called multiple times by the test. The generated report\n    file will be overwritten if a higher hierarchical result is\n    reported by the test. The hierarchy is as follows:\n    SKIP, PASS, WARN, FAIL. For more information see the\n    :ref:`/stories/features/report-result` feature documentation.\n\n    ``tmt-abort`` - generate an abort file from inside the test. This will\n    set the current test result to failed and terminate\n    the execution of subsequent tests. For more information see the\n    :ref:`/stories/features/abort` feature documentation.\n\n    The scripts are hosted by default in the ``/usr/local/bin`` directory, except\n    for guests using ``rpm-ostree``, where ``/var/lib/tmt/scripts`` is used.\n    The directory can be forced using the ``TMT_SCRIPTS_DIR`` environment variable.\n    Note that for guests using ``rpm-ostree``, the directory is added to\n    executable paths using the system-wide ``/etc/profile.d/tmt.sh`` profile script.\n\n    .. warning::\n\n        Please be aware that for guests using ``rpm-ostree``\n        the provided scripts will only be available in a shell that\n        loads the profile scripts. This is the default for\n        ``bash``-like shells, but might not work for others.\n    \"\"\"\n\n    _data_class = ExecuteInternalData\n    data: ExecuteInternalData\n\n    def __init__(self, **kwargs: Any):\n        super().__init__(**kwargs)\n        self._previous_progress_message = \"\"\n\n    def _test_environment(\n        self,\n        *,\n        invocation: TestInvocation,\n        extra_environment: Optional[Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; Environment:\n        \"\"\"\n        Return test environment\n        \"\"\"\n\n        extra_environment = extra_environment or Environment()\n\n        environment = extra_environment.copy()\n        environment.update(invocation.test.environment)\n        assert self.parent is not None\n        assert isinstance(self.parent, tmt.steps.execute.Execute)\n        assert self.parent.plan.my_run is not None\n\n        environment['TMT_TEST_PIDFILE'] = EnvVarValue(\n            effective_pidfile_root() / TEST_PIDFILE_FILENAME\n        )\n        environment['TMT_TEST_PIDFILE_LOCK'] = EnvVarValue(\n            effective_pidfile_root() / TEST_PIDFILE_LOCK_FILENAME\n        )\n        environment[\"TMT_TEST_NAME\"] = EnvVarValue(invocation.test.name)\n        environment[\"TMT_TEST_INVOCATION_PATH\"] = EnvVarValue(invocation.path)\n        environment[\"TMT_TEST_DATA\"] = EnvVarValue(invocation.test_data_path)\n        environment[\"TMT_TEST_SUBMITTED_FILES\"] = EnvVarValue(invocation.submission_log_path)\n        environment['TMT_TEST_SERIAL_NUMBER'] = EnvVarValue(str(invocation.test.serial_number))\n        environment['TMT_TEST_ITERATION_ID'] = EnvVarValue(\n            f\"{self.parent.plan.my_run.unique_id}-{invocation.test.serial_number}\"\n        )\n        environment[\"TMT_TEST_METADATA\"] = EnvVarValue(\n            invocation.path / tmt.steps.execute.TEST_METADATA_FILENAME\n        )\n        environment[\"TMT_REBOOT_REQUEST\"] = EnvVarValue(\n            invocation.test_data_path / tmt.steps.scripts.TMT_REBOOT_SCRIPT.created_file\n        )\n\n        # Set the restraint-compatible mode if enabled\n        environment[\"TMT_RESTRAINT_COMPATIBLE\"] = EnvVarValue(\n            str(int(self.data.restraint_compatible))\n        )\n\n        # Set all supported reboot variables\n        for reboot_variable in tmt.steps.scripts.TMT_REBOOT_SCRIPT.related_variables:\n            environment[reboot_variable] = EnvVarValue(str(invocation._reboot_count))\n        environment['TMT_TEST_RESTART_COUNT'] = EnvVarValue(str(invocation._restart_count))\n\n        # Add variables the framework wants to expose\n        environment.update(\n            invocation.test.test_framework.get_environment_variables(invocation, logger)\n        )\n\n        return environment\n\n    def _test_output_logger(\n        self,\n        key: str,\n        value: Optional[str] = None,\n        color: tmt.utils.themes.Style = None,\n        shift: int = 2,\n        level: int = 3,\n        topic: Optional[tmt.log.Topic] = None,\n    ) -&gt; None:\n        \"\"\"\n        Custom logger for test output with shift 2 and level 3 defaults\n        \"\"\"\n\n        self.verbose(key=key, value=value, color=color, shift=shift, level=level)\n\n    def execute(\n        self,\n        *,\n        invocation: TestInvocation,\n        extra_environment: Optional[Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; list[Result]:\n        \"\"\"\n        Run test on the guest\n        \"\"\"\n\n        test, guest = invocation.test, invocation.guest\n\n        logger.debug(f\"Execute '{test.name}' as a '{test.framework}' test.\")\n\n        # Test will be executed in it's own directory, relative to the workdir\n        assert self.discover.workdir is not None  # narrow type\n        assert test.path is not None  # narrow type\n        workdir = self.discover.workdir / test.path.unrooted()\n        logger.debug(f\"Use workdir '{workdir}'.\", level=3)\n\n        # Create data directory, prepare test environment\n        environment = self._test_environment(\n            invocation=invocation, extra_environment=extra_environment, logger=logger\n        )\n\n        def _prepare_test_wrapper(\n            label: str, filename_template: str, template: jinja2.Template, **variables: Any\n        ) -&gt; Path:\n            # tmt wrapper filenames *must* be \"unique\" - the plugin might be handling\n            # the same `discover` phase for different guests at the same time, and\n            # must keep them isolated. The wrapper scripts, while being prepared, are\n            # a shared global state, and we must prevent race conditions.\n            test_wrapper_filename = safe_filename(\n                filename_template, self, guest, INVOCATION=invocation\n            )\n\n            test_wrapper_filepath = workdir / test_wrapper_filename\n            logger.debug(f'test {label} wrapper', test_wrapper_filepath)\n\n            test_wrapper = ShellScript(\n                template.render(LOGGER=logger, INVOCATION=invocation, **variables).strip()\n            )\n            self.debug(f'Test {label} wrapper', test_wrapper, level=3)\n\n            self.write(test_wrapper_filepath, str(test_wrapper), 'w')\n            test_wrapper_filepath.chmod(0o755)\n            guest.push(\n                source=test_wrapper_filepath,\n                destination=test_wrapper_filepath,\n                options=[\"-s\", \"-p\", \"--chmod=755\"],\n            )\n\n            return test_wrapper_filepath\n\n        # The inner test wrapper envelops the test script...\n        test_inner_wrapper_filepath = _prepare_test_wrapper(\n            'inner', TEST_INNER_WRAPPER_FILENAME_TEMPLATE, TEST_INNER_WRAPPER_TEMPLATE\n        )\n\n        # ... and it's a command the outer plugin invoke execute.\n        test_outer_wrapper_filepath = _prepare_test_wrapper(\n            'outer',\n            TEST_OUTER_WRAPPER_FILENAME_TEMPLATE,\n            TEST_OUTER_WRAPPER_TEMPLATE,\n            TEST_COMMAND=ShellScript(f'./{test_inner_wrapper_filepath.name}'),\n        )\n\n        # Create topology files\n        topology = tmt.steps.Topology(self.step.plan.provision.ready_guests)\n        topology.guest = tmt.steps.GuestTopology(guest)\n\n        environment.update(topology.push(dirpath=invocation.path, guest=guest, logger=logger))\n\n        # Prepare the actual remote command\n        remote_command: ShellScript\n        if guest.become and not guest.facts.is_superuser:\n            remote_command = ShellScript(f'sudo -E ./{test_outer_wrapper_filepath.name}')\n        else:\n            remote_command = ShellScript(f'./{test_outer_wrapper_filepath.name}')\n\n        def _test_output_logger(\n            key: str,\n            value: Optional[str] = None,\n            color: tmt.utils.themes.Style = None,\n            shift: int = 2,\n            level: int = 3,\n            topic: Optional[tmt.log.Topic] = None,\n        ) -&gt; None:\n            logger.verbose(\n                key=key, value=value, color=color, shift=shift, level=level, topic=topic\n            )\n\n        # TODO: do we want timestamps? Yes, we do, leaving that for refactoring later,\n        # to use some reusable decorator.\n        invocation.check_results = self.run_checks_before_test(\n            invocation=invocation, environment=environment, logger=logger\n        )\n\n        # Pick the proper timeout for the test\n        timeout: Optional[int]\n\n        if self.data.interactive:\n            if test.duration:\n                logger.warning('Ignoring requested duration, not supported in interactive mode.')\n\n            timeout = None\n\n        elif self.data.ignore_duration:\n            logger.debug(\"Test duration is not effective due to ignore-duration option.\")\n            timeout = None\n\n        else:\n            timeout = tmt.utils.duration_to_seconds(\n                test.duration, tmt.base.DEFAULT_TEST_DURATION_L1\n            )\n\n        # And invoke the test process.\n        output = invocation.invoke_test(\n            remote_command,\n            cwd=workdir,\n            env=environment,\n            interactive=self.data.interactive,\n            log=_test_output_logger,\n            timeout=timeout,\n        )\n\n        # Save the captured output. Do not let the follow-up pulls\n        # overwrite it.\n        self.write(invocation.path / TEST_OUTPUT_FILENAME, output.stdout or '', mode='a', level=3)\n\n        def pull_from_guest() -&gt; None:\n            if not invocation.is_guest_healthy:\n                return\n\n            try:\n                guest.pull(\n                    source=invocation.path,\n                    extend_options=[\n                        *test.test_framework.get_pull_options(invocation, logger),\n                        '--exclude',\n                        str(invocation.path / TEST_OUTPUT_FILENAME),\n                    ],\n                )\n\n                # Fetch plan data content as well in order to prevent\n                # losing logs if the guest becomes later unresponsive.\n                guest.pull(source=self.step.plan.data_directory)\n\n            # Handle failing to pull test artifacts after guest becoming\n            # unresponsive. If not handled test would stay in 'pending' state.\n            # See issue https://github.com/teemtee/tmt/issues/3647.\n            except tmt.utils.RunError:\n                # TODO: We rely here on the traceback to print a reasonable\n                # failure message, should be improved later.\n                pass\n\n        # Fetch #1: we need logs and everything the test produced so we could\n        # collect its results.\n        pull_from_guest()\n\n        # Run after-test checks before extracting results\n        invocation.check_results += self.run_checks_after_test(\n            invocation=invocation, environment=environment, logger=logger\n        )\n\n        # Extract test results and store them in the invocation. Note\n        # that these results will be overwritten with a fresh set of\n        # results after a successful reboot in the middle of a test.\n        invocation.results = self.extract_results(invocation, logger)\n\n        # Fetch #2: after-test checks might have produced remote files as well,\n        # we need to fetch them too.\n        pull_from_guest()\n\n        # Attach check results to every test result. There might be more than one,\n        # and it's hard to pick the main one, who knows what custom results might\n        # cover, so let's make sure every single result can lead to check results\n        # related to its lifetime.\n        for result in invocation.results:\n            if result.name == invocation.test.name:\n                result.log.extend(invocation.submitted_files)\n            result.check = invocation.check_results\n\n        return invocation.results\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; None:\n        \"\"\"\n        Execute available tests\n        \"\"\"\n\n        super().go(guest=guest, environment=environment, logger=logger)\n\n        # Nothing to do in dry mode\n        if self.is_dry_run:\n            self._results = []\n            return\n\n        self._run_tests(guest=guest, extra_environment=environment, logger=logger)\n\n    def _run_tests(\n        self,\n        *,\n        guest: Guest,\n        extra_environment: Optional[Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; None:\n        \"\"\"\n        Execute tests on provided guest\n        \"\"\"\n\n        assert self.workdir is not None  # narrow type\n\n        # Prepare tests, check options\n        test_invocations = self.prepare_tests(guest, logger)\n\n        # Push workdir to guest and execute tests\n        guest.push()\n        # We cannot use enumerate here due to continue in the code\n        index = 0\n\n        # TODO: plugin does not return any value. Results are exchanged\n        # via `self.results`, to signal abort we need a bigger gun. Once\n        # we get back to refactoring the plugin, this would turn into a\n        # better way of transporting \"plugin outcome\" back to the step.\n        abort_execute_exception: Optional[AbortExecute] = None\n\n        with UpdatableMessage(self) as progress_bar:\n            while index &lt; len(test_invocations):\n                invocation = test_invocations[index]\n\n                test = invocation.test\n\n                progress = f\"{index + 1}/{len(test_invocations)}\"\n                progress_bar.update(progress, test.name)\n                logger.verbose('test', test.summary or test.name, color='cyan', shift=1, level=2)\n\n                self.execute(\n                    invocation=invocation, extra_environment=extra_environment, logger=logger\n                )\n\n                assert invocation.real_duration is not None  # narrow type\n                duration = style(invocation.real_duration, fg='cyan')\n                shift = 1 if self.verbosity_level &lt; 2 else 2\n\n                # Handle test restart. May include guest reboot too.\n                if invocation.restart_requested:\n                    # Output before the restart\n                    logger.verbose(f\"{duration} {test.name} [{progress}]\", shift=shift)\n\n                    try:\n                        if invocation.handle_restart():\n                            continue\n\n                    except (\n                        tmt.utils.RebootTimeoutError,\n                        tmt.utils.ReconnectTimeoutError,\n                        tmt.utils.RestartMaxAttemptsError,\n                    ) as error:\n                        invocation.exception = error\n                        for result in invocation.results:\n                            result.result = ResultOutcome.ERROR\n\n                # Handle reboot\n                if invocation.reboot_requested:\n                    # Output before the reboot\n                    logger.verbose(f\"{duration} {test.name} [{progress}]\", shift=shift)\n                    try:\n                        if invocation.handle_reboot():\n                            continue\n                    except tmt.utils.RebootTimeoutError as error:\n                        invocation.exception = error\n                        for result in invocation.results:\n                            result.result = ResultOutcome.ERROR\n\n                # Execute internal checks\n                invocation.check_results += self.run_internal_checks(\n                    invocation=invocation,\n                    environment=self._test_environment(\n                        invocation=invocation, extra_environment=extra_environment, logger=logger\n                    ),\n                    logger=logger,\n                )\n\n                self._results.extend(invocation.results)\n                self.step.plan.execute.update_results(self.results())\n                self.step.plan.execute.save()\n\n                ResultRenderer(\n                    basepath=self.workdir,\n                    logger=logger,\n                    shift=shift,\n                    variables={'PROGRESS': f'[{progress}]'},\n                ).print_results(invocation.results)\n\n                abort_execute = invocation.abort_requested or (\n                    self.data.exit_first\n                    and any(\n                        result.result in (ResultOutcome.FAIL, ResultOutcome.ERROR)\n                        for result in invocation.results\n                    )\n                )\n\n                if abort_execute:\n                    if invocation.abort_requested:\n                        abort_message = f'Test {test.name} aborted, stopping execution.'\n\n                    else:\n                        abort_message = f'Test {test.name} failed, stopping execution.'\n\n                    abort_execute_exception = AbortExecute(abort_message)\n\n                    progress_bar.clear()\n\n                    break\n\n                index += 1\n\n                # Log into the guest after each executed test if \"login\n                # --test\" option is provided\n                if self._login_after_test:\n                    assert test.path is not None  # narrow type\n\n                    if self.discover.workdir is None:\n                        cwd = test.path.unrooted()\n                    else:\n                        cwd = self.discover.workdir / test.path.unrooted()\n                    self._login_after_test.after_test(\n                        invocation.results,\n                        cwd=cwd,\n                        env=self._test_environment(\n                            invocation=invocation,\n                            extra_environment=extra_environment,\n                            logger=logger,\n                        ),\n                    )\n\n        # Pull artifacts created in the plan data directory\n        self.debug(\"Pull the plan data directory.\", level=2)\n        guest.pull(source=self.step.plan.data_directory)\n\n        if abort_execute_exception:\n            raise abort_execute_exception\n\n    def results(self) -&gt; list[Result]:\n        \"\"\"\n        Return test results\n        \"\"\"\n\n        return self._results\n\n    def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n        \"\"\"\n        Collect all essential requirements of the plugin.\n\n        Essential requirements of a plugin are necessary for the plugin to\n        perform its basic functionality.\n\n        :returns: a list of requirements.\n        \"\"\"\n\n        return [\n            tmt.base.DependencySimple('/usr/bin/awk'),\n            tmt.base.DependencySimple('/usr/bin/flock'),\n        ]\n</code></pre>"},{"location":"plugins/execute/#tmt.steps.execute.internal.ExecuteInternal.essential_requires","title":"<code>essential_requires()</code>","text":"<p>Collect all essential requirements of the plugin.</p> <p>Essential requirements of a plugin are necessary for the plugin to perform its basic functionality.</p> <p>:returns: a list of requirements.</p> Source code in <code>tmt/steps/execute/internal.py</code> <pre><code>def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n    \"\"\"\n    Collect all essential requirements of the plugin.\n\n    Essential requirements of a plugin are necessary for the plugin to\n    perform its basic functionality.\n\n    :returns: a list of requirements.\n    \"\"\"\n\n    return [\n        tmt.base.DependencySimple('/usr/bin/awk'),\n        tmt.base.DependencySimple('/usr/bin/flock'),\n    ]\n</code></pre>"},{"location":"plugins/execute/#tmt.steps.execute.internal.ExecuteInternal.execute","title":"<code>execute(*, invocation, extra_environment=None, logger)</code>","text":"<p>Run test on the guest</p> Source code in <code>tmt/steps/execute/internal.py</code> <pre><code>def execute(\n    self,\n    *,\n    invocation: TestInvocation,\n    extra_environment: Optional[Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; list[Result]:\n    \"\"\"\n    Run test on the guest\n    \"\"\"\n\n    test, guest = invocation.test, invocation.guest\n\n    logger.debug(f\"Execute '{test.name}' as a '{test.framework}' test.\")\n\n    # Test will be executed in it's own directory, relative to the workdir\n    assert self.discover.workdir is not None  # narrow type\n    assert test.path is not None  # narrow type\n    workdir = self.discover.workdir / test.path.unrooted()\n    logger.debug(f\"Use workdir '{workdir}'.\", level=3)\n\n    # Create data directory, prepare test environment\n    environment = self._test_environment(\n        invocation=invocation, extra_environment=extra_environment, logger=logger\n    )\n\n    def _prepare_test_wrapper(\n        label: str, filename_template: str, template: jinja2.Template, **variables: Any\n    ) -&gt; Path:\n        # tmt wrapper filenames *must* be \"unique\" - the plugin might be handling\n        # the same `discover` phase for different guests at the same time, and\n        # must keep them isolated. The wrapper scripts, while being prepared, are\n        # a shared global state, and we must prevent race conditions.\n        test_wrapper_filename = safe_filename(\n            filename_template, self, guest, INVOCATION=invocation\n        )\n\n        test_wrapper_filepath = workdir / test_wrapper_filename\n        logger.debug(f'test {label} wrapper', test_wrapper_filepath)\n\n        test_wrapper = ShellScript(\n            template.render(LOGGER=logger, INVOCATION=invocation, **variables).strip()\n        )\n        self.debug(f'Test {label} wrapper', test_wrapper, level=3)\n\n        self.write(test_wrapper_filepath, str(test_wrapper), 'w')\n        test_wrapper_filepath.chmod(0o755)\n        guest.push(\n            source=test_wrapper_filepath,\n            destination=test_wrapper_filepath,\n            options=[\"-s\", \"-p\", \"--chmod=755\"],\n        )\n\n        return test_wrapper_filepath\n\n    # The inner test wrapper envelops the test script...\n    test_inner_wrapper_filepath = _prepare_test_wrapper(\n        'inner', TEST_INNER_WRAPPER_FILENAME_TEMPLATE, TEST_INNER_WRAPPER_TEMPLATE\n    )\n\n    # ... and it's a command the outer plugin invoke execute.\n    test_outer_wrapper_filepath = _prepare_test_wrapper(\n        'outer',\n        TEST_OUTER_WRAPPER_FILENAME_TEMPLATE,\n        TEST_OUTER_WRAPPER_TEMPLATE,\n        TEST_COMMAND=ShellScript(f'./{test_inner_wrapper_filepath.name}'),\n    )\n\n    # Create topology files\n    topology = tmt.steps.Topology(self.step.plan.provision.ready_guests)\n    topology.guest = tmt.steps.GuestTopology(guest)\n\n    environment.update(topology.push(dirpath=invocation.path, guest=guest, logger=logger))\n\n    # Prepare the actual remote command\n    remote_command: ShellScript\n    if guest.become and not guest.facts.is_superuser:\n        remote_command = ShellScript(f'sudo -E ./{test_outer_wrapper_filepath.name}')\n    else:\n        remote_command = ShellScript(f'./{test_outer_wrapper_filepath.name}')\n\n    def _test_output_logger(\n        key: str,\n        value: Optional[str] = None,\n        color: tmt.utils.themes.Style = None,\n        shift: int = 2,\n        level: int = 3,\n        topic: Optional[tmt.log.Topic] = None,\n    ) -&gt; None:\n        logger.verbose(\n            key=key, value=value, color=color, shift=shift, level=level, topic=topic\n        )\n\n    # TODO: do we want timestamps? Yes, we do, leaving that for refactoring later,\n    # to use some reusable decorator.\n    invocation.check_results = self.run_checks_before_test(\n        invocation=invocation, environment=environment, logger=logger\n    )\n\n    # Pick the proper timeout for the test\n    timeout: Optional[int]\n\n    if self.data.interactive:\n        if test.duration:\n            logger.warning('Ignoring requested duration, not supported in interactive mode.')\n\n        timeout = None\n\n    elif self.data.ignore_duration:\n        logger.debug(\"Test duration is not effective due to ignore-duration option.\")\n        timeout = None\n\n    else:\n        timeout = tmt.utils.duration_to_seconds(\n            test.duration, tmt.base.DEFAULT_TEST_DURATION_L1\n        )\n\n    # And invoke the test process.\n    output = invocation.invoke_test(\n        remote_command,\n        cwd=workdir,\n        env=environment,\n        interactive=self.data.interactive,\n        log=_test_output_logger,\n        timeout=timeout,\n    )\n\n    # Save the captured output. Do not let the follow-up pulls\n    # overwrite it.\n    self.write(invocation.path / TEST_OUTPUT_FILENAME, output.stdout or '', mode='a', level=3)\n\n    def pull_from_guest() -&gt; None:\n        if not invocation.is_guest_healthy:\n            return\n\n        try:\n            guest.pull(\n                source=invocation.path,\n                extend_options=[\n                    *test.test_framework.get_pull_options(invocation, logger),\n                    '--exclude',\n                    str(invocation.path / TEST_OUTPUT_FILENAME),\n                ],\n            )\n\n            # Fetch plan data content as well in order to prevent\n            # losing logs if the guest becomes later unresponsive.\n            guest.pull(source=self.step.plan.data_directory)\n\n        # Handle failing to pull test artifacts after guest becoming\n        # unresponsive. If not handled test would stay in 'pending' state.\n        # See issue https://github.com/teemtee/tmt/issues/3647.\n        except tmt.utils.RunError:\n            # TODO: We rely here on the traceback to print a reasonable\n            # failure message, should be improved later.\n            pass\n\n    # Fetch #1: we need logs and everything the test produced so we could\n    # collect its results.\n    pull_from_guest()\n\n    # Run after-test checks before extracting results\n    invocation.check_results += self.run_checks_after_test(\n        invocation=invocation, environment=environment, logger=logger\n    )\n\n    # Extract test results and store them in the invocation. Note\n    # that these results will be overwritten with a fresh set of\n    # results after a successful reboot in the middle of a test.\n    invocation.results = self.extract_results(invocation, logger)\n\n    # Fetch #2: after-test checks might have produced remote files as well,\n    # we need to fetch them too.\n    pull_from_guest()\n\n    # Attach check results to every test result. There might be more than one,\n    # and it's hard to pick the main one, who knows what custom results might\n    # cover, so let's make sure every single result can lead to check results\n    # related to its lifetime.\n    for result in invocation.results:\n        if result.name == invocation.test.name:\n            result.log.extend(invocation.submitted_files)\n        result.check = invocation.check_results\n\n    return invocation.results\n</code></pre>"},{"location":"plugins/execute/#tmt.steps.execute.internal.ExecuteInternal.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Execute available tests</p> Source code in <code>tmt/steps/execute/internal.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; None:\n    \"\"\"\n    Execute available tests\n    \"\"\"\n\n    super().go(guest=guest, environment=environment, logger=logger)\n\n    # Nothing to do in dry mode\n    if self.is_dry_run:\n        self._results = []\n        return\n\n    self._run_tests(guest=guest, extra_environment=environment, logger=logger)\n</code></pre>"},{"location":"plugins/execute/#tmt.steps.execute.internal.ExecuteInternal.results","title":"<code>results()</code>","text":"<p>Return test results</p> Source code in <code>tmt/steps/execute/internal.py</code> <pre><code>def results(self) -&gt; list[Result]:\n    \"\"\"\n    Return test results\n    \"\"\"\n\n    return self._results\n</code></pre>"},{"location":"plugins/execute/#upgrade","title":"upgrade","text":""},{"location":"plugins/execute/#tmt.steps.execute.upgrade.ExecuteUpgrade","title":"<code>tmt.steps.execute.upgrade.ExecuteUpgrade</code>","text":"<p>               Bases: <code>ExecuteInternal</code></p> <p>Perform system upgrade during testing.</p> <p>In order to enable developing tests for upgrade testing, we need to provide a way how to execute these tests easily. This does not cover unit tests for individual actors but rather system tests which verify the whole upgrade story.</p> <p>The upgrade executor runs the discovered tests (using the internal executor), then performs a set of upgrade tasks from a remote repository, and finally, re-runs the tests on the upgraded guest.</p> <p>The <code>IN_PLACE_UPGRADE</code> environment variable is set during the test execution to differentiate between the stages of the test. It is set to <code>old</code> during the first execution and <code>new</code> during the second execution. Test names are prefixed with this value to make the names unique. Based on this variable, the test can perform appropriate actions.</p> <ul> <li><code>old</code>: setup, test</li> <li><code>new</code>: test, cleanup</li> <li><code>without</code>: setup, test, cleanup</li> </ul> <p>The upgrade tasks performing the actual system upgrade are taken from a remote repository (specified by the <code>url</code> key) based on an upgrade path (e.g. <code>fedora35to36</code>) or other filters (e.g. specified by the <code>filter</code> key). If both <code>upgrade-path</code> and extra filters are specified, the discover keys in the remote upgrade path plan are overridden by the filters specified in the local plan.</p> <p>The upgrade path must correspond to a plan name in the remote repository whose discover step selects tests (upgrade tasks) performing the upgrade. Currently, selection of upgrade tasks in the remote repository can be done using both fmf and shell discover method. If the <code>url</code> is not provided, upgrade path and upgrade tasks are taken from the current repository. The supported keys in discover are:</p> <ul> <li><code>ref</code></li> <li><code>filter</code></li> <li><code>exclude</code></li> <li><code>tests</code></li> <li><code>test</code></li> </ul> <p>The environment variables defined in the remote upgrade path plan are passed to the upgrade tasks when they are executed. An example of an upgrade path plan (in the remote repository):</p> <p>.. code-block:: yaml</p> <pre><code>discover: # Selects appropriate upgrade tasks (L1 tests)\n    how: fmf\n    filter: \"tag:fedora\"\nenvironment: # This is passed to upgrade tasks\n    SOURCE: 35\n    TARGET: 36\nexecute:\n    how: tmt\n</code></pre> <p>If no upgrade path is specified in the plan, the tests (upgrade tasks) are selected based on the configuration of the upgrade plugin (e.g. based on the filter in its configuration).</p> <p>If these two possible ways of specifying upgrade tasks are combined, the remote discover plan is used but its options are overridden with the values specified locally.</p> <p>The same options and config keys and values can be used as in the internal executor.</p> <p>Minimal execute config example with an upgrade path:</p> <p>.. code-block:: yaml</p> <pre><code>execute:\n    how: upgrade\n    url: https://github.com/teemtee/upgrade\n    upgrade-path: /paths/fedora35to36\n</code></pre> <p>Execute config example without an upgrade path:</p> <p>.. code-block:: yaml</p> <pre><code>execute:\n    how: upgrade\n    url: https://github.com/teemtee/upgrade\n    filter: \"tag:fedora\"\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># A simple beakerlib test using the $IN_PLACE_UPGRADE variable\n. /usr/share/beakerlib/beakerlib.sh || exit 1\n\nVENV_PATH=/var/tmp/venv_test\n\nrlJournalStart\n    # Perform the setup only for the old distro\n    if [[ \"$IN_PLACE_UPGRADE\" !=  \"new\" ]]; then\n        rlPhaseStartSetup\n            rlRun \"python3.9 -m venv $VENV_PATH\"\n            rlRun \"$VENV_PATH/bin/pip install pyjokes\"\n        rlPhaseEnd\n    fi\n\n    # Execute the test for both old &amp; new distro\n    rlPhaseStartTest\n        rlAsssertExists \"$VENV_PATH/bin/pyjoke\"\n        rlRun \"$VENV_PATH/bin/pyjoke\"\n    rlPhaseEnd\n\n    # Skip the cleanup phase when on the old distro\n    if [[ \"$IN_PLACE_UPGRADE\" !=  \"old\" ]]; then\n        rlPhaseStartCleanup\n            rlRun \"rm -rf $VENV_PATH\"\n        rlPhaseEnd\n    fi\nrlJournalEnd\n</code></pre> Source code in <code>tmt/steps/execute/upgrade.py</code> <pre><code>@tmt.steps.provides_method('upgrade')\nclass ExecuteUpgrade(ExecuteInternal):\n    \"\"\"\n    Perform system upgrade during testing.\n\n    In order to enable developing tests for upgrade testing, we need to provide\n    a way how to execute these tests easily. This does not cover unit tests for\n    individual actors but rather system tests which verify\n    the whole upgrade story.\n\n    The upgrade executor runs the discovered tests (using the internal\n    executor), then performs a set of upgrade tasks from a remote\n    repository, and finally, re-runs the tests on the upgraded guest.\n\n    The ``IN_PLACE_UPGRADE`` environment variable is set during the test\n    execution to differentiate between the stages of the test. It is set\n    to ``old`` during the first execution and ``new`` during the second\n    execution. Test names are prefixed with this value to make the names\n    unique. Based on this variable, the test can perform appropriate actions.\n\n    * ``old``: setup, test\n    * ``new``: test, cleanup\n    * ``without``: setup, test, cleanup\n\n    The upgrade tasks performing the actual system upgrade are taken\n    from a remote repository (specified by the ``url`` key) based on an upgrade\n    path (e.g. ``fedora35to36``) or other filters (e.g. specified by the\n    ``filter`` key). If both ``upgrade-path`` and extra filters are specified,\n    the discover keys in the remote upgrade path plan are overridden by the\n    filters specified in the local plan.\n\n    The upgrade path must correspond to a plan name in the\n    remote repository whose discover step selects tests (upgrade tasks)\n    performing the upgrade. Currently, selection of upgrade tasks in the remote\n    repository can be done using both fmf and shell discover method.\n    If the ``url`` is not provided, upgrade path and upgrade tasks are taken from\n    the current repository. The supported keys in discover are:\n\n    * ``ref``\n    * ``filter``\n    * ``exclude``\n    * ``tests``\n    * ``test``\n\n    The environment variables defined in the remote upgrade path plan are\n    passed to the upgrade tasks when they are executed. An example of an\n    upgrade path plan (in the remote repository):\n\n    .. code-block:: yaml\n\n        discover: # Selects appropriate upgrade tasks (L1 tests)\n            how: fmf\n            filter: \"tag:fedora\"\n        environment: # This is passed to upgrade tasks\n            SOURCE: 35\n            TARGET: 36\n        execute:\n            how: tmt\n\n    If no upgrade path is specified in the plan, the tests (upgrade tasks)\n    are selected based on the configuration of the upgrade plugin\n    (e.g. based on the filter in its configuration).\n\n    If these two possible ways of specifying upgrade tasks are combined,\n    the remote discover plan is used but its options are overridden\n    with the values specified locally.\n\n    The same options and config keys and values can be used as in the\n    internal executor.\n\n    Minimal execute config example with an upgrade path:\n\n    .. code-block:: yaml\n\n        execute:\n            how: upgrade\n            url: https://github.com/teemtee/upgrade\n            upgrade-path: /paths/fedora35to36\n\n    Execute config example without an upgrade path:\n\n    .. code-block:: yaml\n\n        execute:\n            how: upgrade\n            url: https://github.com/teemtee/upgrade\n            filter: \"tag:fedora\"\n\n    .. code-block:: yaml\n\n        # A simple beakerlib test using the $IN_PLACE_UPGRADE variable\n        . /usr/share/beakerlib/beakerlib.sh || exit 1\n\n        VENV_PATH=/var/tmp/venv_test\n\n        rlJournalStart\n            # Perform the setup only for the old distro\n            if [[ \"$IN_PLACE_UPGRADE\" !=  \"new\" ]]; then\n                rlPhaseStartSetup\n                    rlRun \"python3.9 -m venv $VENV_PATH\"\n                    rlRun \"$VENV_PATH/bin/pip install pyjokes\"\n                rlPhaseEnd\n            fi\n\n            # Execute the test for both old &amp; new distro\n            rlPhaseStartTest\n                rlAsssertExists \"$VENV_PATH/bin/pyjoke\"\n                rlRun \"$VENV_PATH/bin/pyjoke\"\n            rlPhaseEnd\n\n            # Skip the cleanup phase when on the old distro\n            if [[ \"$IN_PLACE_UPGRADE\" !=  \"old\" ]]; then\n                rlPhaseStartCleanup\n                    rlRun \"rm -rf $VENV_PATH\"\n                rlPhaseEnd\n            fi\n        rlJournalEnd\n    \"\"\"\n\n    _data_class = ExecuteUpgradeData\n    data: ExecuteUpgradeData\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        super().__init__(**kwargs)\n        self._discover_upgrade: Optional[DiscoverFmf] = None\n\n    @property  # type:ignore[override]\n    def discover(self) -&gt; Union[Discover, DiscoverFmf]:\n        \"\"\"\n        Return discover plugin instance\n        \"\"\"\n\n        # If we are in the second phase (upgrade), take tests from our fake\n        # discover plugin.\n        if self._discover_upgrade:\n            return self._discover_upgrade\n        return self.step.plan.discover\n\n    @discover.setter\n    def discover(self, plugin: Optional[DiscoverPlugin[DiscoverStepData]]) -&gt; None:\n        self._discover = plugin\n\n    def go(\n        self,\n        *,\n        guest: 'tmt.steps.provision.Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; None:\n        \"\"\"\n        Execute available tests\n        \"\"\"\n\n        # Inform about the how, skip the actual execution\n        ExecutePlugin.go(self, guest=guest, environment=environment, logger=logger)\n\n        self.url = self.get('url')\n        self.upgrade_path = self.get('upgrade-path')\n        for key in self._keys:\n            value = self.get(key)\n            if value:\n                if key == \"test\":\n                    self.info('test', fmf.utils.listed(value), 'green')\n                else:\n                    self.info(key, value, color='green')\n\n        # Nothing to do in dry mode\n        if self.is_dry_run:\n            self._results = []\n            return\n\n        self.verbose('upgrade', 'run tests on the old system', color='blue', shift=1)\n        self._run_test_phase(guest, BEFORE_UPGRADE_PREFIX, logger)\n        self.verbose('upgrade', 'perform the system upgrade', color='blue', shift=1)\n        self._perform_upgrade(guest, logger)\n        self.verbose('upgrade', 'run tests on the new system', color='blue', shift=1)\n        self._run_test_phase(guest, AFTER_UPGRADE_PREFIX, logger)\n\n    def _get_plan(self, upgrades_repo: Path) -&gt; tmt.base.Plan:\n        \"\"\"\n        Get plan based on upgrade path\n        \"\"\"\n\n        tree = tmt.base.Tree(logger=self._logger, path=upgrades_repo)\n        try:\n            # We do not want to consider plan -n provided on the command line\n            # in the remote repo for finding upgrade path.\n            tmt.base.Plan.ignore_class_options = True\n            plans = tree.plans(names=[self.upgrade_path])\n        finally:\n            tmt.base.Plan.ignore_class_options = False\n\n        if len(plans) == 0:\n            raise tmt.utils.ExecuteError(\n                f\"No matching upgrade path found for '{self.upgrade_path}'.\"\n            )\n        if len(plans) &gt; 1:\n            names = [plan.name for plan in plans]\n            raise tmt.utils.ExecuteError(\n                f\"Ambiguous upgrade path reference, found plans {fmf.utils.listed(names)}.\"\n            )\n        return plans[0]\n\n    def _fetch_upgrade_tasks(self) -&gt; None:\n        \"\"\"\n        Fetch upgrade tasks using DiscoverFmf\n        \"\"\"\n\n        data = DiscoverFmfStepData(\n            name='upgrade-discover',\n            how='fmf',\n            # url=self.data.url,\n            **{key: getattr(self.data, key) for key in PROPAGATE_TO_DISCOVER_KEYS},\n        )\n\n        self._discover_upgrade = DiscoverFmf(logger=self._logger, step=self.step, data=data)\n        self._run_discover_upgrade()\n\n    def _run_discover_upgrade(self) -&gt; None:\n        \"\"\"\n        Silently run discover upgrade\n        \"\"\"\n\n        # Make it quiet, we do not want any output from discover\n        assert self._discover_upgrade is not None\n\n        # Discover normally uses also options from global Test class\n        # (e.g. test -n foo). Ignore this when selecting upgrade tasks.\n        tmt.base.Test.ignore_class_options = True\n\n        cli_invocation = self._discover_upgrade.cli_invocation\n        if cli_invocation:\n            quiet, cli_invocation.options['quiet'] = cli_invocation.options['quiet'], True\n\n        try:\n            self._discover_upgrade.wake()\n            self._discover_upgrade.go()\n\n        finally:\n            tmt.base.Test.ignore_class_options = False\n\n            if cli_invocation:\n                cli_invocation.options['quiet'] = quiet\n\n    def _install_dependencies(\n        self,\n        guest: tmt.steps.provision.Guest,\n        dependencies: list[tmt.base.DependencySimple],\n        recommends: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Install packages required/recommended for upgrade\n        \"\"\"\n\n        phase_name = 'recommended' if recommends else 'required'\n        data = PrepareInstallData(\n            how='install',\n            name=f'{phase_name}-packages-upgrade',\n            summary=f'Install packages {phase_name} by the upgrade',\n            package=tmt.utils.uniq(dependencies),\n            missing='skip' if recommends else 'fail',\n        )\n\n        PreparePlugin.delegate(self.step, data=data).go(  # type:ignore[attr-defined]\n            guest=guest, logger=self._logger\n        )\n\n    def _prepare_remote_discover_data(self, plan: tmt.base.Plan) -&gt; tmt.steps._RawStepData:\n        \"\"\"\n        Merge remote discover data with the local filters\n        \"\"\"\n\n        if len(plan.discover.data) &gt; 1:\n            raise tmt.utils.ExecuteError(\"Multiple discover configs are not supported.\")\n\n        data = plan.discover.data[0]\n\n        remote_raw_data: tmt.steps._RawStepData = {\n            # Force name\n            'name': 'upgrade-discover-remote',\n            'how': 'fmf',\n        }\n        remote_raw_data.update(\n            cast(\n                tmt.steps._RawStepData,\n                {\n                    key_to_option(key): value\n                    for key, value in data.items()\n                    if key in PROPAGATE_TO_DISCOVER_KEYS\n                },\n            )\n        )\n\n        # Local values have priority, override\n        for key in self._keys:\n            value = self.get(key)\n            if key in PROPAGATE_TO_DISCOVER_KEYS and value:\n                remote_raw_data[key] = value  # type:ignore[literal-required]\n\n        return remote_raw_data\n\n    def _perform_upgrade(self, guest: tmt.steps.provision.Guest, logger: tmt.log.Logger) -&gt; None:\n        \"\"\"\n        Perform a system upgrade\n        \"\"\"\n\n        original_discover_phase = self.discover_phase\n\n        try:\n            self._fetch_upgrade_tasks()\n            extra_environment = None\n            assert self._discover_upgrade is not None\n            if self.upgrade_path:\n                # Create a fake discover from the data in the upgrade path\n                plan = self._get_plan(self._discover_upgrade.testdir)\n                data = self._prepare_remote_discover_data(plan)\n                # Unset `url` because we don't want discover step to perform clone. Instead,\n                # we want it to reuse existing, already cloned path.\n                # ignore[typeddict-unknown-key]: data is _RwStepData, we do not have more detailed\n                # type for raw step data of internal/upgrade plugins, it would be pretty verbose.\n                data['url'] = None  # type: ignore[typeddict-unknown-key]\n                data['path'] = self._discover_upgrade.testdir  # type:ignore[typeddict-unknown-key]\n                # FIXME: cast() - https://github.com/teemtee/tmt/issues/1599\n                self._discover_upgrade = cast(\n                    DiscoverFmf, DiscoverPlugin.delegate(self.step, raw_data=data)\n                )\n                self._run_discover_upgrade()\n                # Pass in the path-specific env variables\n                extra_environment = plan.environment\n\n            required_packages: list[tmt.base.DependencySimple] = []\n            recommended_packages: list[tmt.base.DependencySimple] = []\n            for test_origin in self._discover_upgrade.tests(enabled=True):\n                test = test_origin.test\n\n                test.name = f'/{DURING_UPGRADE_PREFIX}/{test.name.lstrip(\"/\")}'\n\n                # Gathering dependencies for upgrade tasks\n                required_packages += tmt.base.assert_simple_dependencies(\n                    test.require,\n                    'After beakerlib processing, tests may have only simple requirements',\n                    self._logger,\n                )\n\n                recommended_packages += tmt.base.assert_simple_dependencies(\n                    test.recommend,\n                    'After beakerlib processing, tests may have only simple requirements',\n                    self._logger,\n                )\n\n                required_packages += test.test_framework.get_requirements(test, self._logger)\n\n                for check in test.check:\n                    required_packages += check.plugin.essential_requires(guest, test, self._logger)\n\n            self._install_dependencies(guest, required_packages)\n            self._install_dependencies(guest, recommended_packages, recommends=True)\n            self.discover_phase = self._discover_upgrade.name\n            self._run_tests(guest=guest, extra_environment=extra_environment, logger=logger)\n        finally:\n            self._discover_upgrade = None\n            self.discover_phase = original_discover_phase\n\n    def _run_test_phase(\n        self, guest: tmt.steps.provision.Guest, prefix: str, logger: tmt.log.Logger\n    ) -&gt; None:\n        \"\"\"\n        Execute a single test phase on the guest\n\n        Tests names are prefixed with the prefix argument in order to make\n        their names unique so that the results are distinguishable.\n        The prefix is also set as IN_PLACE_UPGRADE environment variable.\n        \"\"\"\n\n        names_backup = []\n        for test_origin in self.discover.tests(enabled=True):\n            names_backup.append(test_origin.test.name)\n            test_origin.test.name = f'/{prefix}/{test_origin.test.name.lstrip(\"/\")}'\n\n        self._run_tests(\n            guest=guest,\n            extra_environment=Environment({STATUS_VARIABLE: EnvVarValue(prefix)}),\n            logger=logger,\n        )\n\n        self._remove_old_results(prefix)\n\n        for i, test_origin in enumerate(self.discover.tests(enabled=True)):\n            test_origin.test.name = names_backup[i]\n\n    def _remove_old_results(self, prefix: str) -&gt; None:\n        \"\"\"\n        Remove old results that were replaced by prefixed ones\n        \"\"\"\n\n        results = self.step.plan.execute.results()\n        old_result_names = [\n            result.name.removeprefix(f'/{prefix}')\n            for result in results\n            if result.name.startswith(f'/{prefix}/')\n        ]\n\n        self.step.plan.execute._results = [\n            result for result in results if result.name not in old_result_names\n        ]\n        self.step.plan.execute.save()\n</code></pre>"},{"location":"plugins/execute/#tmt.steps.execute.upgrade.ExecuteUpgrade.discover","title":"<code>discover</code>  <code>property</code> <code>writable</code>","text":"<p>Return discover plugin instance</p>"},{"location":"plugins/execute/#tmt.steps.execute.upgrade.ExecuteUpgrade.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Execute available tests</p> Source code in <code>tmt/steps/execute/upgrade.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'tmt.steps.provision.Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; None:\n    \"\"\"\n    Execute available tests\n    \"\"\"\n\n    # Inform about the how, skip the actual execution\n    ExecutePlugin.go(self, guest=guest, environment=environment, logger=logger)\n\n    self.url = self.get('url')\n    self.upgrade_path = self.get('upgrade-path')\n    for key in self._keys:\n        value = self.get(key)\n        if value:\n            if key == \"test\":\n                self.info('test', fmf.utils.listed(value), 'green')\n            else:\n                self.info(key, value, color='green')\n\n    # Nothing to do in dry mode\n    if self.is_dry_run:\n        self._results = []\n        return\n\n    self.verbose('upgrade', 'run tests on the old system', color='blue', shift=1)\n    self._run_test_phase(guest, BEFORE_UPGRADE_PREFIX, logger)\n    self.verbose('upgrade', 'perform the system upgrade', color='blue', shift=1)\n    self._perform_upgrade(guest, logger)\n    self.verbose('upgrade', 'run tests on the new system', color='blue', shift=1)\n    self._run_test_phase(guest, AFTER_UPGRADE_PREFIX, logger)\n</code></pre>"},{"location":"plugins/finish/","title":"Finish","text":"<p>Perform the finishing tasks and clean up provisioned guests.</p>"},{"location":"plugins/finish/#ansible","title":"ansible","text":""},{"location":"plugins/finish/#tmt.steps.finish.ansible.FinishAnsible","title":"<code>tmt.steps.finish.ansible.FinishAnsible</code>","text":"<p>               Bases: <code>FinishPlugin[FinishStepData]</code>, <code>PrepareAnsible</code></p> <p>Perform finishing tasks using ansible.</p> <p>One or more playbooks can be provided as a list under the <code>playbook</code> attribute.  Each of them will be applied using <code>ansible-playbook</code> in the given order. The path must be relative to the metadata tree root.</p> <p>Remote playbooks can be referenced as well as the local ones, and both kinds can be used at the same time.</p> <p>.. warning::</p> <p>The plugin may be a subject of various limitations, imposed by    Ansible itself:</p> <ul> <li>Ansible 2.17+ no longer supports Python 3.6 and older. Guests      where Python 3.7+ is not available cannot be prepared with the      <code>ansible</code> plugin. This has been observed when Fedora Rawhide      runner is used with CentOS 7 or CentOS Stream 8 guests. Possible      workarounds: downgrade Ansible tmt uses, or install Python 3.7+      before using <code>ansible</code> plugin from an alternative repository      or local build.</li> </ul> <p>Single playbook config:</p> <p>.. code-block:: yaml</p> <pre><code>finish:\n    how: ansible\n    playbook: ansible/packages.yml\n</code></pre> <p>Multiple playbooks config:</p> <p>.. code-block:: yaml</p> <pre><code>finish:\n    how: ansible\n    playbook:\n      - playbooks/common.yml\n      - playbooks/os/rhel9.yml\n      - https://foo.bar/rhel9-final-touches.yml\n</code></pre> <p>The playbook path should be relative to the metadata tree root. Use the :ref:<code>/spec/core/order</code> attribute to select in which order finishing tasks should happen if there are multiple configs. Default order is <code>50</code>.</p> Source code in <code>tmt/steps/finish/ansible.py</code> <pre><code>@tmt.steps.provides_method('ansible')\nclass FinishAnsible(\n    tmt.steps.finish.FinishPlugin[tmt.steps.finish.FinishStepData], PrepareAnsible\n):\n    \"\"\"\n    Perform finishing tasks using ansible.\n\n    One or more playbooks can be provided as a list under the ``playbook``\n    attribute.  Each of them will be applied using ``ansible-playbook`` in\n    the given order. The path must be relative to the metadata tree root.\n\n    Remote playbooks can be referenced as well as the local ones,\n    and both kinds can be used at the same time.\n\n    .. warning::\n\n       The plugin may be a subject of various limitations, imposed by\n       Ansible itself:\n\n       * Ansible 2.17+ no longer supports Python 3.6 and older. Guests\n         where Python 3.7+ is not available cannot be prepared with the\n         ``ansible`` plugin. This has been observed when Fedora Rawhide\n         runner is used with CentOS 7 or CentOS Stream 8 guests. Possible\n         workarounds: downgrade Ansible tmt uses, or install Python 3.7+\n         before using ``ansible`` plugin from an alternative repository\n         or local build.\n\n    Single playbook config:\n\n    .. code-block:: yaml\n\n        finish:\n            how: ansible\n            playbook: ansible/packages.yml\n\n    Multiple playbooks config:\n\n    .. code-block:: yaml\n\n        finish:\n            how: ansible\n            playbook:\n              - playbooks/common.yml\n              - playbooks/os/rhel9.yml\n              - https://foo.bar/rhel9-final-touches.yml\n\n    The playbook path should be relative to the metadata tree root. Use\n    the :ref:`/spec/core/order` attribute to select in which order\n    finishing tasks should happen if there are multiple configs. Default\n    order is ``50``.\n    \"\"\"\n\n    # We are reusing \"prepare\" step for \"finish\",\n    # and they both have different expectations\n    _data_class = tmt.steps.prepare.ansible.PrepareAnsibleData\n\n    # FIXME: ignore[assignment]: https://github.com/teemtee/tmt/issues/1540\n    # Also, assigning class methods seems to cause trouble to mypy\n    # See https://github.com/python/mypy/issues/6700\n    base_command = tmt.steps.finish.FinishPlugin.base_command  # type: ignore[assignment]\n\n    # `FinishPlugin` plugin would win the inheritance battle and provide\n    # its no-op `go()`. Force the one from `PrepareAnsible`.\n    go = PrepareAnsible.go\n</code></pre>"},{"location":"plugins/finish/#shell","title":"shell","text":""},{"location":"plugins/finish/#tmt.steps.finish.shell.FinishShell","title":"<code>tmt.steps.finish.shell.FinishShell</code>","text":"<p>               Bases: <code>FinishPlugin[FinishShellData]</code></p> <p>Perform finishing tasks using shell (bash) scripts.</p> <p>Execute arbitrary shell commands to finish the testing. Default shell options are applied to the script, see the :ref:<code>/spec/tests/test</code> key specification for more details.</p> <p>Example config:</p> <p>.. code-block:: yaml</p> <pre><code>finish:\n    how: shell\n    script:\n      - upload-logs.sh || true\n      - rm -rf /tmp/temporary-files\n</code></pre> <p>Use the :ref:<code>/spec/core/order</code> attribute to select in which order finishing tasks should happen if there are multiple configs. Default order is <code>50</code>.</p> Source code in <code>tmt/steps/finish/shell.py</code> <pre><code>@tmt.steps.provides_method('shell')\nclass FinishShell(tmt.steps.finish.FinishPlugin[FinishShellData]):\n    \"\"\"\n    Perform finishing tasks using shell (bash) scripts.\n\n    Execute arbitrary shell commands to finish the testing.\n    Default shell options are applied to the script, see the\n    :ref:`/spec/tests/test` key specification for more\n    details.\n\n    Example config:\n\n    .. code-block:: yaml\n\n        finish:\n            how: shell\n            script:\n              - upload-logs.sh || true\n              - rm -rf /tmp/temporary-files\n\n    Use the :ref:`/spec/core/order` attribute to select in which order\n    finishing tasks should happen if there are multiple configs. Default\n    order is ``50``.\n    \"\"\"\n\n    _data_class = FinishShellData\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; tmt.steps.PluginOutcome:\n        \"\"\"\n        Perform finishing tasks on given guest\n        \"\"\"\n\n        outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n        # Give a short summary\n        overview = fmf.utils.listed(self.data.script, 'script')\n        self.info('overview', f'{overview} found', 'green')\n\n        workdir = self.step.plan.worktree\n        assert workdir is not None  # narrow type\n\n        finish_wrapper_filename = safe_filename(FINISH_WRAPPER_FILENAME, self, guest)\n        finish_wrapper_path = workdir / finish_wrapper_filename\n\n        logger.debug('finish wrapper', finish_wrapper_path, level=3)\n\n        # Execute each script on the guest\n        for script in self.data.script:\n            self.verbose('script', script, 'green')\n            script_with_options = tmt.utils.ShellScript(f'{tmt.utils.SHELL_OPTIONS}; {script}')\n            self.write(finish_wrapper_path, str(script_with_options), 'w')\n            if not self.is_dry_run:\n                finish_wrapper_path.chmod(0o755)\n            guest.push(\n                source=finish_wrapper_path,\n                destination=finish_wrapper_path,\n                options=[\"-s\", \"-p\", \"--chmod=755\"],\n            )\n            command: ShellScript\n            if guest.become and not guest.facts.is_superuser:\n                command = tmt.utils.ShellScript(f'sudo -E {finish_wrapper_path}')\n            else:\n                command = tmt.utils.ShellScript(f'{finish_wrapper_path}')\n            guest.execute(command, cwd=workdir)\n\n        return outcome\n</code></pre>"},{"location":"plugins/finish/#tmt.steps.finish.shell.FinishShell.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Perform finishing tasks on given guest</p> Source code in <code>tmt/steps/finish/shell.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; tmt.steps.PluginOutcome:\n    \"\"\"\n    Perform finishing tasks on given guest\n    \"\"\"\n\n    outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n    # Give a short summary\n    overview = fmf.utils.listed(self.data.script, 'script')\n    self.info('overview', f'{overview} found', 'green')\n\n    workdir = self.step.plan.worktree\n    assert workdir is not None  # narrow type\n\n    finish_wrapper_filename = safe_filename(FINISH_WRAPPER_FILENAME, self, guest)\n    finish_wrapper_path = workdir / finish_wrapper_filename\n\n    logger.debug('finish wrapper', finish_wrapper_path, level=3)\n\n    # Execute each script on the guest\n    for script in self.data.script:\n        self.verbose('script', script, 'green')\n        script_with_options = tmt.utils.ShellScript(f'{tmt.utils.SHELL_OPTIONS}; {script}')\n        self.write(finish_wrapper_path, str(script_with_options), 'w')\n        if not self.is_dry_run:\n            finish_wrapper_path.chmod(0o755)\n        guest.push(\n            source=finish_wrapper_path,\n            destination=finish_wrapper_path,\n            options=[\"-s\", \"-p\", \"--chmod=755\"],\n        )\n        command: ShellScript\n        if guest.become and not guest.facts.is_superuser:\n            command = tmt.utils.ShellScript(f'sudo -E {finish_wrapper_path}')\n        else:\n            command = tmt.utils.ShellScript(f'{finish_wrapper_path}')\n        guest.execute(command, cwd=workdir)\n\n    return outcome\n</code></pre>"},{"location":"plugins/prepare/","title":"Prepare","text":"<p>Prepare the environment for testing.</p>"},{"location":"plugins/prepare/#ansible","title":"ansible","text":""},{"location":"plugins/prepare/#tmt.steps.prepare.ansible.PrepareAnsible","title":"<code>tmt.steps.prepare.ansible.PrepareAnsible</code>","text":"<p>               Bases: <code>PreparePlugin[PrepareAnsibleData]</code></p> <p>Run Ansible playbooks against the guest, by running <code>ansible-playbook</code> for all given playbooks.</p> <p>.. note::</p> <p>The plugin requires a working Ansible to be available on the    test runner.</p> <p>.. warning::</p> <pre><code>When specifying playbooks with paths:\n\n* If a metadata tree root exists, all paths must be relative to\n  the metadata tree root.\n* If the metadata tree root does not exist,\n  all paths must be relative to the current working directory.\n</code></pre> <p>.. warning::</p> <p>The plugin may be a subject of various limitations, imposed by    Ansible itself:</p> <ul> <li>Ansible 2.17+ no longer supports Python 3.6 and older. Guests      where Python 3.7+ is not available cannot be prepared with the      <code>ansible</code> plugin. This has been observed when Fedora Rawhide      runner is used with CentOS 7 or CentOS Stream 8 guests. Possible      workarounds: downgrade Ansible tmt uses, or install Python 3.7+      before using <code>ansible</code> plugin from an alternative repository      or local build.</li> </ul> <p>Run a single playbook on the guest:</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: ansible\n    playbook: ansible/packages.yml\n</code></pre> <p>.. code-block:: shell</p> <pre><code>prepare --how ansible --playbook ansible/packages.yml\n</code></pre> <p>Run multiple playbooks in one phase, with extra arguments for <code>ansible-playbook</code>:</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: ansible\n    playbook:\n      - one.yml\n      - two.yml\n    extra-args: '-vvv'\n</code></pre> <p>.. code-block:: shell</p> <pre><code>prepare --how ansible --playbook one.yml --playbook two.yml --extra-args '-vvv'\n</code></pre> <p>Remote playbooks - provided as URLs starting with <code>http://</code> or <code>https://</code>, local playbooks - optionally starting with a <code>file://</code> schema, and playbooks bundled with collections can be referenced as well as local ones, and all kinds can be intermixed:</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: ansible\n    playbook:\n      - https://foo.bar/one.yml\n      - two.yml\n      - file://three.yml\n      - ansible_galaxy_namespace.cool_collection.four\n</code></pre> <p>.. code-block:: shell</p> <pre><code>prepare --how ansible --playbook https://foo.bar/two.yml \\\n                      --playbook two.yml \\\n                      --playbook file://three.yml \\\n                      --playbook ansible_galaxy_namespace.cool_collection.four\n</code></pre> Source code in <code>tmt/steps/prepare/ansible.py</code> <pre><code>@tmt.steps.provides_method('ansible')\nclass PrepareAnsible(tmt.steps.prepare.PreparePlugin[PrepareAnsibleData]):\n    #\n    # This plugin docstring has been reviewed and updated to follow\n    # our documentation best practices. When changing it, please make\n    # sure new changes are following them as well.\n    #\n    # https://tmt.readthedocs.io/en/stable/contribute.html#docs\n    #\n    \"\"\"\n    Run Ansible playbooks against the guest, by running\n    ``ansible-playbook`` for all given playbooks.\n\n    .. note::\n\n       The plugin requires a working Ansible to be available on the\n       test runner.\n\n    .. warning::\n\n        When specifying playbooks with paths:\n\n        * If a metadata tree root exists, all paths must be relative to\n          the metadata tree root.\n        * If the metadata tree root does not exist,\n          all paths must be relative to the current working directory.\n\n    .. warning::\n\n       The plugin may be a subject of various limitations, imposed by\n       Ansible itself:\n\n       * Ansible 2.17+ no longer supports Python 3.6 and older. Guests\n         where Python 3.7+ is not available cannot be prepared with the\n         ``ansible`` plugin. This has been observed when Fedora Rawhide\n         runner is used with CentOS 7 or CentOS Stream 8 guests. Possible\n         workarounds: downgrade Ansible tmt uses, or install Python 3.7+\n         before using ``ansible`` plugin from an alternative repository\n         or local build.\n\n    Run a single playbook on the guest:\n\n    .. code-block:: yaml\n\n        prepare:\n            how: ansible\n            playbook: ansible/packages.yml\n\n    .. code-block:: shell\n\n        prepare --how ansible --playbook ansible/packages.yml\n\n    Run multiple playbooks in one phase, with extra arguments for\n    ``ansible-playbook``:\n\n    .. code-block:: yaml\n\n        prepare:\n            how: ansible\n            playbook:\n              - one.yml\n              - two.yml\n            extra-args: '-vvv'\n\n    .. code-block:: shell\n\n        prepare --how ansible --playbook one.yml --playbook two.yml --extra-args '-vvv'\n\n    Remote playbooks - provided as URLs starting with ``http://`` or\n    ``https://``, local playbooks - optionally starting with a\n    ``file://`` schema, and playbooks bundled with collections can be\n    referenced as well as local ones, and all kinds can be intermixed:\n\n    .. code-block:: yaml\n\n        prepare:\n            how: ansible\n            playbook:\n              - https://foo.bar/one.yml\n              - two.yml\n              - file://three.yml\n              - ansible_galaxy_namespace.cool_collection.four\n\n    .. code-block:: shell\n\n        prepare --how ansible --playbook https://foo.bar/two.yml \\\\\n                              --playbook two.yml \\\\\n                              --playbook file://three.yml \\\\\n                              --playbook ansible_galaxy_namespace.cool_collection.four\n    \"\"\"\n\n    _data_class = PrepareAnsibleData\n\n    @property\n    def _preserved_workdir_members(self) -&gt; set[str]:\n        return {\n            *super()._preserved_workdir_members,\n            # Include directories storing individual playbook logs.\n            *{f'playbook-{i}' for i in range(len(self.data.playbook))},\n        }\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; tmt.steps.PluginOutcome:\n        \"\"\"\n        Prepare the guests\n        \"\"\"\n\n        assert self.step.workdir is not None\n        assert self.workdir is not None\n\n        outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n        # Apply each playbook on the guest\n        for playbook_index, _playbook in enumerate(self.data.playbook):\n            logger.info('playbook', _playbook, 'green')\n\n            playbook_name = f'{self.name} / {_playbook}'\n            lowercased_playbook = _playbook.lower()\n\n            playbook_record_dirpath = self.workdir / f'playbook-{playbook_index}' / guest.safe_name\n            playbook_log_filepath = playbook_record_dirpath / 'output.txt'\n\n            def normalize_remote_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n                assert self.step.workdir is not None  # narrow type\n                root_path = self.step.workdir\n\n                try:\n                    with retry_session(\n                        retries=ENVFILE_RETRY_SESSION_RETRIES,\n                        status_forcelist=DEFAULT_RETRIABLE_HTTP_CODES,\n                    ) as session:\n                        response = session.get(raw_playbook)\n\n                    if not response.ok:\n                        raise PrepareError(f\"Failed to fetch remote playbook '{raw_playbook}'.\")\n\n                except requests.RequestException as exc:\n                    raise PrepareError(\n                        f\"Failed to fetch remote playbook '{raw_playbook}'.\"\n                    ) from exc\n\n                with tempfile.NamedTemporaryFile(\n                    mode='w+b',\n                    prefix='playbook-',\n                    suffix='.yml',\n                    dir=root_path,\n                    delete=False,\n                ) as file:\n                    file.write(response.content)\n                    file.flush()\n\n                    return root_path, Path(file.name).relative_to(root_path)\n\n            def normalize_local_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n                if raw_playbook.startswith('file://'):\n                    return self.step.plan.anchor_path, Path(raw_playbook[7:])\n\n                return self.step.plan.anchor_path, Path(raw_playbook)\n\n            def normalize_collection_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n                return self.step.plan.anchor_path, AnsibleCollectionPlaybook(raw_playbook)\n\n            try:\n                playbook_record_dirpath.mkdir(parents=True, exist_ok=True)\n\n                if lowercased_playbook.startswith(('http://', 'https://')):\n                    playbook_root, playbook = normalize_remote_playbook(lowercased_playbook)\n\n                elif lowercased_playbook.startswith('file://'):\n                    playbook_root, playbook = normalize_local_playbook(lowercased_playbook)\n\n                elif ANSIBLE_COLLECTION_PLAYBOOK_PATTERN.match(lowercased_playbook):\n                    playbook_root, playbook = normalize_collection_playbook(lowercased_playbook)\n\n                else:\n                    playbook_root, playbook = normalize_local_playbook(lowercased_playbook)\n\n                output = guest.ansible(\n                    playbook,\n                    playbook_root=playbook_root,\n                    extra_args=self.data.extra_args,\n                )\n\n            except RunError as exc:\n                self.write(\n                    playbook_log_filepath,\n                    '\\n'.join(\n                        tmt.utils.render_command_report(label=playbook_name, output=exc.output)\n                    ),\n                )\n\n                outcome.results.append(\n                    tmt.result.PhaseResult(\n                        name=playbook_name,\n                        result=ResultOutcome.FAIL,\n                        note=tmt.utils.render_exception_as_notes(exc),\n                        log=[playbook_log_filepath.relative_to(self.step.workdir)],\n                    )\n                )\n\n                outcome.exceptions.append(exc)\n\n                return outcome\n\n            except Exception as exc:\n                outcome.results.append(\n                    tmt.result.PhaseResult(\n                        name=playbook_name,\n                        result=ResultOutcome.ERROR,\n                        note=tmt.utils.render_exception_as_notes(exc),\n                    )\n                )\n\n                outcome.exceptions.append(exc)\n\n                return outcome\n\n            else:\n                self.write(\n                    playbook_log_filepath,\n                    '\\n'.join(tmt.utils.render_command_report(label=playbook_name, output=output)),\n                )\n\n                outcome.results.append(\n                    tmt.result.PhaseResult(\n                        name=playbook_name,\n                        result=ResultOutcome.PASS,\n                        log=[playbook_log_filepath.relative_to(self.step.workdir)],\n                    )\n                )\n\n        return outcome\n\n    def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n        \"\"\"\n        Collect all essential requirements of the plugin.\n\n        Essential requirements of a plugin are necessary for the plugin to\n        perform its basic functionality.\n\n        :returns: a list of requirements.\n        \"\"\"\n\n        return tmt.steps.provision.essential_ansible_requires()\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.ansible.PrepareAnsible.essential_requires","title":"<code>essential_requires()</code>","text":"<p>Collect all essential requirements of the plugin.</p> <p>Essential requirements of a plugin are necessary for the plugin to perform its basic functionality.</p> <p>:returns: a list of requirements.</p> Source code in <code>tmt/steps/prepare/ansible.py</code> <pre><code>def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n    \"\"\"\n    Collect all essential requirements of the plugin.\n\n    Essential requirements of a plugin are necessary for the plugin to\n    perform its basic functionality.\n\n    :returns: a list of requirements.\n    \"\"\"\n\n    return tmt.steps.provision.essential_ansible_requires()\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.ansible.PrepareAnsible.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Prepare the guests</p> Source code in <code>tmt/steps/prepare/ansible.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; tmt.steps.PluginOutcome:\n    \"\"\"\n    Prepare the guests\n    \"\"\"\n\n    assert self.step.workdir is not None\n    assert self.workdir is not None\n\n    outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n    # Apply each playbook on the guest\n    for playbook_index, _playbook in enumerate(self.data.playbook):\n        logger.info('playbook', _playbook, 'green')\n\n        playbook_name = f'{self.name} / {_playbook}'\n        lowercased_playbook = _playbook.lower()\n\n        playbook_record_dirpath = self.workdir / f'playbook-{playbook_index}' / guest.safe_name\n        playbook_log_filepath = playbook_record_dirpath / 'output.txt'\n\n        def normalize_remote_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n            assert self.step.workdir is not None  # narrow type\n            root_path = self.step.workdir\n\n            try:\n                with retry_session(\n                    retries=ENVFILE_RETRY_SESSION_RETRIES,\n                    status_forcelist=DEFAULT_RETRIABLE_HTTP_CODES,\n                ) as session:\n                    response = session.get(raw_playbook)\n\n                if not response.ok:\n                    raise PrepareError(f\"Failed to fetch remote playbook '{raw_playbook}'.\")\n\n            except requests.RequestException as exc:\n                raise PrepareError(\n                    f\"Failed to fetch remote playbook '{raw_playbook}'.\"\n                ) from exc\n\n            with tempfile.NamedTemporaryFile(\n                mode='w+b',\n                prefix='playbook-',\n                suffix='.yml',\n                dir=root_path,\n                delete=False,\n            ) as file:\n                file.write(response.content)\n                file.flush()\n\n                return root_path, Path(file.name).relative_to(root_path)\n\n        def normalize_local_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n            if raw_playbook.startswith('file://'):\n                return self.step.plan.anchor_path, Path(raw_playbook[7:])\n\n            return self.step.plan.anchor_path, Path(raw_playbook)\n\n        def normalize_collection_playbook(raw_playbook: str) -&gt; tuple[Path, AnsibleApplicable]:\n            return self.step.plan.anchor_path, AnsibleCollectionPlaybook(raw_playbook)\n\n        try:\n            playbook_record_dirpath.mkdir(parents=True, exist_ok=True)\n\n            if lowercased_playbook.startswith(('http://', 'https://')):\n                playbook_root, playbook = normalize_remote_playbook(lowercased_playbook)\n\n            elif lowercased_playbook.startswith('file://'):\n                playbook_root, playbook = normalize_local_playbook(lowercased_playbook)\n\n            elif ANSIBLE_COLLECTION_PLAYBOOK_PATTERN.match(lowercased_playbook):\n                playbook_root, playbook = normalize_collection_playbook(lowercased_playbook)\n\n            else:\n                playbook_root, playbook = normalize_local_playbook(lowercased_playbook)\n\n            output = guest.ansible(\n                playbook,\n                playbook_root=playbook_root,\n                extra_args=self.data.extra_args,\n            )\n\n        except RunError as exc:\n            self.write(\n                playbook_log_filepath,\n                '\\n'.join(\n                    tmt.utils.render_command_report(label=playbook_name, output=exc.output)\n                ),\n            )\n\n            outcome.results.append(\n                tmt.result.PhaseResult(\n                    name=playbook_name,\n                    result=ResultOutcome.FAIL,\n                    note=tmt.utils.render_exception_as_notes(exc),\n                    log=[playbook_log_filepath.relative_to(self.step.workdir)],\n                )\n            )\n\n            outcome.exceptions.append(exc)\n\n            return outcome\n\n        except Exception as exc:\n            outcome.results.append(\n                tmt.result.PhaseResult(\n                    name=playbook_name,\n                    result=ResultOutcome.ERROR,\n                    note=tmt.utils.render_exception_as_notes(exc),\n                )\n            )\n\n            outcome.exceptions.append(exc)\n\n            return outcome\n\n        else:\n            self.write(\n                playbook_log_filepath,\n                '\\n'.join(tmt.utils.render_command_report(label=playbook_name, output=output)),\n            )\n\n            outcome.results.append(\n                tmt.result.PhaseResult(\n                    name=playbook_name,\n                    result=ResultOutcome.PASS,\n                    log=[playbook_log_filepath.relative_to(self.step.workdir)],\n                )\n            )\n\n    return outcome\n</code></pre>"},{"location":"plugins/prepare/#feature","title":"feature","text":""},{"location":"plugins/prepare/#tmt.steps.prepare.feature.PrepareFeature","title":"<code>tmt.steps.prepare.feature.PrepareFeature</code>","text":"<p>               Bases: <code>PreparePlugin[PrepareFeatureData]</code></p> <p>Easily enable and disable common features</p> <p>The <code>feature</code> plugin provides a comfortable way to enable and disable some commonly used functionality such as enabling and disabling the <code>epel</code> repository or the <code>fips</code> mode.</p> <p>.. note::</p> <p>The plugin requires a working Ansible to be available on the    test runner.</p> <p>.. warning::</p> <p>The plugin may be a subject of various limitations, imposed by    the fact it uses Ansible to implement some of the features:</p> <ul> <li>Ansible 2.17+ no longer supports Python 3.6 and older. Guests      where Python 3.7+ is not available cannot be prepared with the      <code>feature</code> plugin. This has been observed when Fedora Rawhide      runner is used with CentOS 7 or CentOS Stream 8 guests. Possible      workarounds: downgrade Ansible tmt uses, or install Python 3.7+      before using <code>feature</code> plugin from an alternative repository      or local build.</li> </ul> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: feature\n    epel: disabled\n    crb: enabled\n    fips: enabled\n    ...\n</code></pre> <p>.. code-block:: shell</p> <pre><code>prepare --how feature --epel disabled --crb enabled --fips enabled ...\n</code></pre> <p>.. note::</p> <p>Features available via this plugin are implemented and shipped as    plugins too. The list of available features and configuration keys    will depend on which plugins you have installed.</p> Source code in <code>tmt/steps/prepare/feature/__init__.py</code> <pre><code>@tmt.steps.provides_method('feature')\nclass PrepareFeature(tmt.steps.prepare.PreparePlugin[PrepareFeatureData]):\n    \"\"\"\n    Easily enable and disable common features\n\n    The ``feature`` plugin provides a comfortable way to enable\n    and disable some commonly used functionality such as enabling\n    and disabling the ``epel`` repository or the ``fips`` mode.\n\n    .. note::\n\n       The plugin requires a working Ansible to be available on the\n       test runner.\n\n    .. warning::\n\n       The plugin may be a subject of various limitations, imposed by\n       the fact it uses Ansible to implement some of the features:\n\n       * Ansible 2.17+ no longer supports Python 3.6 and older. Guests\n         where Python 3.7+ is not available cannot be prepared with the\n         ``feature`` plugin. This has been observed when Fedora Rawhide\n         runner is used with CentOS 7 or CentOS Stream 8 guests. Possible\n         workarounds: downgrade Ansible tmt uses, or install Python 3.7+\n         before using ``feature`` plugin from an alternative repository\n         or local build.\n\n    .. code-block:: yaml\n\n        prepare:\n            how: feature\n            epel: disabled\n            crb: enabled\n            fips: enabled\n            ...\n\n    .. code-block:: shell\n\n        prepare --how feature --epel disabled --crb enabled --fips enabled ...\n\n    .. note::\n\n       Features available via this plugin are implemented and shipped as\n       plugins too. The list of available features and configuration keys\n       will depend on which plugins you have installed.\n    \"\"\"\n\n    _data_class = PrepareFeatureData\n\n    @classmethod\n    def get_data_class(cls) -&gt; type[PrepareFeatureData]:\n        \"\"\"\n        Return step data class for this plugin.\n\n        ``prepare/feature`` builds the class in a dynamic way: class'\n        fields are defined by discovered feature plugins. Plugins define\n        their own data classes, these are collected, their fields\n        extracted and merged together with the base data class fields\n        (``name``, ``order``, ...) into the final data class of\n        ``prepare/feature`` plugin.\n        \"\"\"\n\n        # If this class' data class is not `PrepareFeatureData` anymore,\n        # it means this method already constructed the dynamic class.\n        if cls._data_class == PrepareFeatureData:\n            # Collect fields in the base class, we must filter them out\n            # from classes returned by plugins. These fields will be\n            # provided by the base class, and repeating them would raise\n            # an exception.\n            baseclass_fields = list(tmt.container.container_fields(PrepareFeatureData))\n            baseclass_field_names = [field.name for field in baseclass_fields]\n\n            component_fields = [\n                field\n                for plugin in _FEATURE_PLUGIN_REGISTRY.iter_plugins()\n                for field in tmt.container.container_fields(plugin.get_data_class())\n                if field.name not in baseclass_field_names\n            ]\n\n            cls._data_class = cast(\n                type[PrepareFeatureData],\n                dataclasses.make_dataclass(\n                    'PrepareFeatureData',\n                    [(field.name, field.type, field) for field in component_fields],\n                    bases=(PrepareFeatureData,),\n                ),\n            )\n\n            # Fix possibly misleading info: it was observed on CentOS\n            # Stream 9 where Python &amp; Pydantic set `__module__` to be\n            # `types`, resulting in impossible unserialization.\n            # `make_dataclass()` offers `module` parameter, but only\n            # in newer Python versions.\n            cls._data_class.__module__ = cls.__module__\n            cls._data_class.__name__ = 'PrepareFeatureData'\n\n        return cls._data_class\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; tmt.steps.PluginOutcome:\n        \"\"\"\n        Prepare the guests\n        \"\"\"\n\n        outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n        # Nothing to do in dry mode\n        if self.opt('dry'):\n            return outcome\n\n        for plugin_id in _FEATURE_PLUGIN_REGISTRY.iter_plugin_ids():\n            plugin_class = find_plugin(plugin_id)\n\n            value = cast(Optional[str], getattr(self.data, plugin_class.FEATURE_NAME, None))\n            if value is None:\n                continue\n\n            if issubclass(plugin_class, ToggleableFeature):\n                value = value.lower()\n\n                if value == 'enabled':\n                    plugin_class.enable(guest, logger)\n                elif value == 'disabled':\n                    plugin_class.disable(guest, logger)\n                else:\n                    raise tmt.utils.GeneralError(f\"Unknown plugin setting '{value}'.\")\n\n            elif issubclass(plugin_class, Feature):\n                plugin_class.enable(guest, value, logger)\n\n            else:\n                raise tmt.utils.GeneralError(f\"Unknown plugin implementation '{plugin_class}'.\")\n\n        return outcome\n\n    def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n        \"\"\"\n        Collect all essential requirements of the plugin.\n\n        Essential requirements of a plugin are necessary for the plugin to\n        perform its basic functionality.\n\n        :returns: a list of requirements.\n        \"\"\"\n\n        return tmt.steps.provision.essential_ansible_requires()\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.feature.PrepareFeature.essential_requires","title":"<code>essential_requires()</code>","text":"<p>Collect all essential requirements of the plugin.</p> <p>Essential requirements of a plugin are necessary for the plugin to perform its basic functionality.</p> <p>:returns: a list of requirements.</p> Source code in <code>tmt/steps/prepare/feature/__init__.py</code> <pre><code>def essential_requires(self) -&gt; list[tmt.base.Dependency]:\n    \"\"\"\n    Collect all essential requirements of the plugin.\n\n    Essential requirements of a plugin are necessary for the plugin to\n    perform its basic functionality.\n\n    :returns: a list of requirements.\n    \"\"\"\n\n    return tmt.steps.provision.essential_ansible_requires()\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.feature.PrepareFeature.get_data_class","title":"<code>get_data_class()</code>  <code>classmethod</code>","text":"<p>Return step data class for this plugin.</p> <p><code>prepare/feature</code> builds the class in a dynamic way: class' fields are defined by discovered feature plugins. Plugins define their own data classes, these are collected, their fields extracted and merged together with the base data class fields (<code>name</code>, <code>order</code>, ...) into the final data class of <code>prepare/feature</code> plugin.</p> Source code in <code>tmt/steps/prepare/feature/__init__.py</code> <pre><code>@classmethod\ndef get_data_class(cls) -&gt; type[PrepareFeatureData]:\n    \"\"\"\n    Return step data class for this plugin.\n\n    ``prepare/feature`` builds the class in a dynamic way: class'\n    fields are defined by discovered feature plugins. Plugins define\n    their own data classes, these are collected, their fields\n    extracted and merged together with the base data class fields\n    (``name``, ``order``, ...) into the final data class of\n    ``prepare/feature`` plugin.\n    \"\"\"\n\n    # If this class' data class is not `PrepareFeatureData` anymore,\n    # it means this method already constructed the dynamic class.\n    if cls._data_class == PrepareFeatureData:\n        # Collect fields in the base class, we must filter them out\n        # from classes returned by plugins. These fields will be\n        # provided by the base class, and repeating them would raise\n        # an exception.\n        baseclass_fields = list(tmt.container.container_fields(PrepareFeatureData))\n        baseclass_field_names = [field.name for field in baseclass_fields]\n\n        component_fields = [\n            field\n            for plugin in _FEATURE_PLUGIN_REGISTRY.iter_plugins()\n            for field in tmt.container.container_fields(plugin.get_data_class())\n            if field.name not in baseclass_field_names\n        ]\n\n        cls._data_class = cast(\n            type[PrepareFeatureData],\n            dataclasses.make_dataclass(\n                'PrepareFeatureData',\n                [(field.name, field.type, field) for field in component_fields],\n                bases=(PrepareFeatureData,),\n            ),\n        )\n\n        # Fix possibly misleading info: it was observed on CentOS\n        # Stream 9 where Python &amp; Pydantic set `__module__` to be\n        # `types`, resulting in impossible unserialization.\n        # `make_dataclass()` offers `module` parameter, but only\n        # in newer Python versions.\n        cls._data_class.__module__ = cls.__module__\n        cls._data_class.__name__ = 'PrepareFeatureData'\n\n    return cls._data_class\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.feature.PrepareFeature.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Prepare the guests</p> Source code in <code>tmt/steps/prepare/feature/__init__.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; tmt.steps.PluginOutcome:\n    \"\"\"\n    Prepare the guests\n    \"\"\"\n\n    outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n    # Nothing to do in dry mode\n    if self.opt('dry'):\n        return outcome\n\n    for plugin_id in _FEATURE_PLUGIN_REGISTRY.iter_plugin_ids():\n        plugin_class = find_plugin(plugin_id)\n\n        value = cast(Optional[str], getattr(self.data, plugin_class.FEATURE_NAME, None))\n        if value is None:\n            continue\n\n        if issubclass(plugin_class, ToggleableFeature):\n            value = value.lower()\n\n            if value == 'enabled':\n                plugin_class.enable(guest, logger)\n            elif value == 'disabled':\n                plugin_class.disable(guest, logger)\n            else:\n                raise tmt.utils.GeneralError(f\"Unknown plugin setting '{value}'.\")\n\n        elif issubclass(plugin_class, Feature):\n            plugin_class.enable(guest, value, logger)\n\n        else:\n            raise tmt.utils.GeneralError(f\"Unknown plugin implementation '{plugin_class}'.\")\n\n    return outcome\n</code></pre>"},{"location":"plugins/prepare/#install","title":"install","text":""},{"location":"plugins/prepare/#tmt.steps.prepare.install.PrepareInstall","title":"<code>tmt.steps.prepare.install.PrepareInstall</code>","text":"<p>               Bases: <code>PreparePlugin[PrepareInstallData]</code></p> <p>Install packages on the guest.</p> <p>Example config:</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: install\n    copr: psss/tmt\n    package: tmt-all\n    missing: fail\n</code></pre> <p>Use <code>copr</code> for enabling a desired Copr repository and <code>missing</code> to choose whether missing packages should be silently ignored (<code>skip</code>) or a preparation error should be reported (<code>fail</code>), which is the default.</p> <p>One or more RPM packages can be specified under the <code>package</code> attribute. The packages will be installed on the guest. They can either be specified using their names, paths to local rpm files or urls to remote rpms.</p> <p>.. code-block:: yaml</p> <pre><code># Install local rpms using file path\nprepare:\n    how: install\n    package:\n        - tmp/RPMS/noarch/tmt-0.15-1.fc31.noarch.rpm\n        - tmp/RPMS/noarch/python3-tmt-0.15-1.fc31.noarch.rpm\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Install remote packages using url\nprepare:\n    how: install\n    package:\n      - https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n      - https://dl.fedoraproject.org/pub/epel/epel-next-release-latest-8.noarch.rpm\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Install the whole directory, exclude selected packages\nprepare:\n    how: install\n    directory:\n      - tmp/RPMS/noarch\n    exclude:\n      - tmt+all\n      - tmt+provision-virtual\n</code></pre> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: install\n    # Repository with a group owner (@ prefixed) requires quotes, e.g.\n    # copr: \"@osci/rpminspect\"\n    copr: psss/tmt\n    package: tmt-all\n    missing: skip\n</code></pre> <p>Use <code>directory</code> to install all packages from given folder and <code>exclude</code> to skip selected packages (globbing characters are supported as well).</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: install\n    directory: tmp/RPMS/noarch\n    exclude: tmt+provision-virtual\n</code></pre> <p>.. note::</p> <pre><code>When testing ostree booted deployments tmt will use\n``rpm-ostree`` as the package manager to perform the installation of\nrequested packages. The current limitations of the ``rpm-ostree``\nimplementation are:\n\n* Cannot install new version of already installed local rpm.\n* No support for installing debuginfo packages at this time.\n</code></pre> Source code in <code>tmt/steps/prepare/install.py</code> <pre><code>@tmt.steps.provides_method('install')\nclass PrepareInstall(tmt.steps.prepare.PreparePlugin[PrepareInstallData]):\n    \"\"\"\n    Install packages on the guest.\n\n    Example config:\n\n    .. code-block:: yaml\n\n        prepare:\n            how: install\n            copr: psss/tmt\n            package: tmt-all\n            missing: fail\n\n    Use ``copr`` for enabling a desired Copr repository and ``missing`` to choose\n    whether missing packages should be silently ignored (``skip``) or a\n    preparation error should be reported (``fail``), which is the default.\n\n    One or more RPM packages can be specified under the\n    ``package`` attribute. The packages will be installed\n    on the guest. They can either be specified using their\n    names, paths to local rpm files or urls to remote rpms.\n\n    .. code-block:: yaml\n\n        # Install local rpms using file path\n        prepare:\n            how: install\n            package:\n                - tmp/RPMS/noarch/tmt-0.15-1.fc31.noarch.rpm\n                - tmp/RPMS/noarch/python3-tmt-0.15-1.fc31.noarch.rpm\n\n    .. code-block:: yaml\n\n        # Install remote packages using url\n        prepare:\n            how: install\n            package:\n              - https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n              - https://dl.fedoraproject.org/pub/epel/epel-next-release-latest-8.noarch.rpm\n\n    .. code-block:: yaml\n\n        # Install the whole directory, exclude selected packages\n        prepare:\n            how: install\n            directory:\n              - tmp/RPMS/noarch\n            exclude:\n              - tmt+all\n              - tmt+provision-virtual\n\n    .. code-block:: yaml\n\n        prepare:\n            how: install\n            # Repository with a group owner (@ prefixed) requires quotes, e.g.\n            # copr: \"@osci/rpminspect\"\n            copr: psss/tmt\n            package: tmt-all\n            missing: skip\n\n    Use ``directory`` to install all packages from given folder and\n    ``exclude`` to skip selected packages (globbing characters are supported as\n    well).\n\n    .. code-block:: yaml\n\n        prepare:\n            how: install\n            directory: tmp/RPMS/noarch\n            exclude: tmt+provision-virtual\n\n    .. note::\n\n        When testing ostree booted deployments tmt will use\n        ``rpm-ostree`` as the package manager to perform the installation of\n        requested packages. The current limitations of the ``rpm-ostree``\n        implementation are:\n\n        * Cannot install new version of already installed local rpm.\n        * No support for installing debuginfo packages at this time.\n    \"\"\"\n\n    _data_class = PrepareInstallData\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; tmt.steps.PluginOutcome:\n        \"\"\"\n        Perform preparation for the guests\n        \"\"\"\n\n        outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n        # Nothing to do in dry mode\n        if self.is_dry_run:\n            return outcome\n\n        # Pick the right implementation\n        # TODO: it'd be nice to use a \"plugin registry\" and make the\n        # implementations discovered as any other plugins. Package managers are\n        # shipped as plugins, but we still need a matching *installation* class.\n        # But do we really need a class per package manager family? Maybe the\n        # code could be integrated into package manager plugins directly.\n        if guest.facts.package_manager == 'bootc':\n            installer: InstallBase = InstallBootc(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'rpm-ostree':\n            installer = InstallRpmOstree(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'dnf5':\n            installer = InstallDnf5(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'dnf':\n            installer = InstallDnf(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'yum':\n            installer = InstallYum(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'apt':\n            installer = InstallApt(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager == 'apk':\n            installer = InstallApk(\n                logger=logger,\n                parent=self,\n                dependencies=self.data.package,\n                directories=self.data.directory,\n                exclude=self.data.exclude,\n                guest=guest,\n            )\n\n        elif guest.facts.package_manager is None:\n            raise tmt.utils.PrepareError('Unrecognized package manager.')\n\n        else:\n            raise tmt.utils.PrepareError(\n                f\"Package manager '{guest.facts.package_manager}' \"\n                \"is not supported by 'prepare/install'.\"\n            )\n\n        # Enable copr repositories...\n        if isinstance(installer, Copr):\n            installer.enable_copr(self.data.copr)\n\n        # ... and install packages.\n        installer.install()\n\n        return outcome\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.install.PrepareInstall.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Perform preparation for the guests</p> Source code in <code>tmt/steps/prepare/install.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; tmt.steps.PluginOutcome:\n    \"\"\"\n    Perform preparation for the guests\n    \"\"\"\n\n    outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n    # Nothing to do in dry mode\n    if self.is_dry_run:\n        return outcome\n\n    # Pick the right implementation\n    # TODO: it'd be nice to use a \"plugin registry\" and make the\n    # implementations discovered as any other plugins. Package managers are\n    # shipped as plugins, but we still need a matching *installation* class.\n    # But do we really need a class per package manager family? Maybe the\n    # code could be integrated into package manager plugins directly.\n    if guest.facts.package_manager == 'bootc':\n        installer: InstallBase = InstallBootc(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'rpm-ostree':\n        installer = InstallRpmOstree(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'dnf5':\n        installer = InstallDnf5(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'dnf':\n        installer = InstallDnf(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'yum':\n        installer = InstallYum(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'apt':\n        installer = InstallApt(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager == 'apk':\n        installer = InstallApk(\n            logger=logger,\n            parent=self,\n            dependencies=self.data.package,\n            directories=self.data.directory,\n            exclude=self.data.exclude,\n            guest=guest,\n        )\n\n    elif guest.facts.package_manager is None:\n        raise tmt.utils.PrepareError('Unrecognized package manager.')\n\n    else:\n        raise tmt.utils.PrepareError(\n            f\"Package manager '{guest.facts.package_manager}' \"\n            \"is not supported by 'prepare/install'.\"\n        )\n\n    # Enable copr repositories...\n    if isinstance(installer, Copr):\n        installer.enable_copr(self.data.copr)\n\n    # ... and install packages.\n    installer.install()\n\n    return outcome\n</code></pre>"},{"location":"plugins/prepare/#shell","title":"shell","text":""},{"location":"plugins/prepare/#tmt.steps.prepare.shell.PrepareShell","title":"<code>tmt.steps.prepare.shell.PrepareShell</code>","text":"<p>               Bases: <code>PreparePlugin[PrepareShellData]</code></p> <p>Prepare guest using shell (Bash) scripts.</p> <p>Default shell options are applied to the script, see the :ref:<code>/spec/tests/test</code> key specification for more details.</p> <p>.. code-block:: yaml</p> <pre><code>prepare:\n    how: shell\n    script:\n      - sudo dnf install -y 'dnf-command(copr)'\n      - sudo dnf copr enable -y psss/tmt\n      - sudo dnf install -y tmt\n</code></pre> Source code in <code>tmt/steps/prepare/shell.py</code> <pre><code>@tmt.steps.provides_method('shell')\nclass PrepareShell(tmt.steps.prepare.PreparePlugin[PrepareShellData]):\n    \"\"\"\n    Prepare guest using shell (Bash) scripts.\n\n    Default shell options are applied to the script, see the\n    :ref:`/spec/tests/test` key specification for more\n    details.\n\n    .. code-block:: yaml\n\n        prepare:\n            how: shell\n            script:\n              - sudo dnf install -y 'dnf-command(copr)'\n              - sudo dnf copr enable -y psss/tmt\n              - sudo dnf install -y tmt\n    \"\"\"\n\n    _data_class = PrepareShellData\n\n    def go(\n        self,\n        *,\n        guest: 'Guest',\n        environment: Optional[tmt.utils.Environment] = None,\n        logger: tmt.log.Logger,\n    ) -&gt; tmt.steps.PluginOutcome:\n        \"\"\"\n        Prepare the guests\n        \"\"\"\n\n        outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n        environment = environment or tmt.utils.Environment()\n\n        # Give a short summary\n        overview = fmf.utils.listed(self.data.script, 'script')\n        logger.info('overview', f'{overview} found', 'green')\n\n        workdir = self.step.plan.worktree\n        assert workdir is not None  # narrow type\n\n        if not self.is_dry_run:\n            topology = tmt.steps.Topology(self.step.plan.provision.ready_guests)\n            topology.guest = tmt.steps.GuestTopology(guest)\n\n            environment.update(\n                topology.push(\n                    dirpath=workdir,\n                    guest=guest,\n                    logger=logger,\n                    filename_base=safe_filename(\n                        tmt.steps.TEST_TOPOLOGY_FILENAME_BASE, self, guest\n                    ),\n                )\n            )\n\n        prepare_wrapper_filename = safe_filename(PREPARE_WRAPPER_FILENAME, self, guest)\n        prepare_wrapper_path = workdir / prepare_wrapper_filename\n\n        logger.debug('prepare wrapper', prepare_wrapper_path, level=3)\n\n        # Execute each script on the guest (with default shell options)\n        for script in self.data.script:\n            logger.verbose('script', script, 'green')\n            script_with_options = tmt.utils.ShellScript(f'{tmt.utils.SHELL_OPTIONS}; {script}')\n            self.write(prepare_wrapper_path, str(script_with_options), 'w')\n            if not self.is_dry_run:\n                prepare_wrapper_path.chmod(0o755)\n            guest.push(\n                source=prepare_wrapper_path,\n                destination=prepare_wrapper_path,\n                options=[\"-s\", \"-p\", \"--chmod=755\"],\n            )\n            command: ShellScript\n            if guest.become and not guest.facts.is_superuser:\n                command = tmt.utils.ShellScript(f'sudo -E {prepare_wrapper_path}')\n            else:\n                command = tmt.utils.ShellScript(f'{prepare_wrapper_path}')\n            guest.execute(command=command, cwd=workdir, env=environment)\n\n        return outcome\n</code></pre>"},{"location":"plugins/prepare/#tmt.steps.prepare.shell.PrepareShell.go","title":"<code>go(*, guest, environment=None, logger)</code>","text":"<p>Prepare the guests</p> Source code in <code>tmt/steps/prepare/shell.py</code> <pre><code>def go(\n    self,\n    *,\n    guest: 'Guest',\n    environment: Optional[tmt.utils.Environment] = None,\n    logger: tmt.log.Logger,\n) -&gt; tmt.steps.PluginOutcome:\n    \"\"\"\n    Prepare the guests\n    \"\"\"\n\n    outcome = super().go(guest=guest, environment=environment, logger=logger)\n\n    environment = environment or tmt.utils.Environment()\n\n    # Give a short summary\n    overview = fmf.utils.listed(self.data.script, 'script')\n    logger.info('overview', f'{overview} found', 'green')\n\n    workdir = self.step.plan.worktree\n    assert workdir is not None  # narrow type\n\n    if not self.is_dry_run:\n        topology = tmt.steps.Topology(self.step.plan.provision.ready_guests)\n        topology.guest = tmt.steps.GuestTopology(guest)\n\n        environment.update(\n            topology.push(\n                dirpath=workdir,\n                guest=guest,\n                logger=logger,\n                filename_base=safe_filename(\n                    tmt.steps.TEST_TOPOLOGY_FILENAME_BASE, self, guest\n                ),\n            )\n        )\n\n    prepare_wrapper_filename = safe_filename(PREPARE_WRAPPER_FILENAME, self, guest)\n    prepare_wrapper_path = workdir / prepare_wrapper_filename\n\n    logger.debug('prepare wrapper', prepare_wrapper_path, level=3)\n\n    # Execute each script on the guest (with default shell options)\n    for script in self.data.script:\n        logger.verbose('script', script, 'green')\n        script_with_options = tmt.utils.ShellScript(f'{tmt.utils.SHELL_OPTIONS}; {script}')\n        self.write(prepare_wrapper_path, str(script_with_options), 'w')\n        if not self.is_dry_run:\n            prepare_wrapper_path.chmod(0o755)\n        guest.push(\n            source=prepare_wrapper_path,\n            destination=prepare_wrapper_path,\n            options=[\"-s\", \"-p\", \"--chmod=755\"],\n        )\n        command: ShellScript\n        if guest.become and not guest.facts.is_superuser:\n            command = tmt.utils.ShellScript(f'sudo -E {prepare_wrapper_path}')\n        else:\n            command = tmt.utils.ShellScript(f'{prepare_wrapper_path}')\n        guest.execute(command=command, cwd=workdir, env=environment)\n\n    return outcome\n</code></pre>"},{"location":"plugins/provision/","title":"Provision","text":"<p>Provision an environment for testing.</p>"},{"location":"plugins/provision/#artemis","title":"artemis","text":""},{"location":"plugins/provision/#tmt.steps.provision.artemis.ProvisionArtemis","title":"<code>tmt.steps.provision.artemis.ProvisionArtemis</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionArtemisData]</code></p> <p>Provision guest using Artemis backend.</p> <p>Reserve a machine using the Artemis service. Users can specify many requirements, mostly regarding the desired OS, RAM, disk size and more. Most of the HW specifications defined in the :ref:<code>/spec/hardware</code> are supported. Including the :ref:<code>/spec/plans/provision/kickstart</code>.</p> <p>Artemis takes machines from AWS, OpenStack, Beaker or Azure. By default, Artemis handles the selection of a cloud provider to its best abilities and the required specification. However, it is possible to specify the keyword <code>pool</code> and select the desired cloud provider.</p> <p>Artemis project: https://gitlab.com/testing-farm/artemis</p> <p>Minimal configuration could look like this:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: artemis\n    image: Fedora\n    api-url: https://your-artemis.com/\n</code></pre> <p>.. note::</p> <pre><code>When used together with the :ref:`testing-farm` infrastructure\nsome of the options from the first example below will be filled\nfor you by the Testing Farm service.\n</code></pre> <p>.. note::</p> <pre><code>The actual value of ``image`` depends on what images - or \"composes\" as\nArtemis calls them - supports and can deliver.\n</code></pre> <p>.. note::</p> <pre><code>The ``api-url`` can be also given via ``TMT_PLUGIN_PROVISION_ARTEMIS_API_URL``\nenvironment variable.\n</code></pre> <p>Full configuration example:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: artemis\n\n    # Artemis API\n    api-url: https://your-artemis.com/\n    api-version: 0.0.32\n\n    # Mandatory environment properties\n    image: Fedora\n\n    # Optional environment properties\n    arch: aarch64\n    pool: optional-pool-name\n\n    # Provisioning process control (optional)\n    priority-group: custom-priority-group\n    keyname: custom-SSH-key-name\n\n    # Labels to be attached to guest request (optional)\n    user-data:\n        foo: bar\n\n    # Timeouts and deadlines (optional)\n    provision-timeout: 3600\n    provision-tick: 10\n    api-timeout: 600\n    api-retries: 5\n    api-retry-backoff-factor: 1\n</code></pre> Source code in <code>tmt/steps/provision/artemis.py</code> <pre><code>@tmt.steps.provides_method('artemis')\nclass ProvisionArtemis(tmt.steps.provision.ProvisionPlugin[ProvisionArtemisData]):\n    \"\"\"\n    Provision guest using Artemis backend.\n\n    Reserve a machine using the Artemis service.\n    Users can specify many requirements, mostly regarding the\n    desired OS, RAM, disk size and more. Most of the HW specifications\n    defined in the :ref:`/spec/hardware` are supported. Including the\n    :ref:`/spec/plans/provision/kickstart`.\n\n    Artemis takes machines from AWS, OpenStack, Beaker or Azure.\n    By default, Artemis handles the selection of a cloud provider\n    to its best abilities and the required specification. However, it\n    is possible to specify the keyword ``pool`` and select the\n    desired cloud provider.\n\n    Artemis project:\n    https://gitlab.com/testing-farm/artemis\n\n    Minimal configuration could look like this:\n\n    .. code-block:: yaml\n\n        provision:\n            how: artemis\n            image: Fedora\n            api-url: https://your-artemis.com/\n\n    .. note::\n\n        When used together with the :ref:`testing-farm` infrastructure\n        some of the options from the first example below will be filled\n        for you by the Testing Farm service.\n\n    .. note::\n\n        The actual value of ``image`` depends on what images - or \"composes\" as\n        Artemis calls them - supports and can deliver.\n\n    .. note::\n\n        The ``api-url`` can be also given via ``TMT_PLUGIN_PROVISION_ARTEMIS_API_URL``\n        environment variable.\n\n    Full configuration example:\n\n    .. code-block:: yaml\n\n        provision:\n            how: artemis\n\n            # Artemis API\n            api-url: https://your-artemis.com/\n            api-version: 0.0.32\n\n            # Mandatory environment properties\n            image: Fedora\n\n            # Optional environment properties\n            arch: aarch64\n            pool: optional-pool-name\n\n            # Provisioning process control (optional)\n            priority-group: custom-priority-group\n            keyname: custom-SSH-key-name\n\n            # Labels to be attached to guest request (optional)\n            user-data:\n                foo: bar\n\n            # Timeouts and deadlines (optional)\n            provision-timeout: 3600\n            provision-tick: 10\n            api-timeout: 600\n            api-retries: 5\n            api-retry-backoff-factor: 1\n    \"\"\"\n\n    _data_class = ProvisionArtemisData\n    _guest_class = GuestArtemis\n\n    _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the guest\n        \"\"\"\n\n        super().go(logger=logger)\n\n        if self.data.api_version not in SUPPORTED_API_VERSIONS:\n            raise ArtemisProvisionError(f\"API version '{self.data.api_version}' not supported.\")\n\n        data = ArtemisGuestData.from_plugin(self)\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        self._guest = GuestArtemis(\n            logger=self._logger,\n            data=data,\n            name=self.name,\n            parent=self.step,\n        )\n        self._guest.start()\n        self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.artemis.ProvisionArtemis.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the guest</p> Source code in <code>tmt/steps/provision/artemis.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the guest\n    \"\"\"\n\n    super().go(logger=logger)\n\n    if self.data.api_version not in SUPPORTED_API_VERSIONS:\n        raise ArtemisProvisionError(f\"API version '{self.data.api_version}' not supported.\")\n\n    data = ArtemisGuestData.from_plugin(self)\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    self._guest = GuestArtemis(\n        logger=self._logger,\n        data=data,\n        name=self.name,\n        parent=self.step,\n    )\n    self._guest.start()\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#beaker","title":"beaker","text":""},{"location":"plugins/provision/#tmt.steps.provision.mrack.ProvisionBeaker","title":"<code>tmt.steps.provision.mrack.ProvisionBeaker</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionBeakerData]</code></p> <p>Provision guest on Beaker system using mrack.</p> <p>Reserve a machine from the Beaker pool using the <code>mrack</code> plugin. <code>mrack</code> is a multicloud provisioning library supporting multiple cloud services including Beaker.</p> <p>The following two files are used for configuration:</p> <p><code>/etc/tmt/mrack.conf</code> for basic configuration</p> <p><code>/etc/tmt/provisioning-config.yaml</code> configuration per supported provider</p> <p>Beaker installs distribution specified by the <code>image</code> key. If the image can not be translated using the <code>provisioning-config.yaml</code> file mrack passes the image value to Beaker hub and tries to request distribution based on the image value. This way we can bypass default translations and use desired distribution specified like the one in the example below.</p> <p>Minimal configuration could look like this:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: beaker\n    image: fedora\n</code></pre> <p>To trigger a hard reboot of a guest, <code>bkr system-power --action reboot</code> command is executed.</p> <p>.. warning::</p> <pre><code>``bkr system-power`` command is executed on the runner, not\non the guest.\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Specify the distro directly\nprovision:\n    how: beaker\n    image: Fedora-37%\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Set custom whiteboard description (added in 1.30)\nprovision:\n    how: beaker\n    whiteboard: Just a smoke test for now\n</code></pre> Source code in <code>tmt/steps/provision/mrack.py</code> <pre><code>@tmt.steps.provides_method('beaker')\nclass ProvisionBeaker(tmt.steps.provision.ProvisionPlugin[ProvisionBeakerData]):\n    \"\"\"\n    Provision guest on Beaker system using mrack.\n\n    Reserve a machine from the Beaker pool using the ``mrack``\n    plugin. ``mrack`` is a multicloud provisioning library\n    supporting multiple cloud services including Beaker.\n\n    The following two files are used for configuration:\n\n    ``/etc/tmt/mrack.conf`` for basic configuration\n\n    ``/etc/tmt/provisioning-config.yaml`` configuration per supported provider\n\n    Beaker installs distribution specified by the ``image``\n    key. If the image can not be translated using the\n    ``provisioning-config.yaml`` file mrack passes the image\n    value to Beaker hub and tries to request distribution\n    based on the image value. This way we can bypass default\n    translations and use desired distribution specified like\n    the one in the example below.\n\n    Minimal configuration could look like this:\n\n    .. code-block:: yaml\n\n        provision:\n            how: beaker\n            image: fedora\n\n    To trigger a hard reboot of a guest, ``bkr system-power --action reboot``\n    command is executed.\n\n    .. warning::\n\n        ``bkr system-power`` command is executed on the runner, not\n        on the guest.\n\n    .. code-block:: yaml\n\n        # Specify the distro directly\n        provision:\n            how: beaker\n            image: Fedora-37%\n\n    .. code-block:: yaml\n\n        # Set custom whiteboard description (added in 1.30)\n        provision:\n            how: beaker\n            whiteboard: Just a smoke test for now\n    \"\"\"\n\n    _data_class = ProvisionBeakerData\n    _guest_class = GuestBeaker\n\n    # _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    # data argument should be a \"Optional[GuestData]\" type but we would like to use\n    # BeakerGuestData created here ignoring the override will make mypy calm\n    def wake(self, data: Optional[BeakerGuestData] = None) -&gt; None:  # type: ignore[override]\n        \"\"\"\n        Wake up the plugin, process data, apply options\n        \"\"\"\n\n        super().wake(data=data)\n\n        if data:\n            self._guest = GuestBeaker(\n                data=data,\n                name=self.name,\n                parent=self.step,\n                logger=self._logger,\n            )\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the guest\n        \"\"\"\n\n        super().go(logger=logger)\n\n        data = BeakerGuestData.from_plugin(self)\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        if data.hardware:\n            data.hardware.report_support(\n                names=list(_CONSTRAINT_TRANSFORMERS.keys()), logger=self._logger\n            )\n\n        self._guest = GuestBeaker(\n            data=data,\n            name=self.name,\n            parent=self.step,\n            logger=self._logger,\n        )\n        self._guest.start()\n        self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.mrack.ProvisionBeaker.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the guest</p> Source code in <code>tmt/steps/provision/mrack.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the guest\n    \"\"\"\n\n    super().go(logger=logger)\n\n    data = BeakerGuestData.from_plugin(self)\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    if data.hardware:\n        data.hardware.report_support(\n            names=list(_CONSTRAINT_TRANSFORMERS.keys()), logger=self._logger\n        )\n\n    self._guest = GuestBeaker(\n        data=data,\n        name=self.name,\n        parent=self.step,\n        logger=self._logger,\n    )\n    self._guest.start()\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.mrack.ProvisionBeaker.wake","title":"<code>wake(data=None)</code>","text":"<p>Wake up the plugin, process data, apply options</p> Source code in <code>tmt/steps/provision/mrack.py</code> <pre><code>def wake(self, data: Optional[BeakerGuestData] = None) -&gt; None:  # type: ignore[override]\n    \"\"\"\n    Wake up the plugin, process data, apply options\n    \"\"\"\n\n    super().wake(data=data)\n\n    if data:\n        self._guest = GuestBeaker(\n            data=data,\n            name=self.name,\n            parent=self.step,\n            logger=self._logger,\n        )\n</code></pre>"},{"location":"plugins/provision/#bootc","title":"bootc","text":""},{"location":"plugins/provision/#tmt.steps.provision.bootc.ProvisionBootc","title":"<code>tmt.steps.provision.bootc.ProvisionBootc</code>","text":"<p>               Bases: <code>ProvisionPlugin[BootcData]</code></p> <p>Provision a local virtual machine using a bootc container image</p> <p>Minimal config which uses the CentOS Stream 9 bootc image:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: bootc\n    container-image: quay.io/centos-bootc/centos-bootc:stream9\n    rootfs: xfs\n</code></pre> <p>Here's a config example using a Containerfile:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: bootc\n    container-file: \"./my-custom-image.containerfile\"\n    container-file-workdir: .\n    image-builder: quay.io/centos-bootc/bootc-image-builder:stream9\n    rootfs: ext4\n    disk: 100\n</code></pre> <p>Another config example using an image that already includes tmt dependencies:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: bootc\n    add-tmt-dependencies: false\n    container-image: localhost/my-image-with-deps\n    rootfs: btrfs\n</code></pre> <p>This plugin is an extension of the virtual.testcloud plugin. Essentially, it takes a container image as input, builds a bootc disk image from the container image, then uses the virtual.testcloud plugin to create a virtual machine using the bootc disk image.</p> <p>The bootc disk creation requires running podman as root. The plugin will automatically check if the current podman connection is rootless. If it is, a podman machine will be spun up and used to build the bootc disk.</p> <p>To trigger hard reboot of a guest, plugin uses testcloud API. It is also used to trigger soft reboot unless a custom reboot command was specified via <code>tmt-reboot -c ...</code>.</p> Source code in <code>tmt/steps/provision/bootc.py</code> <pre><code>@tmt.steps.provides_method('bootc')\nclass ProvisionBootc(tmt.steps.provision.ProvisionPlugin[BootcData]):\n    \"\"\"\n    Provision a local virtual machine using a bootc container image\n\n    Minimal config which uses the CentOS Stream 9 bootc image:\n\n    .. code-block:: yaml\n\n        provision:\n            how: bootc\n            container-image: quay.io/centos-bootc/centos-bootc:stream9\n            rootfs: xfs\n\n    Here's a config example using a Containerfile:\n\n    .. code-block:: yaml\n\n        provision:\n            how: bootc\n            container-file: \"./my-custom-image.containerfile\"\n            container-file-workdir: .\n            image-builder: quay.io/centos-bootc/bootc-image-builder:stream9\n            rootfs: ext4\n            disk: 100\n\n    Another config example using an image that already includes tmt\n    dependencies:\n\n    .. code-block:: yaml\n\n        provision:\n            how: bootc\n            add-tmt-dependencies: false\n            container-image: localhost/my-image-with-deps\n            rootfs: btrfs\n\n    This plugin is an extension of the virtual.testcloud plugin.\n    Essentially, it takes a container image as input, builds a\n    bootc disk image from the container image, then uses the virtual.testcloud\n    plugin to create a virtual machine using the bootc disk image.\n\n    The bootc disk creation requires running podman as root. The plugin will\n    automatically check if the current podman connection is rootless. If it is,\n    a podman machine will be spun up and used to build the bootc disk.\n\n    To trigger hard reboot of a guest, plugin uses testcloud API. It is\n    also used to trigger soft reboot unless a custom reboot command was\n    specified via ``tmt-reboot -c ...``.\n    \"\"\"\n\n    _data_class = BootcData\n    _guest_class = GuestTestcloud\n    _guest = None\n    _rootless = True\n\n    @property\n    def is_in_standalone_mode(self) -&gt; bool:\n        \"\"\"\n        Enable standalone mode when build_disk_image_only is True\n        \"\"\"\n\n        if self.data.build_disk_image_only:\n            return True\n        return super().is_in_standalone_mode\n\n    def _get_id(self) -&gt; str:\n        # FIXME: cast() - https://github.com/teemtee/tmt/issues/1372\n        parent = cast(tmt.steps.provision.Provision, self.parent)\n        assert parent.plan is not None\n        assert parent.plan.my_run is not None\n        assert parent.plan.my_run.unique_id is not None\n        return parent.plan.my_run.unique_id\n\n    def _expand_path(self, relative_path: str) -&gt; str:\n        \"\"\"\n        Expand the path to the full path relative to the current working dir\n        \"\"\"\n\n        if relative_path.startswith(\"/\"):\n            return relative_path\n        return f\"{os.getcwd()}/{relative_path}\"\n\n    def _build_derived_image(self, base_image: str) -&gt; str:\n        \"\"\"\n        Build a \"derived\" container image from the base image with tmt dependencies added\n        \"\"\"\n\n        assert self.workdir is not None  # narrow type\n\n        self._logger.debug(\"Build modified container image with necessary tmt packages/config.\")\n        containerfile_template = '''\n            FROM {{ base_image }}\n\n            RUN \\\n            dnf -y install cloud-init rsync &amp;&amp; \\\n            ln -s ../cloud-init.target /usr/lib/systemd/system/default.target.wants &amp;&amp; \\\n            rm /usr/local -rf &amp;&amp; ln -sr /var/usrlocal /usr/local &amp;&amp; mkdir -p /var/usrlocal/bin &amp;&amp; \\\n            dnf clean all\n        '''\n        containerfile_parsed = render_template(containerfile_template, base_image=base_image)\n        (self.workdir / 'Containerfile').write_text(containerfile_parsed)\n\n        image_tag = f'localhost/tmtmodified-{self._get_id()}'\n        tmt.utils.Command(\n            \"podman\",\n            \"build\",\n            f'{self.workdir}',\n            \"-f\",\n            f'{self.workdir}/Containerfile',\n            \"-t\",\n            image_tag,\n        ).run(\n            cwd=self.workdir,\n            stream_output=True,\n            logger=self._logger,\n            env=PODMAN_ENV if self._rootless else None,\n        )\n\n        return image_tag\n\n    def _build_base_image(self, containerfile: str, workdir: str) -&gt; str:\n        \"\"\"\n        Build the \"base\" or user supplied container image\n        \"\"\"\n\n        image_tag = f'localhost/tmtbase-{self._get_id()}'\n        self._logger.debug(\"Build container image.\")\n        tmt.utils.Command(\n            \"podman\",\n            \"build\",\n            self._expand_path(workdir),\n            \"-f\",\n            self._expand_path(containerfile),\n            \"-t\",\n            image_tag,\n        ).run(\n            cwd=self.workdir,\n            stream_output=True,\n            logger=self._logger,\n            env=PODMAN_ENV if self._rootless else None,\n        )\n        return image_tag\n\n    def _build_bootc_disk(self, containerimage: str, image_builder: str, rootfs: str) -&gt; None:\n        \"\"\"\n        Build the bootc disk from a container image using bootc image builder\n        \"\"\"\n\n        self._logger.debug(\"Build bootc disk image.\")\n\n        tmt.utils.Command(\n            \"podman\",\n            \"run\",\n            \"--rm\",\n            \"--privileged\",\n            \"-v\",\n            f'{CONTAINER_STORAGE_DIR}:{CONTAINER_STORAGE_DIR}',\n            \"--security-opt\",\n            \"label=type:unconfined_t\",\n            \"-v\",\n            f\"{self.workdir}:/output\",\n            image_builder,\n            \"build\",\n            \"--type\",\n            \"qcow2\",\n            \"--rootfs\",\n            rootfs,\n            \"--local\",\n            containerimage,\n        ).run(\n            cwd=self.workdir,\n            stream_output=True,\n            logger=self._logger,\n            env=PODMAN_ENV if self._rootless else None,\n        )\n\n    def _init_podman_machine(self) -&gt; None:\n        try:\n            tmt.utils.Command(\"podman\", \"machine\", \"rm\", \"-f\", PODMAN_MACHINE_NAME).run(\n                cwd=self.workdir, stream_output=True, logger=self._logger\n            )\n        except BaseException:\n            self._logger.debug(\"Unable to remove existing podman machine (it might not exist).\")\n\n        self._logger.debug(\"Initialize podman machine.\")\n        # fmt: off\n        tmt.utils.Command(\n            \"podman\", \"machine\", \"init\", \"--rootful\",\n            \"--disk-size\", f\"{DEFAULT_PODMAN_MACHINE_DISK_SIZE.magnitude}\",\n            \"--memory\", f\"{DEFAULT_PODMAN_MACHINE_MEM.magnitude}\",\n            \"--cpus\", f\"{DEFAULT_PODMAN_MACHINE_CPU}\",\n            \"-v\", f\"{DEFAULT_TMP_PATH}:{DEFAULT_TMP_PATH}\",\n            \"-v\", \"$HOME:$HOME\",\n            PODMAN_MACHINE_NAME,\n        ).run(cwd=self.workdir, stream_output=True, logger=self._logger)\n        # fmt: on\n\n        self._logger.debug(\"Start podman machine.\")\n        tmt.utils.Command(\"podman\", \"machine\", \"start\", PODMAN_MACHINE_NAME).run(\n            cwd=self.workdir, stream_output=True, logger=self._logger\n        )\n\n    def _check_if_podman_is_rootless(self) -&gt; None:\n        output = tmt.utils.Command(\n            \"podman\", \"info\", \"--format\", \"{{.Host.Security.Rootless}}\"\n        ).run(cwd=self.workdir, stream_output=True, logger=self._logger)\n        self._rootless = output.stdout == \"true\\n\"\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the bootc instance\n        \"\"\"\n\n        super().go(logger=logger)\n\n        self._check_if_podman_is_rootless()\n\n        data = BootcData.from_plugin(self)\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        if self._rootless and not self.is_dry_run:\n            self._init_podman_machine()\n\n        # Image of file have to provided\n        if data.container_image is None and data.container_file is None:\n            raise tmt.utils.ProvisionError(\n                \"Either 'container-file' or 'container-image' must be specified.\"\n            )\n\n        containerimage: Optional[str] = None\n\n        if not self.is_dry_run:\n            # Use provided container image\n            if data.container_image is not None:\n                containerimage = data.container_image\n                if data.add_tmt_dependencies:\n                    containerimage = self._build_derived_image(data.container_image)\n                self._build_bootc_disk(containerimage, data.image_builder, data.rootfs)\n\n            # Build image according to the container file\n            elif data.container_file is not None:\n                containerimage = self._build_base_image(\n                    data.container_file, data.container_file_workdir\n                )\n                if data.add_tmt_dependencies:\n                    containerimage = self._build_derived_image(containerimage)\n                self._build_bootc_disk(containerimage, data.image_builder, data.rootfs)\n\n        # Set unique disk file name, each plan will have its own disk file\n        disk_file_name = Path(\n            render_template(\n                'disk-{{ PHASE.parent.plan.my_run.unique_id }}'\n                '-{{ PHASE.parent.plan.pathless_safe_name }}'\n                '-{{ PHASE.safe_name }}.qcow2',\n                PHASE=self,\n            )\n        )\n\n        assert self.workdir is not None\n\n        image_dir = self.workdir / 'qcow2'\n\n        # Rename disk file name to unique file name\n        built_image = image_dir / 'disk.qcow2'\n        renamed_image = image_dir / disk_file_name\n\n        if not self.is_dry_run:\n            built_image.rename(renamed_image)\n        data.image = f\"file://{renamed_image}\"\n\n        if data.build_disk_image_only:\n            self.info(\"The disk image is converted and saved\")\n            click.echo(tmt.log.indent(data.image, level=2))\n            return\n\n        self._guest = GuestBootc(\n            logger=self._logger,\n            data=data,\n            name=self.name,\n            parent=self.step,\n            containerimage=containerimage,\n            rootless=self._rootless,\n        )\n        self._guest.start()\n        self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.bootc.ProvisionBootc.is_in_standalone_mode","title":"<code>is_in_standalone_mode</code>  <code>property</code>","text":"<p>Enable standalone mode when build_disk_image_only is True</p>"},{"location":"plugins/provision/#tmt.steps.provision.bootc.ProvisionBootc.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the bootc instance</p> Source code in <code>tmt/steps/provision/bootc.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the bootc instance\n    \"\"\"\n\n    super().go(logger=logger)\n\n    self._check_if_podman_is_rootless()\n\n    data = BootcData.from_plugin(self)\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    if self._rootless and not self.is_dry_run:\n        self._init_podman_machine()\n\n    # Image of file have to provided\n    if data.container_image is None and data.container_file is None:\n        raise tmt.utils.ProvisionError(\n            \"Either 'container-file' or 'container-image' must be specified.\"\n        )\n\n    containerimage: Optional[str] = None\n\n    if not self.is_dry_run:\n        # Use provided container image\n        if data.container_image is not None:\n            containerimage = data.container_image\n            if data.add_tmt_dependencies:\n                containerimage = self._build_derived_image(data.container_image)\n            self._build_bootc_disk(containerimage, data.image_builder, data.rootfs)\n\n        # Build image according to the container file\n        elif data.container_file is not None:\n            containerimage = self._build_base_image(\n                data.container_file, data.container_file_workdir\n            )\n            if data.add_tmt_dependencies:\n                containerimage = self._build_derived_image(containerimage)\n            self._build_bootc_disk(containerimage, data.image_builder, data.rootfs)\n\n    # Set unique disk file name, each plan will have its own disk file\n    disk_file_name = Path(\n        render_template(\n            'disk-{{ PHASE.parent.plan.my_run.unique_id }}'\n            '-{{ PHASE.parent.plan.pathless_safe_name }}'\n            '-{{ PHASE.safe_name }}.qcow2',\n            PHASE=self,\n        )\n    )\n\n    assert self.workdir is not None\n\n    image_dir = self.workdir / 'qcow2'\n\n    # Rename disk file name to unique file name\n    built_image = image_dir / 'disk.qcow2'\n    renamed_image = image_dir / disk_file_name\n\n    if not self.is_dry_run:\n        built_image.rename(renamed_image)\n    data.image = f\"file://{renamed_image}\"\n\n    if data.build_disk_image_only:\n        self.info(\"The disk image is converted and saved\")\n        click.echo(tmt.log.indent(data.image, level=2))\n        return\n\n    self._guest = GuestBootc(\n        logger=self._logger,\n        data=data,\n        name=self.name,\n        parent=self.step,\n        containerimage=containerimage,\n        rootless=self._rootless,\n    )\n    self._guest.start()\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#connect","title":"connect","text":""},{"location":"plugins/provision/#tmt.steps.provision.connect.ProvisionConnect","title":"<code>tmt.steps.provision.connect.ProvisionConnect</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionConnectData]</code></p> <p>Connect to a provisioned guest using SSH.</p> <p>Do not provision any system, tests will be executed directly on the machine that has been already provisioned. Use provided authentication information to connect to it over SSH.</p> <p>Private key authentication (using <code>sudo</code> to run scripts):</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: connect\n    guest: host.example.org\n    user: fedora\n    become: true\n    key: /home/psss/.ssh/example_rsa\n</code></pre> <p>Password authentication:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: connect\n    guest: host.example.org\n    user: root\n    password: secret\n</code></pre> <p>User defaults to <code>root</code>, so if you have private key correctly set the minimal configuration can look like this:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: connect\n    guest: host.example.org\n</code></pre> <p>To support hard reboot of a guest, <code>hard-reboot</code> must be set to an executable command or script. Without this key set, hard reboot will remain unsupported and result in an error. In comparison, <code>soft-reboot</code> is optional, but if set, the given command will be preferred over the default soft reboot command, <code>reboot</code>:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n  how: connect\n  hard-reboot: virsh reboot my-example-vm\n  soft-reboot: ssh root@my-example-vm 'shutdown -r now'\n</code></pre> <p>.. code-block:: shell</p> <pre><code>provision --how connect \\\n          --hard-reboot=\"virsh reboot my-example-vm\" \\\n          --soft-reboot=\"ssh root@my-example-vm 'shutdown -r now'\"\n</code></pre> <p>.. warning::</p> <pre><code>Both ``hard-reboot`` and ``soft-reboot`` commands are executed\non the runner, not on the guest.\n</code></pre> Source code in <code>tmt/steps/provision/connect.py</code> <pre><code>@tmt.steps.provides_method('connect')\nclass ProvisionConnect(tmt.steps.provision.ProvisionPlugin[ProvisionConnectData]):\n    #\n    # This plugin docstring has been reviewed and updated to follow\n    # our documentation best practices. When changing it, please make\n    # sure new changes are following them as well.\n    #\n    # https://tmt.readthedocs.io/en/stable/contribute.html#docs\n    #\n    \"\"\"\n    Connect to a provisioned guest using SSH.\n\n    Do not provision any system, tests will be executed directly on the\n    machine that has been already provisioned. Use provided\n    authentication information to connect to it over SSH.\n\n\n\n    Private key authentication (using ``sudo`` to run scripts):\n\n    .. code-block:: yaml\n\n        provision:\n            how: connect\n            guest: host.example.org\n            user: fedora\n            become: true\n            key: /home/psss/.ssh/example_rsa\n\n    Password authentication:\n\n    .. code-block:: yaml\n\n        provision:\n            how: connect\n            guest: host.example.org\n            user: root\n            password: secret\n\n    User defaults to ``root``, so if you have private key correctly set\n    the minimal configuration can look like this:\n\n    .. code-block:: yaml\n\n        provision:\n            how: connect\n            guest: host.example.org\n\n\n\n    To support hard reboot of a guest, ``hard-reboot`` must be set to\n    an executable command or script. Without this key set, hard reboot\n    will remain unsupported and result in an error. In comparison,\n    ``soft-reboot`` is optional, but if set, the given command will be\n    preferred over the default soft reboot command, ``reboot``:\n\n    .. code-block:: yaml\n\n        provision:\n          how: connect\n          hard-reboot: virsh reboot my-example-vm\n          soft-reboot: ssh root@my-example-vm 'shutdown -r now'\n\n    .. code-block:: shell\n\n        provision --how connect \\\\\n                  --hard-reboot=\"virsh reboot my-example-vm\" \\\\\n                  --soft-reboot=\"ssh root@my-example-vm 'shutdown -r now'\"\n\n    .. warning::\n\n        Both ``hard-reboot`` and ``soft-reboot`` commands are executed\n        on the runner, not on the guest.\n    \"\"\"\n\n    _data_class = ProvisionConnectData\n    _guest_class = GuestConnect\n\n    _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Prepare the connection\n        \"\"\"\n\n        super().go(logger=logger)\n\n        # Check guest and auth info\n        if not self.data.guest:\n            raise tmt.utils.SpecificationError('Provide a host name or an ip address to connect.')\n\n        if (self.data.soft_reboot or self.data.hard_reboot) and not self.is_feeling_safe:\n            raise tmt.utils.GeneralError(\n                \"Custom soft and hard reboot commands are allowed \"\n                \"only with the '--feeling-safe' option.\"\n            )\n\n        data = ConnectGuestData.from_plugin(self)\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        if data.password:\n            self.debug('Using password authentication.')\n\n        else:\n            self.debug('Using private key authentication.')\n\n        if data.hardware and data.hardware.constraint:\n            self.warn(\"The 'connect' provision plugin does not support hardware requirements.\")\n\n        # And finally create the guest\n        self._guest = GuestConnect(\n            logger=self._logger, data=data, name=self.name, parent=self.step\n        )\n        self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.connect.ProvisionConnect.go","title":"<code>go(*, logger=None)</code>","text":"<p>Prepare the connection</p> Source code in <code>tmt/steps/provision/connect.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Prepare the connection\n    \"\"\"\n\n    super().go(logger=logger)\n\n    # Check guest and auth info\n    if not self.data.guest:\n        raise tmt.utils.SpecificationError('Provide a host name or an ip address to connect.')\n\n    if (self.data.soft_reboot or self.data.hard_reboot) and not self.is_feeling_safe:\n        raise tmt.utils.GeneralError(\n            \"Custom soft and hard reboot commands are allowed \"\n            \"only with the '--feeling-safe' option.\"\n        )\n\n    data = ConnectGuestData.from_plugin(self)\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    if data.password:\n        self.debug('Using password authentication.')\n\n    else:\n        self.debug('Using private key authentication.')\n\n    if data.hardware and data.hardware.constraint:\n        self.warn(\"The 'connect' provision plugin does not support hardware requirements.\")\n\n    # And finally create the guest\n    self._guest = GuestConnect(\n        logger=self._logger, data=data, name=self.name, parent=self.step\n    )\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#container","title":"container","text":""},{"location":"plugins/provision/#tmt.steps.provision.podman.ProvisionPodman","title":"<code>tmt.steps.provision.podman.ProvisionPodman</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionPodmanData]</code></p> <p>Create a new container using <code>podman</code>.</p> <p>Example config:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: container\n    image: fedora:latest\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Use an image with a non-root user with sudo privileges,\n# and run scripts with sudo.\nprovision:\n    how: container\n    image: image with non-root user with sudo privileges\n    user: tester\n    become: true\n</code></pre> <p>In order to always pull the fresh container image use <code>pull: true</code>.</p> <p>In order to run the container with different user as the default <code>root</code>, use <code>user: USER</code>.</p> <p>Container-backed guests do not support soft reboots or custom reboot commands. Soft reboot or <code>tmt-reboot -c ...</code> will result in an error.</p> Source code in <code>tmt/steps/provision/podman.py</code> <pre><code>@tmt.steps.provides_method(\n    'container',\n    installation_hint=\"\"\"\n        Make sure ``podman`` is installed and configured, it is required for container-backed\n        guests provided by ``provision/container`` plugin.\n\n        To quickly test ``podman`` functionality, you can try running ``podman images`` or\n        ``podman run --rm -it fedora:latest``.\n\n        * Users who installed tmt from system repositories should install\n          ``tmt+provision-container`` package.\n        * Users who installed tmt from PyPI should also install ``tmt+provision-container``\n          package, as it will install required system dependencies. After doing so, they should\n          install ``tmt[provision-container]`` extra.\n    \"\"\",\n)\nclass ProvisionPodman(tmt.steps.provision.ProvisionPlugin[ProvisionPodmanData]):\n    \"\"\"\n    Create a new container using ``podman``.\n\n    Example config:\n\n    .. code-block:: yaml\n\n        provision:\n            how: container\n            image: fedora:latest\n\n    .. code-block:: yaml\n\n        # Use an image with a non-root user with sudo privileges,\n        # and run scripts with sudo.\n        provision:\n            how: container\n            image: image with non-root user with sudo privileges\n            user: tester\n            become: true\n\n    In order to always pull the fresh container image use ``pull: true``.\n\n    In order to run the container with different user as the default ``root``,\n    use ``user: USER``.\n\n    Container-backed guests do not support soft reboots or custom reboot\n    commands. Soft reboot or ``tmt-reboot -c ...`` will result in an\n    error.\n    \"\"\"\n\n    _data_class = ProvisionPodmanData\n    _guest_class = GuestContainer\n\n    _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    def default(self, option: str, default: Any = None) -&gt; Any:\n        \"\"\"\n        Return default data for given option\n        \"\"\"\n\n        if option == 'pull':\n            return self.data.force_pull\n\n        return super().default(option, default=default)\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the container\n        \"\"\"\n\n        super().go(logger=logger)\n\n        # Prepare data for the guest instance\n        data = PodmanGuestData.from_plugin(self)\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        if data.hardware and data.hardware.constraint:\n            self.warn(\"The 'container' provision plugin does not support hardware requirements.\")\n\n        # Create a new GuestTestcloud instance and start it\n        self._guest = GuestContainer(\n            logger=self._logger,\n            data=data,\n            name=self.name,\n            parent=self.step,\n        )\n        self._guest.start()\n        self._guest.setup()\n\n        # TODO: this might be allowed with `--privileged`...\n        self._guest.facts.capabilities[GuestCapability.SYSLOG_ACTION_READ_ALL] = False\n        # ... while this seems to be forbidden completely.\n        self._guest.facts.capabilities[GuestCapability.SYSLOG_ACTION_READ_CLEAR] = False\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.podman.ProvisionPodman.default","title":"<code>default(option, default=None)</code>","text":"<p>Return default data for given option</p> Source code in <code>tmt/steps/provision/podman.py</code> <pre><code>def default(self, option: str, default: Any = None) -&gt; Any:\n    \"\"\"\n    Return default data for given option\n    \"\"\"\n\n    if option == 'pull':\n        return self.data.force_pull\n\n    return super().default(option, default=default)\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.podman.ProvisionPodman.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the container</p> Source code in <code>tmt/steps/provision/podman.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the container\n    \"\"\"\n\n    super().go(logger=logger)\n\n    # Prepare data for the guest instance\n    data = PodmanGuestData.from_plugin(self)\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    if data.hardware and data.hardware.constraint:\n        self.warn(\"The 'container' provision plugin does not support hardware requirements.\")\n\n    # Create a new GuestTestcloud instance and start it\n    self._guest = GuestContainer(\n        logger=self._logger,\n        data=data,\n        name=self.name,\n        parent=self.step,\n    )\n    self._guest.start()\n    self._guest.setup()\n\n    # TODO: this might be allowed with `--privileged`...\n    self._guest.facts.capabilities[GuestCapability.SYSLOG_ACTION_READ_ALL] = False\n    # ... while this seems to be forbidden completely.\n    self._guest.facts.capabilities[GuestCapability.SYSLOG_ACTION_READ_CLEAR] = False\n</code></pre>"},{"location":"plugins/provision/#local","title":"local","text":""},{"location":"plugins/provision/#tmt.steps.provision.local.ProvisionLocal","title":"<code>tmt.steps.provision.local.ProvisionLocal</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionLocalData]</code></p> <p>Use the localhost for the test execution.</p> <p>Do not provision any system, tests will be executed directly on the localhost.</p> <p>.. warning::</p> <pre><code>In general, it is not recommended to run tests on your local\nmachine as there might be security risks. Run only those tests\nwhich you know are safe so that you don't destroy your\nworkstation ;-)\n\nFrom tmt version 1.38, the ``--feeling-safe`` option or\nthe ``TMT_FEELING_SAFE=1`` environment variable is\nrequired in order to use the ``local`` provision plugin.\n</code></pre> <p>Using the plugin:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: local\n</code></pre> <p>.. code-block:: shell</p> <pre><code>provision --how local\n</code></pre> <p>.. note::</p> <pre><code>``tmt run`` is expected to be executed under a non-privileged\nuser account. For some actions on the localhost, e.g.\ninstallation of test requirements, ``local`` will require\nelevated privileges, either by running under ``root``\naccount, or by using ``sudo`` to run the sensitive commands. You\nmay be asked for a password in such cases.\n</code></pre> <p>.. note::</p> <pre><code>Neither hard nor soft reboot is supported.\n</code></pre> Source code in <code>tmt/steps/provision/local.py</code> <pre><code>@tmt.steps.provides_method('local')\nclass ProvisionLocal(tmt.steps.provision.ProvisionPlugin[ProvisionLocalData]):\n    #\n    # This plugin docstring has been reviewed and updated to follow\n    # our documentation best practices. When changing it, please make\n    # sure new changes are following them as well.\n    #\n    # https://tmt.readthedocs.io/en/stable/contribute.html#docs\n    #\n    \"\"\"\n    Use the localhost for the test execution.\n\n    Do not provision any system, tests will be executed directly on the\n    localhost.\n\n    .. warning::\n\n        In general, it is not recommended to run tests on your local\n        machine as there might be security risks. Run only those tests\n        which you know are safe so that you don't destroy your\n        workstation ;-)\n\n        From tmt version 1.38, the ``--feeling-safe`` option or\n        the ``TMT_FEELING_SAFE=1`` environment variable is\n        required in order to use the ``local`` provision plugin.\n\n    Using the plugin:\n\n    .. code-block:: yaml\n\n        provision:\n            how: local\n\n    .. code-block:: shell\n\n        provision --how local\n\n    .. note::\n\n        ``tmt run`` is expected to be executed under a non-privileged\n        user account. For some actions on the localhost, e.g.\n        installation of test requirements, ``local`` will require\n        elevated privileges, either by running under ``root``\n        account, or by using ``sudo`` to run the sensitive commands. You\n        may be asked for a password in such cases.\n\n    .. note::\n\n        Neither hard nor soft reboot is supported.\n    \"\"\"\n\n    _data_class = ProvisionLocalData\n    _guest_class = GuestLocal\n\n    _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the container\n        \"\"\"\n\n        super().go(logger=logger)\n\n        # Create a GuestLocal instance\n        data = tmt.steps.provision.GuestData.from_plugin(self)\n        data.primary_address = 'localhost'\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        self.assert_feeling_safe(\"1.38\", \"The 'local' provision plugin\")\n\n        if data.hardware and data.hardware.constraint:\n            self.warn(\"The 'local' provision plugin does not support hardware requirements.\")\n\n        self._guest = GuestLocal(logger=self._logger, data=data, name=self.name, parent=self.step)\n        self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.local.ProvisionLocal.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the container</p> Source code in <code>tmt/steps/provision/local.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the container\n    \"\"\"\n\n    super().go(logger=logger)\n\n    # Create a GuestLocal instance\n    data = tmt.steps.provision.GuestData.from_plugin(self)\n    data.primary_address = 'localhost'\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    self.assert_feeling_safe(\"1.38\", \"The 'local' provision plugin\")\n\n    if data.hardware and data.hardware.constraint:\n        self.warn(\"The 'local' provision plugin does not support hardware requirements.\")\n\n    self._guest = GuestLocal(logger=self._logger, data=data, name=self.name, parent=self.step)\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/provision/#virtualtestcloud","title":"virtual.testcloud","text":""},{"location":"plugins/provision/#tmt.steps.provision.testcloud.ProvisionTestcloud","title":"<code>tmt.steps.provision.testcloud.ProvisionTestcloud</code>","text":"<p>               Bases: <code>ProvisionPlugin[ProvisionTestcloudData]</code></p> <p>Local virtual machine using <code>testcloud</code> library. Testcloud takes care of downloading an image and making necessary changes to it for optimal experience (such as disabling <code>UseDNS</code> and <code>GSSAPI</code> for SSH).</p> <p>Minimal config which uses the latest Fedora image:</p> <p>.. code-block:: yaml</p> <pre><code>provision:\n    how: virtual\n</code></pre> <p>Here's a full config example:</p> <p>.. code-block:: yaml</p> <pre><code># Provision a virtual machine from a specific QCOW2 file,\n# using specific memory and disk settings, using the fedora user,\n# and using sudo to run scripts.\nprovision:\n    how: virtual\n    image: https://mirror.vpsnet.com/fedora/linux/releases/41/Cloud/x86_64/images/Fedora-Cloud-Base-Generic-41-1.4.x86_64.qcow2\n    user: fedora\n    become: true\n    # in MB\n    memory: 2048\n    # in GB\n    disk: 30\n</code></pre> <p>Images ^^^^^^</p> <p>As the image use <code>fedora</code> for the latest released Fedora compose, <code>fedora-rawhide</code> for the latest Rawhide compose, short aliases such as <code>fedora-32</code>, <code>f-32</code> or <code>f32</code> for specific release or a full url to the qcow2 image for example from https://kojipkgs.fedoraproject.org/compose/.</p> <p>Short names are also provided for <code>centos</code>, <code>centos-stream</code>, <code>alma</code>, <code>rocky</code>, <code>oracle</code>, <code>debian</code> and <code>ubuntu</code> (e.g. <code>centos-8</code> or <code>c8</code>).</p> <p>.. note::</p> <pre><code>The non-rpm distros are not fully supported yet in tmt as\nthe package installation is performed solely using ``dnf``/``yum``\nand ``rpm``.\nBut you should be able the login to the provisioned guest and start\nexperimenting. Full support is coming in the future :)\n</code></pre> <p>Supported Fedora CoreOS images are:</p> <ul> <li><code>fedora-coreos</code></li> <li><code>fedora-coreos-stable</code></li> <li><code>fedora-coreos-testing</code></li> <li><code>fedora-coreos-next</code></li> </ul> <p>Use the full path for images stored on local disk, for example:</p> <p>.. code-block:: shell</p> <pre><code>/var/tmp/images/Fedora-Cloud-Base-31-1.9.x86_64.qcow2\n</code></pre> <p>In addition to the qcow2 format, Vagrant boxes can be used as well, testcloud will take care of unpacking the image for you.</p> <p>Reboot ^^^^^^</p> <p>To trigger hard reboot of a guest, plugin uses testcloud API. It is also used to trigger soft reboot unless a custom reboot command was specified via <code>tmt-reboot -c ...</code>.</p> <p>Console ^^^^^^^</p> <p>The full console log is available, after the guest is booted, in the <code>logs</code> directory under the provision step workdir, for example: <code>plan/provision/client/logs/console.txt</code>. Enable verbose mode using <code>-vv</code> to get the full path printed to the terminal for easy investigation.</p> Source code in <code>tmt/steps/provision/testcloud.py</code> <pre><code>@tmt.steps.provides_method(\n    'virtual.testcloud',\n    installation_hint=\"\"\"\n        Make sure ``testcloud`` and ``libvirt`` packages are installed and configured, they are\n        required for VM-backed guests provided by ``provision/virtual.testcloud`` plugin.\n\n        * Users who installed tmt from system repositories should install ``tmt+provision-virtual``\n          package.\n        * Users who installed tmt from PyPI should also install ``tmt+provision-virtual`` package,\n          as it will install required system dependencies. After doing so, they should install\n          ``tmt[provision-virtual]`` extra.\n    \"\"\",\n)\nclass ProvisionTestcloud(tmt.steps.provision.ProvisionPlugin[ProvisionTestcloudData]):\n    \"\"\"\n    Local virtual machine using ``testcloud`` library.\n    Testcloud takes care of downloading an image and\n    making necessary changes to it for optimal experience\n    (such as disabling ``UseDNS`` and ``GSSAPI`` for SSH).\n\n    Minimal config which uses the latest Fedora image:\n\n    .. code-block:: yaml\n\n        provision:\n            how: virtual\n\n    Here's a full config example:\n\n    .. code-block:: yaml\n\n        # Provision a virtual machine from a specific QCOW2 file,\n        # using specific memory and disk settings, using the fedora user,\n        # and using sudo to run scripts.\n        provision:\n            how: virtual\n            image: https://mirror.vpsnet.com/fedora/linux/releases/41/Cloud/x86_64/images/Fedora-Cloud-Base-Generic-41-1.4.x86_64.qcow2\n            user: fedora\n            become: true\n            # in MB\n            memory: 2048\n            # in GB\n            disk: 30\n\n    Images\n    ^^^^^^\n\n    As the image use ``fedora`` for the latest released Fedora compose,\n    ``fedora-rawhide`` for the latest Rawhide compose, short aliases such as\n    ``fedora-32``, ``f-32`` or ``f32`` for specific release or a full url to\n    the qcow2 image for example from https://kojipkgs.fedoraproject.org/compose/.\n\n    Short names are also provided for ``centos``, ``centos-stream``, ``alma``,\n    ``rocky``, ``oracle``, ``debian`` and ``ubuntu`` (e.g. ``centos-8`` or ``c8``).\n\n    .. note::\n\n        The non-rpm distros are not fully supported yet in tmt as\n        the package installation is performed solely using ``dnf``/``yum``\n        and ``rpm``.\n        But you should be able the login to the provisioned guest and start\n        experimenting. Full support is coming in the future :)\n\n    Supported Fedora CoreOS images are:\n\n    * ``fedora-coreos``\n    * ``fedora-coreos-stable``\n    * ``fedora-coreos-testing``\n    * ``fedora-coreos-next``\n\n    Use the full path for images stored on local disk, for example:\n\n    .. code-block:: shell\n\n        /var/tmp/images/Fedora-Cloud-Base-31-1.9.x86_64.qcow2\n\n    In addition to the qcow2 format, Vagrant boxes can be used as well,\n    testcloud will take care of unpacking the image for you.\n\n    Reboot\n    ^^^^^^\n\n    To trigger hard reboot of a guest, plugin uses testcloud API. It is\n    also used to trigger soft reboot unless a custom reboot command was\n    specified via ``tmt-reboot -c ...``.\n\n    Console\n    ^^^^^^^\n\n    The full console log is available, after the guest is booted, in the\n    ``logs`` directory under the provision step workdir, for example:\n    ``plan/provision/client/logs/console.txt``. Enable verbose mode\n    using ``-vv`` to get the full path printed to the terminal for easy\n    investigation.\n\n    \"\"\"\n\n    _data_class = ProvisionTestcloudData\n    _guest_class = GuestTestcloud\n\n    _thread_safe = True\n\n    # Guest instance\n    _guest = None\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Provision the testcloud instance\n        \"\"\"\n\n        super().go(logger=logger)\n\n        if self.data.list_local_images:\n            self._print_local_images()\n            # Clean up the run workdir and exit\n            if self.step.plan.my_run:\n                self.step.plan.my_run._workdir_cleanup()\n            raise SystemExit(0)\n\n        # Give info about provided data\n        data = TestcloudGuestData.from_plugin(self)\n\n        # Once plan schema is enforced this won't be necessary\n        # click enforces int for cmdline and schema validation\n        # will make sure 'int' gets from plan data.\n        # Another key is 'port' however that is not exposed to the cli\n        for int_key in [\"port\"]:\n            value = getattr(data, int_key)\n            if value is not None:\n                try:\n                    setattr(data, int_key, int(value))\n                except ValueError as exc:\n                    raise tmt.utils.NormalizationError(\n                        f'{self.name}:{int_key}', value, 'an integer'\n                    ) from exc\n\n        data.show(verbose=self.verbosity_level, logger=self._logger)\n\n        if data.hardware and data.hardware.constraint:\n            data.hardware.report_support(check=_report_hw_requirement_support, logger=self._logger)\n\n            for line in data.hardware.format_variants():\n                self._logger.debug('hardware', line, level=4)\n\n            if data.memory is not None and data.hardware.constraint.uses_constraint(\n                'memory', self._logger\n            ):\n                self._logger.warning(\n                    \"Hardware requirement 'memory' is specified in 'hardware' key,\"\n                    \" it will be overruled by 'memory' key.\"\n                )\n\n            if data.disk is not None and data.hardware.constraint.uses_constraint(\n                'disk.size', self._logger\n            ):\n                self._logger.warning(\n                    \"Hardware requirement 'disk.size' is specified in 'hardware' key,\"\n                    \" it will be overruled by 'disk' key.\"\n                )\n\n        # Create a new GuestTestcloud instance and start it\n        self._guest = GuestTestcloud(\n            logger=self._logger,\n            data=data,\n            name=self.name,\n            parent=self.step,\n        )\n        self._guest.start()\n        self._guest.setup()\n\n    def _print_local_images(self) -&gt; None:\n        \"\"\"\n        Print images which are already cached\n        \"\"\"\n\n        store_dir = self.workdir_root / 'testcloud/images'\n        self.info(\"Locally available images\")\n        for filename in sorted(store_dir.glob('*.qcow2')):\n            self.info(filename.name, shift=1, color='yellow')\n            click.echo(f\"{store_dir / filename}\")\n\n    @classmethod\n    def clean_images(cls, clean: 'tmt.base.Clean', dry: bool, workdir_root: Path) -&gt; bool:\n        \"\"\"\n        Remove the testcloud images\n        \"\"\"\n\n        testcloud_images = workdir_root / 'testcloud/images'\n        clean.info('testcloud', shift=1, color='green')\n        if not testcloud_images.exists():\n            clean.warn(f\"Directory '{testcloud_images}' does not exist.\", shift=2)\n            return True\n        successful = True\n        for image in testcloud_images.iterdir():\n            if dry:\n                clean.verbose(f\"Would remove '{image}'.\", shift=2)\n            else:\n                clean.verbose(f\"Removing '{image}'.\", shift=2)\n                try:\n                    image.unlink()\n                except OSError:\n                    clean.fail(f\"Failed to remove '{image}'.\", shift=2)\n                    successful = False\n        return successful\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.testcloud.ProvisionTestcloud.clean_images","title":"<code>clean_images(clean, dry, workdir_root)</code>  <code>classmethod</code>","text":"<p>Remove the testcloud images</p> Source code in <code>tmt/steps/provision/testcloud.py</code> <pre><code>@classmethod\ndef clean_images(cls, clean: 'tmt.base.Clean', dry: bool, workdir_root: Path) -&gt; bool:\n    \"\"\"\n    Remove the testcloud images\n    \"\"\"\n\n    testcloud_images = workdir_root / 'testcloud/images'\n    clean.info('testcloud', shift=1, color='green')\n    if not testcloud_images.exists():\n        clean.warn(f\"Directory '{testcloud_images}' does not exist.\", shift=2)\n        return True\n    successful = True\n    for image in testcloud_images.iterdir():\n        if dry:\n            clean.verbose(f\"Would remove '{image}'.\", shift=2)\n        else:\n            clean.verbose(f\"Removing '{image}'.\", shift=2)\n            try:\n                image.unlink()\n            except OSError:\n                clean.fail(f\"Failed to remove '{image}'.\", shift=2)\n                successful = False\n    return successful\n</code></pre>"},{"location":"plugins/provision/#tmt.steps.provision.testcloud.ProvisionTestcloud.go","title":"<code>go(*, logger=None)</code>","text":"<p>Provision the testcloud instance</p> Source code in <code>tmt/steps/provision/testcloud.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Provision the testcloud instance\n    \"\"\"\n\n    super().go(logger=logger)\n\n    if self.data.list_local_images:\n        self._print_local_images()\n        # Clean up the run workdir and exit\n        if self.step.plan.my_run:\n            self.step.plan.my_run._workdir_cleanup()\n        raise SystemExit(0)\n\n    # Give info about provided data\n    data = TestcloudGuestData.from_plugin(self)\n\n    # Once plan schema is enforced this won't be necessary\n    # click enforces int for cmdline and schema validation\n    # will make sure 'int' gets from plan data.\n    # Another key is 'port' however that is not exposed to the cli\n    for int_key in [\"port\"]:\n        value = getattr(data, int_key)\n        if value is not None:\n            try:\n                setattr(data, int_key, int(value))\n            except ValueError as exc:\n                raise tmt.utils.NormalizationError(\n                    f'{self.name}:{int_key}', value, 'an integer'\n                ) from exc\n\n    data.show(verbose=self.verbosity_level, logger=self._logger)\n\n    if data.hardware and data.hardware.constraint:\n        data.hardware.report_support(check=_report_hw_requirement_support, logger=self._logger)\n\n        for line in data.hardware.format_variants():\n            self._logger.debug('hardware', line, level=4)\n\n        if data.memory is not None and data.hardware.constraint.uses_constraint(\n            'memory', self._logger\n        ):\n            self._logger.warning(\n                \"Hardware requirement 'memory' is specified in 'hardware' key,\"\n                \" it will be overruled by 'memory' key.\"\n            )\n\n        if data.disk is not None and data.hardware.constraint.uses_constraint(\n            'disk.size', self._logger\n        ):\n            self._logger.warning(\n                \"Hardware requirement 'disk.size' is specified in 'hardware' key,\"\n                \" it will be overruled by 'disk' key.\"\n            )\n\n    # Create a new GuestTestcloud instance and start it\n    self._guest = GuestTestcloud(\n        logger=self._logger,\n        data=data,\n        name=self.name,\n        parent=self.step,\n    )\n    self._guest.start()\n    self._guest.setup()\n</code></pre>"},{"location":"plugins/report/","title":"Report","text":"<p>Provide test results overview and send reports.</p>"},{"location":"plugins/report/#display","title":"display","text":""},{"location":"plugins/report/#tmt.steps.report.display.ReportDisplay","title":"<code>tmt.steps.report.display.ReportDisplay</code>","text":"<p>               Bases: <code>ReportPlugin[ReportDisplayData]</code></p> <p>Show test results on the terminal.</p> <p>Give a concise summary of test results directly on the terminal. Allows to select the desired level of verbosity.</p> <p>.. code-block:: yaml</p> <pre><code>tmt run -l report        # overall summary only\ntmt run -l report -v     # individual test results\ntmt run -l report -vv    # show full paths to logs\ntmt run -l report -vvv   # provide complete test output\n</code></pre> Source code in <code>tmt/steps/report/display.py</code> <pre><code>@tmt.steps.provides_method('display')\nclass ReportDisplay(tmt.steps.report.ReportPlugin[ReportDisplayData]):\n    \"\"\"\n    Show test results on the terminal.\n\n    Give a concise summary of test results directly on the terminal.\n    Allows to select the desired level of verbosity.\n\n    .. code-block:: yaml\n\n        tmt run -l report        # overall summary only\n        tmt run -l report -v     # individual test results\n        tmt run -l report -vv    # show full paths to logs\n        tmt run -l report -vvv   # provide complete test output\n    \"\"\"\n\n    _data_class = ReportDisplayData\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Discover available tests\n        \"\"\"\n\n        super().go(logger=logger)\n        # Show individual test results only in verbose mode\n        if not self.verbosity_level:\n            return\n\n        if self.data.display_guest == 'always':\n            display_guest = True\n\n        elif self.data.display_guest == 'never':\n            display_guest = False\n\n        else:\n            seen_guests = {result.guest.name for result in self.step.plan.execute.results()}\n\n            display_guest = len(seen_guests) &gt; 1\n\n        assert self.step.plan.execute.workdir is not None\n\n        ResultRenderer(\n            basepath=self.step.plan.execute.workdir,\n            logger=self._logger,\n            shift=1,\n            verbosity=self.verbosity_level,\n            display_guest=display_guest,\n        ).print_results(self.step.plan.execute.results())\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.display.ReportDisplay.go","title":"<code>go(*, logger=None)</code>","text":"<p>Discover available tests</p> Source code in <code>tmt/steps/report/display.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Discover available tests\n    \"\"\"\n\n    super().go(logger=logger)\n    # Show individual test results only in verbose mode\n    if not self.verbosity_level:\n        return\n\n    if self.data.display_guest == 'always':\n        display_guest = True\n\n    elif self.data.display_guest == 'never':\n        display_guest = False\n\n    else:\n        seen_guests = {result.guest.name for result in self.step.plan.execute.results()}\n\n        display_guest = len(seen_guests) &gt; 1\n\n    assert self.step.plan.execute.workdir is not None\n\n    ResultRenderer(\n        basepath=self.step.plan.execute.workdir,\n        logger=self._logger,\n        shift=1,\n        verbosity=self.verbosity_level,\n        display_guest=display_guest,\n    ).print_results(self.step.plan.execute.results())\n</code></pre>"},{"location":"plugins/report/#html","title":"html","text":""},{"location":"plugins/report/#tmt.steps.report.html.ReportHtml","title":"<code>tmt.steps.report.html.ReportHtml</code>","text":"<p>               Bases: <code>ReportPlugin[ReportHtmlData]</code></p> <p>Format test results into an HTML report.</p> <p>Create a local <code>html</code> file with test results arranged in a table. Optionally open the page in the default browser.</p> <p>Example config:</p> <p>.. code-block:: yaml</p> <pre><code># Enable html report from the command line\ntmt run --all report --how html\ntmt run --all report --how html --open\ntmt run -l report -h html -o\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Use html as the default report for given plan\nreport:\n    how: html\n    open: true\n</code></pre> Source code in <code>tmt/steps/report/html.py</code> <pre><code>@tmt.steps.provides_method('html')\nclass ReportHtml(tmt.steps.report.ReportPlugin[ReportHtmlData]):\n    \"\"\"\n    Format test results into an HTML report.\n\n    Create a local ``html`` file with test results arranged in\n    a table. Optionally open the page in the default browser.\n\n    Example config:\n\n    .. code-block:: yaml\n\n        # Enable html report from the command line\n        tmt run --all report --how html\n        tmt run --all report --how html --open\n        tmt run -l report -h html -o\n\n    .. code-block:: yaml\n\n        # Use html as the default report for given plan\n        report:\n            how: html\n            open: true\n    \"\"\"\n\n    _data_class = ReportHtmlData\n\n    @property\n    def _preserved_workdir_members(self) -&gt; set[str]:\n        \"\"\"\n        A set of members of the step workdir that should not be removed.\n        \"\"\"\n\n        return {DEFAULT_FILENAME}\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Process results\n        \"\"\"\n\n        super().go(logger=logger)\n\n        # Prepare the template\n        environment = tmt.utils.templates.default_template_environment()\n\n        # Explicitly enable the autoescape because it's disabled by default by TMT\n        # (see /teemtee/tmt/issues/2873 for more info.\n        environment.autoescape = select_autoescape(enabled_extensions=('html.j2'))\n\n        if self.data.absolute_paths:\n\n            def _linkable_path(path: str) -&gt; str:\n                return str(Path(path).absolute())\n\n            environment.filters[\"linkable_path\"] = _linkable_path\n        else:\n            # Links used in html should be relative to a workdir\n            def _linkable_path(path: str) -&gt; str:\n                assert self.workdir is not None  # narrow type\n\n                return str(Path(path).relative_to(self.workdir))\n\n            environment.filters[\"linkable_path\"] = _linkable_path\n\n        if self.data.display_guest == 'always':\n            display_guest = True\n\n        elif self.data.display_guest == 'never':\n            display_guest = False\n\n        else:\n            seen_guests = {result.guest.name for result in self.step.plan.execute.results()}\n\n            display_guest = len(seen_guests) &gt; 1\n\n        # Write the report\n        assert self.workdir is not None\n        filepath = self.data.file or self.workdir / DEFAULT_FILENAME\n\n        try:\n            filepath.write_text(\n                tmt.utils.templates.render_template_file(\n                    HTML_TEMPLATE_PATH,\n                    environment,\n                    results=self.step.plan.execute.results(),\n                    base_dir=self.step.plan.execute.workdir,\n                    plan=self.step.plan,\n                    display_guest=display_guest,\n                ),\n            )\n\n        except Exception as error:\n            raise tmt.utils.ReportError(f\"Failed to write the output '{filepath}'.\") from error\n\n        # Nothing more to do in dry mode\n        if self.is_dry_run:\n            return\n\n        # Show output file path\n        self.info(\"output\", filepath, color='yellow')\n        if not self.data.open:\n            return\n\n        # Open target in webbrowser\n        try:\n            if webbrowser.open(f\"file://{filepath}\", new=0):\n                self.info('open', 'Successfully opened in the web browser.', color='green')\n                return\n            self.fail(\"Failed to open the web browser.\")\n        except Exception as error:\n            self.fail(f\"Failed to open the web browser: {error}\")\n\n        raise tmt.utils.ReportError(\"Unable to open the web browser.\")\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.html.ReportHtml.go","title":"<code>go(*, logger=None)</code>","text":"<p>Process results</p> Source code in <code>tmt/steps/report/html.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Process results\n    \"\"\"\n\n    super().go(logger=logger)\n\n    # Prepare the template\n    environment = tmt.utils.templates.default_template_environment()\n\n    # Explicitly enable the autoescape because it's disabled by default by TMT\n    # (see /teemtee/tmt/issues/2873 for more info.\n    environment.autoescape = select_autoescape(enabled_extensions=('html.j2'))\n\n    if self.data.absolute_paths:\n\n        def _linkable_path(path: str) -&gt; str:\n            return str(Path(path).absolute())\n\n        environment.filters[\"linkable_path\"] = _linkable_path\n    else:\n        # Links used in html should be relative to a workdir\n        def _linkable_path(path: str) -&gt; str:\n            assert self.workdir is not None  # narrow type\n\n            return str(Path(path).relative_to(self.workdir))\n\n        environment.filters[\"linkable_path\"] = _linkable_path\n\n    if self.data.display_guest == 'always':\n        display_guest = True\n\n    elif self.data.display_guest == 'never':\n        display_guest = False\n\n    else:\n        seen_guests = {result.guest.name for result in self.step.plan.execute.results()}\n\n        display_guest = len(seen_guests) &gt; 1\n\n    # Write the report\n    assert self.workdir is not None\n    filepath = self.data.file or self.workdir / DEFAULT_FILENAME\n\n    try:\n        filepath.write_text(\n            tmt.utils.templates.render_template_file(\n                HTML_TEMPLATE_PATH,\n                environment,\n                results=self.step.plan.execute.results(),\n                base_dir=self.step.plan.execute.workdir,\n                plan=self.step.plan,\n                display_guest=display_guest,\n            ),\n        )\n\n    except Exception as error:\n        raise tmt.utils.ReportError(f\"Failed to write the output '{filepath}'.\") from error\n\n    # Nothing more to do in dry mode\n    if self.is_dry_run:\n        return\n\n    # Show output file path\n    self.info(\"output\", filepath, color='yellow')\n    if not self.data.open:\n        return\n\n    # Open target in webbrowser\n    try:\n        if webbrowser.open(f\"file://{filepath}\", new=0):\n            self.info('open', 'Successfully opened in the web browser.', color='green')\n            return\n        self.fail(\"Failed to open the web browser.\")\n    except Exception as error:\n        self.fail(f\"Failed to open the web browser: {error}\")\n\n    raise tmt.utils.ReportError(\"Unable to open the web browser.\")\n</code></pre>"},{"location":"plugins/report/#junit","title":"junit","text":""},{"location":"plugins/report/#tmt.steps.report.junit.ReportJUnit","title":"<code>tmt.steps.report.junit.ReportJUnit</code>","text":"<p>               Bases: <code>ReportPlugin[ReportJUnitData]</code></p> <p>Save test results in chosen JUnit flavor format.</p> <p>When flavor is set to custom, the <code>template-path</code> with a path to a custom template must be provided.</p> <p>When <code>file</code> is not specified, output is written into a file named <code>junit.xml</code> located in the current workdir.</p> <p>.. code-block:: yaml</p> <pre><code># Enable junit report from the command line\ntmt run --all report --how junit\ntmt run --all report --how junit --file test.xml\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Use junit as the default report for given plan\nreport:\n    how: junit\n    file: test.xml\n</code></pre> Source code in <code>tmt/steps/report/junit.py</code> <pre><code>@tmt.steps.provides_method(\n    'junit',\n    installation_hint=\"\"\"\n        For neater JUnit XML and XML validation against the XSD, ``lxml`` package is required\n        by the ``report/junit`` plugin.\n\n        To quickly test ``lxml`` presence, you can try running ``python -c 'import lxml'``.\n\n        * Users who installed tmt from system repositories should install ``tmt+report-junit``\n          package.\n        * Users who installed tmt from PyPI should install ``tmt[report-junit]`` extra.\n    \"\"\",\n)\nclass ReportJUnit(tmt.steps.report.ReportPlugin[ReportJUnitData]):\n    \"\"\"\n    Save test results in chosen JUnit flavor format.\n\n    When flavor is set to custom, the ``template-path`` with a path to a custom template must be\n    provided.\n\n    When ``file`` is not specified, output is written into a file named ``junit.xml`` located in\n    the current workdir.\n\n    .. code-block:: yaml\n\n        # Enable junit report from the command line\n        tmt run --all report --how junit\n        tmt run --all report --how junit --file test.xml\n\n    .. code-block:: yaml\n\n        # Use junit as the default report for given plan\n        report:\n            how: junit\n            file: test.xml\n    \"\"\"\n\n    _data_class = ReportJUnitData\n\n    def check_options(self) -&gt; None:\n        \"\"\"\n        Check the module options\n        \"\"\"\n\n        if self.data.flavor == 'custom' and not self.data.template_path:\n            raise tmt.utils.ReportError(\n                \"The 'custom' flavor requires the '--template-path' argument.\"\n            )\n\n        if self.data.flavor != 'custom' and self.data.template_path:\n            raise tmt.utils.ReportError(\n                \"The '--template-path' can be used only with '--flavor=custom'.\"\n            )\n\n    @property\n    def _preserved_workdir_members(self) -&gt; set[str]:\n        \"\"\"\n        A set of members of the step workdir that should not be removed.\n        \"\"\"\n\n        members = super()._preserved_workdir_members\n\n        if self.data.file is None:\n            members = {*members, DEFAULT_FILENAME}\n\n        return members\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Read executed tests and write junit\n        \"\"\"\n\n        super().go(logger=logger)\n\n        self.check_options()\n\n        assert self.workdir is not None\n        f_path = self.data.file or self.workdir / DEFAULT_FILENAME\n\n        xml_data = make_junit_xml(\n            phase=self,\n            flavor=self.data.flavor,\n            template_path=self.data.template_path,\n            include_output_log=self.data.include_output_log,\n            prettify=self.data.prettify,\n        )\n        try:\n            f_path.write_text(xml_data)\n            self.info('output', f_path, 'yellow')\n        except Exception as error:\n            raise tmt.utils.ReportError(f\"Failed to write the output '{f_path}'.\") from error\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.junit.ReportJUnit.check_options","title":"<code>check_options()</code>","text":"<p>Check the module options</p> Source code in <code>tmt/steps/report/junit.py</code> <pre><code>def check_options(self) -&gt; None:\n    \"\"\"\n    Check the module options\n    \"\"\"\n\n    if self.data.flavor == 'custom' and not self.data.template_path:\n        raise tmt.utils.ReportError(\n            \"The 'custom' flavor requires the '--template-path' argument.\"\n        )\n\n    if self.data.flavor != 'custom' and self.data.template_path:\n        raise tmt.utils.ReportError(\n            \"The '--template-path' can be used only with '--flavor=custom'.\"\n        )\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.junit.ReportJUnit.go","title":"<code>go(*, logger=None)</code>","text":"<p>Read executed tests and write junit</p> Source code in <code>tmt/steps/report/junit.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Read executed tests and write junit\n    \"\"\"\n\n    super().go(logger=logger)\n\n    self.check_options()\n\n    assert self.workdir is not None\n    f_path = self.data.file or self.workdir / DEFAULT_FILENAME\n\n    xml_data = make_junit_xml(\n        phase=self,\n        flavor=self.data.flavor,\n        template_path=self.data.template_path,\n        include_output_log=self.data.include_output_log,\n        prettify=self.data.prettify,\n    )\n    try:\n        f_path.write_text(xml_data)\n        self.info('output', f_path, 'yellow')\n    except Exception as error:\n        raise tmt.utils.ReportError(f\"Failed to write the output '{f_path}'.\") from error\n</code></pre>"},{"location":"plugins/report/#polarion","title":"polarion","text":""},{"location":"plugins/report/#tmt.steps.report.polarion.ReportPolarion","title":"<code>tmt.steps.report.polarion.ReportPolarion</code>","text":"<p>               Bases: <code>ReportPlugin[ReportPolarionData]</code></p> <p>Write test results into an xUnit file and upload to Polarion.</p> <p>In order to get quickly started create a pylero config file <code>~/.pylero</code> in your home directory with the following content:</p> <p>.. code-block:: ini</p> <pre><code>[webservice]\nurl=https://{your polarion web URL}/polarion\nsvn_repo=https://{your polarion web URL}/repo\ndefault_project={your project name}\nuser={your username}\npassword={your password}\n</code></pre> <p>See the <code>Pylero Documentation</code> for more details on how to configure the <code>pylero</code> module.</p> <p>https://github.com/RedHatQE/pylero</p> <p>.. note::</p> <pre><code>For Polarion report to export correctly you need to\nuse password authentication, since exporting the\nreport happens through Polarion XUnit importer which\ndoes not support using tokens. You can still\nauthenticate with token to only generate the report\nusing ``--no-upload`` argument.\n</code></pre> <p>.. note::</p> <pre><code>Your Polarion project might need a custom value format\nfor the ``arch``, ``planned-in`` and other fields. The\nformat of these fields might differ across Polarion\nprojects, for example, ``x8664`` can be used instead\nof ``x86_64`` for the architecture.\n</code></pre> <p>Examples:</p> <p>.. code-block:: yaml</p> <pre><code># Enable polarion report from the command line\ntmt run --all report --how polarion --project-id tmt\ntmt run --all report --how polarion --project-id tmt --no-upload --file test.xml\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Use polarion as the default report for given plan\nreport:\n    how: polarion\n    file: test.xml\n    project-id: tmt\n    title: tests_that_pass\n    planned-in: RHEL-9.1.0\n    pool-team: sst_tmt\n</code></pre> Source code in <code>tmt/steps/report/polarion.py</code> <pre><code>@tmt.steps.provides_method('polarion')\nclass ReportPolarion(tmt.steps.report.ReportPlugin[ReportPolarionData]):\n    \"\"\"\n    Write test results into an xUnit file and upload to Polarion.\n\n    In order to get quickly started create a pylero config\n    file ``~/.pylero`` in your home directory with the\n    following content:\n\n    .. code-block:: ini\n\n        [webservice]\n        url=https://{your polarion web URL}/polarion\n        svn_repo=https://{your polarion web URL}/repo\n        default_project={your project name}\n        user={your username}\n        password={your password}\n\n    See the ``Pylero Documentation`` for more details on how\n    to configure the ``pylero`` module.\n\n    https://github.com/RedHatQE/pylero\n\n    .. note::\n\n        For Polarion report to export correctly you need to\n        use password authentication, since exporting the\n        report happens through Polarion XUnit importer which\n        does not support using tokens. You can still\n        authenticate with token to only generate the report\n        using ``--no-upload`` argument.\n\n    .. note::\n\n        Your Polarion project might need a custom value format\n        for the ``arch``, ``planned-in`` and other fields. The\n        format of these fields might differ across Polarion\n        projects, for example, ``x8664`` can be used instead\n        of ``x86_64`` for the architecture.\n\n    Examples:\n\n    .. code-block:: yaml\n\n        # Enable polarion report from the command line\n        tmt run --all report --how polarion --project-id tmt\n        tmt run --all report --how polarion --project-id tmt --no-upload --file test.xml\n\n    .. code-block:: yaml\n\n        # Use polarion as the default report for given plan\n        report:\n            how: polarion\n            file: test.xml\n            project-id: tmt\n            title: tests_that_pass\n            planned-in: RHEL-9.1.0\n            pool-team: sst_tmt\n    \"\"\"\n\n    _data_class = ReportPolarionData\n\n    @property\n    def _preserved_workdir_members(self) -&gt; set[str]:\n        \"\"\"\n        A set of members of the step workdir that should not be removed.\n        \"\"\"\n\n        members = super()._preserved_workdir_members\n\n        if self.data.file is None:\n            members = {*members, DEFAULT_FILENAME}\n\n        return members\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Go through executed tests and report into Polarion\n        \"\"\"\n\n        super().go(logger=logger)\n\n        from tmt.export.polarion import find_polarion_case_ids, import_polarion\n\n        import_polarion()\n        from tmt.export.polarion import PolarionWorkItem\n\n        title = self.data.title\n        if not title:\n            title = os.getenv(\n                'TMT_PLUGIN_REPORT_POLARION_TITLE',\n                self.step.plan.name.rsplit('/', 1)[1]\n                + '_'\n                +\n                # Polarion server running with UTC timezone\n                datetime.datetime.now(tz=datetime.timezone.utc).strftime(\"%Y%m%d%H%M%S\"),\n            )\n\n        title = title.replace('-', '_')\n        template = self.data.template or os.getenv('TMT_PLUGIN_REPORT_POLARION_TEMPLATE')\n        project_id = self.data.project_id or os.getenv(\n            'TMT_PLUGIN_REPORT_POLARION_PROJECT_ID', PolarionWorkItem._session.default_project\n        )\n\n        # The project_id is required\n        if not project_id:\n            raise tmt.utils.ReportError(\n                \"The Polarion project ID could not be determined. Consider setting it using \"\n                \"'--project-id' argument or by setting 'TMT_PLUGIN_REPORT_POLARION_PROJECT_ID' \"\n                \"environment variable.\"\n            )\n\n        # TODO: try use self.data instead - but these fields are not optional, they do have\n        # default values, do envvars even have any effect at all??\n        upload = self.get('upload', os.getenv('TMT_PLUGIN_REPORT_POLARION_UPLOAD'))\n        use_facts = self.get('use-facts', os.getenv('TMT_PLUGIN_REPORT_POLARION_USE_FACTS'))\n\n        other_testrun_fields = [\n            'arch',\n            'assignee',\n            'build',\n            'compose_id',\n            'description',\n            'fips',\n            'logs',\n            'planned_in',\n            'platform',\n            'pool_team',\n            'sample_image',\n        ]\n\n        testsuites_properties: dict[str, Optional[str]] = {}\n\n        for tr_field in other_testrun_fields:\n            param = self.get(tr_field, os.getenv(f'TMT_PLUGIN_REPORT_POLARION_{tr_field.upper()}'))\n            # TODO: remove the os.getenv when envvars in click work with steps in plans as well\n            # as with steps on cmdline\n            if param:\n                testsuites_properties[f\"polarion-custom-{tr_field.replace('_', '')}\"] = param\n\n        if use_facts:\n            guests = self.step.plan.provision.ready_guests\n            try:\n                testsuites_properties['polarion-custom-hostname'] = guests[0].primary_address\n                testsuites_properties['polarion-custom-arch'] = guests[0].facts.arch\n            except IndexError as error:\n                raise tmt.utils.ReportError(\n                    'Failed to retrieve facts from the guest environment. '\n                    'You can use a `--no-use-facts` argument to disable '\n                    'this behavior.'\n                ) from error\n\n        if template:\n            testsuites_properties['polarion-testrun-template-id'] = template\n\n        logs = os.getenv('TMT_REPORT_ARTIFACTS_URL')\n        if logs and 'polarion-custom-logs' not in testsuites_properties:\n            testsuites_properties['polarion-custom-logs'] = logs\n\n        project_span_ids: list[str] = []\n\n        results_context = ResultsContext(self.step.plan.execute.results())\n\n        for result in results_context:\n            if not result.ids or not any(result.ids.values()):\n                self.warn(\n                    f\"Test Case '{result.name}' is not exported to Polarion, \"\n                    \"please run 'tmt tests export --how polarion' on it.\"\n                )\n                continue\n\n            work_item_id, test_project_id = find_polarion_case_ids(result.ids)\n\n            if work_item_id is None or test_project_id is None:\n                self.warn(f\"Test case '{result.name}' missing or not found in Polarion.\")\n                continue\n\n            if test_project_id not in project_span_ids:\n                project_span_ids.append(test_project_id)\n\n            testcase_properties = {\n                'polarion-testcase-id': work_item_id,\n                'polarion-testcase-project-id': test_project_id,\n            }\n\n            # ignore[assignment]: mypy does not support different types for property getter and\n            # setter. The assignment is correct, but mypy cannot tell.\n            # See https://github.com/python/mypy/issues/3004 for getter/setter discussions\n            result.properties = testcase_properties  # type: ignore[assignment]\n\n        assert self.workdir is not None\n\n        testsuites_properties.update(\n            {\n                'polarion-project-id': project_id,\n                'polarion-user-id': PolarionWorkItem._session.user_id,\n                'polarion-testrun-title': title,\n                'polarion-project-span-ids': ','.join([project_id, *project_span_ids]),\n            }\n        )\n\n        # Add deployment mode if provided as a context variable\n        deployment_mode = self.step.plan._fmf_context.get('deployment-mode', [])\n        if deployment_mode:\n            testsuites_properties.update({'polarion-custom-deploymentMode': deployment_mode[0]})\n\n        # ignore[assignment]: mypy does not support different types for property getter\n        # and setter. The assignment is correct, but mypy cannot tell.\n        # See https://github.com/python/mypy/issues/3004 for getter/setter discussions\n        results_context.properties = testsuites_properties  # type: ignore[assignment]\n\n        xml_data = make_junit_xml(\n            phase=self,\n            flavor='polarion',\n            prettify=self.data.prettify,\n            include_output_log=self.data.include_output_log,\n            results_context=results_context,\n        )\n\n        f_path = self.data.file or self.workdir / DEFAULT_FILENAME\n\n        try:\n            f_path.write_text(xml_data)\n        except Exception as error:\n            raise tmt.utils.ReportError(f\"Failed to write the output '{f_path}'.\") from error\n\n        if upload:\n            server_url = str(PolarionWorkItem._session._server.url)\n            polarion_import_url = (\n                f'{server_url}{\"\" if server_url.endswith(\"/\") else \"/\"}import/xunit'\n            )\n            auth = (PolarionWorkItem._session.user_id, PolarionWorkItem._session.password)\n\n            response = post(\n                polarion_import_url,\n                auth=auth,\n                files={\n                    'file': ('xunit.xml', xml_data),\n                },\n                timeout=10,\n            )\n            self.info(f'Response code is {response.status_code} with text: {response.text}')\n        else:\n            self.info('Polarion upload can be done manually using command:')\n            self.info(\n                'curl -k -u &lt;USER&gt;:&lt;PASSWORD&gt; -X POST -F file=@&lt;XUNIT_XML_FILE_PATH&gt; '\n                '&lt;POLARION_URL&gt;/polarion/import/xunit'\n            )\n        self.info('xUnit file saved at', f_path, 'yellow')\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.polarion.ReportPolarion.go","title":"<code>go(*, logger=None)</code>","text":"<p>Go through executed tests and report into Polarion</p> Source code in <code>tmt/steps/report/polarion.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Go through executed tests and report into Polarion\n    \"\"\"\n\n    super().go(logger=logger)\n\n    from tmt.export.polarion import find_polarion_case_ids, import_polarion\n\n    import_polarion()\n    from tmt.export.polarion import PolarionWorkItem\n\n    title = self.data.title\n    if not title:\n        title = os.getenv(\n            'TMT_PLUGIN_REPORT_POLARION_TITLE',\n            self.step.plan.name.rsplit('/', 1)[1]\n            + '_'\n            +\n            # Polarion server running with UTC timezone\n            datetime.datetime.now(tz=datetime.timezone.utc).strftime(\"%Y%m%d%H%M%S\"),\n        )\n\n    title = title.replace('-', '_')\n    template = self.data.template or os.getenv('TMT_PLUGIN_REPORT_POLARION_TEMPLATE')\n    project_id = self.data.project_id or os.getenv(\n        'TMT_PLUGIN_REPORT_POLARION_PROJECT_ID', PolarionWorkItem._session.default_project\n    )\n\n    # The project_id is required\n    if not project_id:\n        raise tmt.utils.ReportError(\n            \"The Polarion project ID could not be determined. Consider setting it using \"\n            \"'--project-id' argument or by setting 'TMT_PLUGIN_REPORT_POLARION_PROJECT_ID' \"\n            \"environment variable.\"\n        )\n\n    # TODO: try use self.data instead - but these fields are not optional, they do have\n    # default values, do envvars even have any effect at all??\n    upload = self.get('upload', os.getenv('TMT_PLUGIN_REPORT_POLARION_UPLOAD'))\n    use_facts = self.get('use-facts', os.getenv('TMT_PLUGIN_REPORT_POLARION_USE_FACTS'))\n\n    other_testrun_fields = [\n        'arch',\n        'assignee',\n        'build',\n        'compose_id',\n        'description',\n        'fips',\n        'logs',\n        'planned_in',\n        'platform',\n        'pool_team',\n        'sample_image',\n    ]\n\n    testsuites_properties: dict[str, Optional[str]] = {}\n\n    for tr_field in other_testrun_fields:\n        param = self.get(tr_field, os.getenv(f'TMT_PLUGIN_REPORT_POLARION_{tr_field.upper()}'))\n        # TODO: remove the os.getenv when envvars in click work with steps in plans as well\n        # as with steps on cmdline\n        if param:\n            testsuites_properties[f\"polarion-custom-{tr_field.replace('_', '')}\"] = param\n\n    if use_facts:\n        guests = self.step.plan.provision.ready_guests\n        try:\n            testsuites_properties['polarion-custom-hostname'] = guests[0].primary_address\n            testsuites_properties['polarion-custom-arch'] = guests[0].facts.arch\n        except IndexError as error:\n            raise tmt.utils.ReportError(\n                'Failed to retrieve facts from the guest environment. '\n                'You can use a `--no-use-facts` argument to disable '\n                'this behavior.'\n            ) from error\n\n    if template:\n        testsuites_properties['polarion-testrun-template-id'] = template\n\n    logs = os.getenv('TMT_REPORT_ARTIFACTS_URL')\n    if logs and 'polarion-custom-logs' not in testsuites_properties:\n        testsuites_properties['polarion-custom-logs'] = logs\n\n    project_span_ids: list[str] = []\n\n    results_context = ResultsContext(self.step.plan.execute.results())\n\n    for result in results_context:\n        if not result.ids or not any(result.ids.values()):\n            self.warn(\n                f\"Test Case '{result.name}' is not exported to Polarion, \"\n                \"please run 'tmt tests export --how polarion' on it.\"\n            )\n            continue\n\n        work_item_id, test_project_id = find_polarion_case_ids(result.ids)\n\n        if work_item_id is None or test_project_id is None:\n            self.warn(f\"Test case '{result.name}' missing or not found in Polarion.\")\n            continue\n\n        if test_project_id not in project_span_ids:\n            project_span_ids.append(test_project_id)\n\n        testcase_properties = {\n            'polarion-testcase-id': work_item_id,\n            'polarion-testcase-project-id': test_project_id,\n        }\n\n        # ignore[assignment]: mypy does not support different types for property getter and\n        # setter. The assignment is correct, but mypy cannot tell.\n        # See https://github.com/python/mypy/issues/3004 for getter/setter discussions\n        result.properties = testcase_properties  # type: ignore[assignment]\n\n    assert self.workdir is not None\n\n    testsuites_properties.update(\n        {\n            'polarion-project-id': project_id,\n            'polarion-user-id': PolarionWorkItem._session.user_id,\n            'polarion-testrun-title': title,\n            'polarion-project-span-ids': ','.join([project_id, *project_span_ids]),\n        }\n    )\n\n    # Add deployment mode if provided as a context variable\n    deployment_mode = self.step.plan._fmf_context.get('deployment-mode', [])\n    if deployment_mode:\n        testsuites_properties.update({'polarion-custom-deploymentMode': deployment_mode[0]})\n\n    # ignore[assignment]: mypy does not support different types for property getter\n    # and setter. The assignment is correct, but mypy cannot tell.\n    # See https://github.com/python/mypy/issues/3004 for getter/setter discussions\n    results_context.properties = testsuites_properties  # type: ignore[assignment]\n\n    xml_data = make_junit_xml(\n        phase=self,\n        flavor='polarion',\n        prettify=self.data.prettify,\n        include_output_log=self.data.include_output_log,\n        results_context=results_context,\n    )\n\n    f_path = self.data.file or self.workdir / DEFAULT_FILENAME\n\n    try:\n        f_path.write_text(xml_data)\n    except Exception as error:\n        raise tmt.utils.ReportError(f\"Failed to write the output '{f_path}'.\") from error\n\n    if upload:\n        server_url = str(PolarionWorkItem._session._server.url)\n        polarion_import_url = (\n            f'{server_url}{\"\" if server_url.endswith(\"/\") else \"/\"}import/xunit'\n        )\n        auth = (PolarionWorkItem._session.user_id, PolarionWorkItem._session.password)\n\n        response = post(\n            polarion_import_url,\n            auth=auth,\n            files={\n                'file': ('xunit.xml', xml_data),\n            },\n            timeout=10,\n        )\n        self.info(f'Response code is {response.status_code} with text: {response.text}')\n    else:\n        self.info('Polarion upload can be done manually using command:')\n        self.info(\n            'curl -k -u &lt;USER&gt;:&lt;PASSWORD&gt; -X POST -F file=@&lt;XUNIT_XML_FILE_PATH&gt; '\n            '&lt;POLARION_URL&gt;/polarion/import/xunit'\n        )\n    self.info('xUnit file saved at', f_path, 'yellow')\n</code></pre>"},{"location":"plugins/report/#reportportal","title":"reportportal","text":""},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal","title":"<code>tmt.steps.report.reportportal.ReportReportPortal</code>","text":"<p>               Bases: <code>ReportPlugin[ReportReportPortalData]</code></p> <p>Report test results and their subresults to a ReportPortal instance via API.</p> <p>For communication with Report Portal API is necessary to provide following options:</p> <ul> <li>token for authentication</li> <li>url of the ReportPortal instance</li> <li>project name</li> </ul> <p>In addition to command line options it's possible to use environment variables:</p> <p>.. code-block:: bash</p> <pre><code>export TMT_PLUGIN_REPORT_REPORTPORTAL_${MY_OPTION}=${MY_VALUE}\n\n# Boolean options are activated with value of 1:\nTMT_PLUGIN_REPORT_REPORTPORTAL_SUITE_PER_PLAN=1\n</code></pre> <p>Assuming the URL and token are provided by the environment variables, the plan config can look like this:</p> <p>.. code-block:: yaml</p> <pre><code># Use ReportPortal as the default report for given plan\nreport:\n    how: reportportal\n    project: baseosqe\n\n# Report context attributes for given plan\ncontext:\n    ...\n\nenvironment:\n    ...\n</code></pre> <p>.. code-block:: yaml</p> <pre><code># Report description, contact, id and environment variables for given test\nsummary: ...\ncontact: ...\nid: ...\nenvironment:\n    ...\n</code></pre> <p>Where the context and environment sections must be filled with corresponding data in order to report context as attributes (arch, component, distro, trigger, compose, etc.) and environment variables as parameters in the Item Details.</p> <p>Other reported fmf data are summary, id, web link and contact per test.</p> <p>Two types of data structures are supported for reporting to ReportPortal:</p> <ul> <li><code>launch-per-plan</code> mapping (default) that results in launch-test structure.</li> <li><code>suite-per-plan</code> mapping that results in launch-suite-test structure.</li> </ul> <p>Supported report use cases:</p> <ul> <li>Report a new run in launch-suite-test or launch-test structure</li> <li>Report an additional rerun with <code>launch-rerun</code> option and same launch name (-&gt; Retry items)   or by reusing the run and reporting with <code>again</code> option (-&gt; append logs)</li> <li>To see plan progress, discover and report an empty (IDLE) run   and reuse the run for execution and updating the report with <code>again</code> option</li> <li>Report contents of a new run to an existing launch via the URL ID in three ways:   tests to launch, suites to launch and tests to suite.</li> </ul> <p>Example:</p> <p>.. code-block:: shell</p> <pre><code># Enable ReportPortal report from the command line depending on the use case:\n\n## Simple upload with all project, url endpoint and user token passed in command line\ntmt run --all report --how reportportal --project=baseosqe --url=\"https://reportportal.xxx.com\" --token=\"abc...789\"\n\n## Simple upload with url and token exported in environment variable\ntmt run --all report --how reportportal --project=baseosqe\n\n## Upload with project name in fmf data, filtering out parameters (environment variables)\n## that tend to be unique and break the history aggregation\ntmt run --all report --how reportportal --exclude-variables=\"^(TMT|PACKIT|TESTING_FARM).*\"\n\n## Upload all plans as suites into one ReportPortal launch\ntmt run --all report --how reportportal --suite-per-plan --launch=Errata --launch-description=\"...\"\n\n## Rerun the launch with suite structure for the test results to be uploaded\n## into the latest launch with the same name as a new 'Retry' tab\n## (mapping based on unique paths)\ntmt run --all report --how reportportal --suite-per-plan --launch=Errata --launch-rerun\n\n## Rerun the tmt run and append the new result logs under the previous one\n## uploaded in ReportPortal (precise mapping)\ntmt run --id run-012 --all report --how reportportal --again\n\n## Additional upload of new suites into given launch with suite structure\ntmt run --all report --how reportportal --suite-per-plan --upload-to-launch=4321\n\n## Additional upload of new tests into given launch with non-suite structure\ntmt run --all report --how reportportal --launch-per-plan --upload-to-launch=1234\n\n## Additional upload of new tests into given suite\ntmt run --all report --how reportportal --upload-to-suite=123456\n\n## Upload Idle tests, then execute it and add result logs into prepared empty tests\ntmt run discover report --how reportportal --defect-type=Idle\ntmt run --last --all report --how reportportal --again\n</code></pre> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>@tmt.steps.provides_method(\"reportportal\")\nclass ReportReportPortal(tmt.steps.report.ReportPlugin[ReportReportPortalData]):\n    \"\"\"\n    Report test results and their subresults to a ReportPortal instance via API.\n\n    For communication with Report Portal API is necessary to provide\n    following options:\n\n    * token for authentication\n    * url of the ReportPortal instance\n    * project name\n\n    In addition to command line options it's possible to use environment\n    variables:\n\n    .. code-block:: bash\n\n        export TMT_PLUGIN_REPORT_REPORTPORTAL_${MY_OPTION}=${MY_VALUE}\n\n        # Boolean options are activated with value of 1:\n        TMT_PLUGIN_REPORT_REPORTPORTAL_SUITE_PER_PLAN=1\n\n    Assuming the URL and token are provided by the environment variables,\n    the plan config can look like this:\n\n    .. code-block:: yaml\n\n        # Use ReportPortal as the default report for given plan\n        report:\n            how: reportportal\n            project: baseosqe\n\n        # Report context attributes for given plan\n        context:\n            ...\n\n        environment:\n            ...\n\n    .. code-block:: yaml\n\n        # Report description, contact, id and environment variables for given test\n        summary: ...\n        contact: ...\n        id: ...\n        environment:\n            ...\n\n    Where the context and environment sections must be filled with\n    corresponding data in order to report context as attributes\n    (arch, component, distro, trigger, compose, etc.) and\n    environment variables as parameters in the Item Details.\n\n    Other reported fmf data are summary, id, web link and contact per\n    test.\n\n    Two types of data structures are supported for reporting to ReportPortal:\n\n    * ``launch-per-plan`` mapping (default) that results in launch-test structure.\n    * ``suite-per-plan`` mapping that results in launch-suite-test structure.\n\n    Supported report use cases:\n\n    * Report a new run in launch-suite-test or launch-test structure\n    * Report an additional rerun with ``launch-rerun`` option and same launch name (-&gt; Retry items)\n      or by reusing the run and reporting with ``again`` option (-&gt; append logs)\n    * To see plan progress, discover and report an empty (IDLE) run\n      and reuse the run for execution and updating the report with ``again`` option\n    * Report contents of a new run to an existing launch via the URL ID in three ways:\n      tests to launch, suites to launch and tests to suite.\n\n    Example:\n\n    .. code-block:: shell\n\n        # Enable ReportPortal report from the command line depending on the use case:\n\n        ## Simple upload with all project, url endpoint and user token passed in command line\n        tmt run --all report --how reportportal --project=baseosqe --url=\"https://reportportal.xxx.com\" --token=\"abc...789\"\n\n        ## Simple upload with url and token exported in environment variable\n        tmt run --all report --how reportportal --project=baseosqe\n\n        ## Upload with project name in fmf data, filtering out parameters (environment variables)\n        ## that tend to be unique and break the history aggregation\n        tmt run --all report --how reportportal --exclude-variables=\"^(TMT|PACKIT|TESTING_FARM).*\"\n\n        ## Upload all plans as suites into one ReportPortal launch\n        tmt run --all report --how reportportal --suite-per-plan --launch=Errata --launch-description=\"...\"\n\n        ## Rerun the launch with suite structure for the test results to be uploaded\n        ## into the latest launch with the same name as a new 'Retry' tab\n        ## (mapping based on unique paths)\n        tmt run --all report --how reportportal --suite-per-plan --launch=Errata --launch-rerun\n\n        ## Rerun the tmt run and append the new result logs under the previous one\n        ## uploaded in ReportPortal (precise mapping)\n        tmt run --id run-012 --all report --how reportportal --again\n\n        ## Additional upload of new suites into given launch with suite structure\n        tmt run --all report --how reportportal --suite-per-plan --upload-to-launch=4321\n\n        ## Additional upload of new tests into given launch with non-suite structure\n        tmt run --all report --how reportportal --launch-per-plan --upload-to-launch=1234\n\n        ## Additional upload of new tests into given suite\n        tmt run --all report --how reportportal --upload-to-suite=123456\n\n        ## Upload Idle tests, then execute it and add result logs into prepared empty tests\n        tmt run discover report --how reportportal --defect-type=Idle\n        tmt run --last --all report --how reportportal --again\n    \"\"\"  # noqa: E501\n\n    _data_class = ReportReportPortalData\n\n    TMT_TO_RP_RESULT_STATUS = {\n        ResultOutcome.PASS: \"PASSED\",\n        ResultOutcome.FAIL: \"FAILED\",\n        ResultOutcome.INFO: \"SKIPPED\",\n        ResultOutcome.WARN: \"FAILED\",\n        ResultOutcome.ERROR: \"FAILED\",\n        ResultOutcome.SKIP: \"SKIPPED\",\n        ResultOutcome.PENDING: \"SKIPPED\",\n    }\n\n    def handle_response(self, response: requests.Response) -&gt; None:\n        \"\"\"\n        Check the endpoint response and raise an exception if needed\n        \"\"\"\n\n        self.debug(\"Response code from the endpoint\", response.status_code)\n        self.debug(\"Message from the endpoint\", response.text)\n\n        if not response.ok:\n            raise tmt.utils.ReportError(\n                f\"Received non-ok status code {response.status_code} \"\n                f\"from ReportPortal: {response.text}\"\n            )\n\n    def check_options(self) -&gt; None:\n        \"\"\"\n        Check options for known troublesome combinations\n        \"\"\"\n\n        if self.data.launch_per_plan and self.data.suite_per_plan:\n            self.warn(\n                \"The options '--launch-per-plan' and '--suite-per-plan' are mutually exclusive. \"\n                \"Default option '--launch-per-plan' is used.\"\n            )\n            self.data.suite_per_plan = False\n\n        if self.data.launch_rerun and (self.data.upload_to_launch or self.data.upload_to_suite):\n            self.warn(\n                \"Unexpected option combination: \"\n                \"'--launch-rerun' is ignored when uploading additional tests.\"\n            )\n\n        if not self.data.suite_per_plan and self.data.launch_rerun:\n            self.warn(\n                \"Unexpected option combination: '--launch-rerun' \"\n                \"may cause an unexpected behaviour with launch-per-plan structure\"\n            )\n\n    @property\n    def datetime(self) -&gt; str:\n        # Use the same format of timestramp as tmt does\n        return format_timestamp(datetime.datetime.now(datetime.timezone.utc))\n\n    @property\n    def headers(self) -&gt; dict[str, str]:\n        return {\n            \"Authorization\": f\"Bearer {self.data.token}\",\n            \"Accept\": \"*/*\",\n            \"Content-Type\": \"application/json\",\n        }\n\n    @property\n    def url(self) -&gt; str:\n        return f\"{self.data.url}/api/{self.data.api_version}/{self.data.project}\"\n\n    def construct_launch_attributes(\n        self, suite_per_plan: bool, attributes: list[dict[str, str]]\n    ) -&gt; list[dict[str, str]]:\n        if not suite_per_plan or not self.step.plan.my_run:\n            return attributes.copy()\n\n        # Get common attributes across the plans\n        merged_plans = [\n            {key: value[0] for key, value in plan._fmf_context.items()}\n            for plan in self.step.plan.my_run.plans\n        ]\n        result_dict = merged_plans[0]\n        for current_plan in merged_plans[1:]:\n            tmp_dict = {\n                key: value\n                for key, value in current_plan.items()\n                if key in result_dict and result_dict[key] == value\n            }\n            result_dict = tmp_dict\n        return [{'key': key, 'value': value} for key, value in result_dict.items()]\n\n    def get_defect_type_locator(\n        self, session: requests.Session, defect_type: Optional[str]\n    ) -&gt; str:\n        if not defect_type:\n            return \"ti001\"\n\n        response = self.rp_api_get(session, \"settings\")\n        defect_types = yaml_to_dict(response.text).get(\"subTypes\")\n        if not defect_types:\n            return \"ti001\"\n\n        groups_to_search = [\n            'TO_INVESTIGATE',\n            'NO_DEFECT',\n            'SYSTEM_ISSUE',\n            'AUTOMATION_BUG',\n            'PRODUCT_BUG',\n        ]\n        for group_name in groups_to_search:\n            defect_types_list = defect_types[group_name]\n            dt_tmp = [\n                dt['locator']\n                for dt in defect_types_list\n                if dt['longName'].lower() == defect_type.lower()\n            ]\n            dt_locator = dt_tmp[0] if dt_tmp else None\n            if dt_locator:\n                break\n        if not dt_locator:\n            raise tmt.utils.ReportError(\n                f\"Defect type '{defect_type}' \"\n                \"is not be defined in the project {self.data.project}\"\n            )\n        self.verbose(\"defect_type\", defect_type, color=\"cyan\", shift=1)\n        return str(dt_locator)\n\n    def rp_api_get(self, session: requests.Session, path: str) -&gt; requests.Response:\n        response = session.get(url=f\"{self.url}/{path}\", headers=self.headers)\n        self.handle_response(response)\n        return response\n\n    def rp_api_post(self, session: requests.Session, path: str, json: JSON) -&gt; requests.Response:\n        response = session.post(url=f\"{self.url}/{path}\", headers=self.headers, json=json)\n        self.handle_response(response)\n        return response\n\n    def rp_api_put(self, session: requests.Session, path: str, json: JSON) -&gt; requests.Response:\n        response = session.put(url=f\"{self.url}/{path}\", headers=self.headers, json=json)\n        self.handle_response(response)\n        return response\n\n    def append_description(self, curr_description: str) -&gt; str:\n        \"\"\"\n        Extend text with the launch description (if provided)\n        \"\"\"\n\n        if self.data.launch_description:\n            if curr_description:\n                curr_description += \"&lt;br&gt;\" + self.data.launch_description\n            else:\n                curr_description = self.data.launch_description\n        return curr_description\n\n    def append_link_template(\n        self,\n        description: str,\n        link_template: str,\n        result: tmt.result.Result,\n    ) -&gt; str:\n        \"\"\"\n        Extend text with rendered link template\n        \"\"\"\n\n        url = tmt.utils.templates.render_template(\n            link_template,\n            PLAN_NAME=self.step.plan.pathless_safe_name,\n            RESULT=result,\n        )\n        return f'{description}&lt;br&gt;{url}' if description else url\n\n    def upload_result_logs(\n        self,\n        result: Union[tmt.result.Result, tmt.result.SubResult],\n        session: requests.Session,\n        item_uuid: str,\n        launch_uuid: str,\n        timestamp: str,\n        write_out_failures: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Upload all result log files into the ReportPortal instance\n        \"\"\"\n\n        def upload_log(log_path: Path, is_yaml: bool = False, is_traceback: bool = False) -&gt; None:\n            try:\n                if is_yaml:\n                    logs = tmt.utils.yaml_to_list(self.step.plan.execute.read(log_path))\n                else:\n                    logs = [self.step.plan.execute.read(log_path)]\n            except (tmt.utils.FileError, tmt.utils.GeneralError) as error:\n                tmt.utils.show_exception_as_warning(\n                    exception=error,\n                    message=f\"Failed to read log file '{log_path}' for ReportPortal upload.\",\n                    logger=self._logger,\n                )\n                return\n\n            filter_settings = LogFilterSettings(\n                size=self.data.traceback_size_limit if is_traceback else self.data.log_size_limit,\n                is_traceback=is_traceback,\n            )\n\n            for log in logs:\n                # Add file name to the log if it is not a traceback\n                if not is_traceback:\n                    log = f'### `{log_path.name}`\\n{log}'\n                # Upload log\n                self.rp_api_post(\n                    session=session,\n                    path=\"log/entry\",\n                    json={\n                        \"message\": _filter_log(log, filter_settings),\n                        \"itemUuid\": item_uuid,\n                        \"launchUuid\": launch_uuid,\n                        \"level\": \"ERROR\" if is_traceback else \"INFO\",\n                        \"time\": timestamp,\n                    },\n                )\n\n        # Upload result logs\n        for log_path in result.log:\n            if any(pattern.search(log_path.name) for pattern in self.data.upload_log_pattern):\n                upload_log(log_path)\n\n        # Upload check result logs if the check failed\n        for check in result.check:\n            if check.result not in (ResultOutcome.FAIL, ResultOutcome.ERROR):\n                continue\n            for log_path in check.log:\n                if any(pattern.search(log_path.name) for pattern in self.data.upload_log_pattern):\n                    upload_log(log_path, is_traceback=True)\n\n        # Upload failure logs\n        if write_out_failures:\n            for failure_log in result.failure_logs:\n                upload_log(failure_log, is_yaml=True, is_traceback=True)\n\n    def execute_rp_import(self) -&gt; None:\n        \"\"\"\n        Execute the import of test, results and subresults into ReportPortal\n        \"\"\"\n\n        assert self.step.plan.my_run is not None\n        # Use the current datetime as a default, but this is the worst case scenario\n        # and we should use timestamps from results log as much as possible.\n        launch_start_time = self.datetime\n\n        # Support for idle tests\n        executed = bool(self.step.plan.execute.results())\n        if executed:\n            # Launch time should be the earliest start time of all plans.\n            #\n            # The datetime *strings* are in fact sorted here, but finding the minimum will work,\n            # because the datetime in ISO format is designed to be lexicographically sortable.\n            launch_start_time = min(\n                r.start_time or self.datetime for r in self.step.plan.execute.results()\n            )\n\n        # Create launch, suites (if \"--suite_per_plan\") and tests;\n        # or report to existing launch/suite if its id is given\n        suite_per_plan = self.data.suite_per_plan\n        launch_per_plan = self.data.launch_per_plan\n        if not launch_per_plan and not suite_per_plan:\n            launch_per_plan = True  # by default\n\n        suite_id = self.data.upload_to_suite\n        launch_id = self.data.upload_to_launch\n\n        suite_uuid = self.data.suite_uuid\n        launch_uuid = self.data.launch_uuid\n        additional_upload = suite_id or launch_id or launch_uuid\n        is_the_first_plan = self.step.plan == self.step.plan.my_run.plans[0]\n        if not launch_uuid and suite_per_plan and not is_the_first_plan:\n            rp_phases = list(self.step.plan.my_run.plans[0].report.phases(ReportReportPortal))\n            if rp_phases:\n                launch_uuid = rp_phases[0].data.launch_uuid\n\n        create_test = not self.data.test_uuids\n        create_suite = suite_per_plan and not (suite_uuid or suite_id)\n        create_launch = not (launch_uuid or launch_id or suite_uuid or suite_id)\n\n        launch_name = self.data.launch or self.step.plan.name\n        suite_name = \"\"\n        launch_url = \"\"\n\n        launch_rerun = self.data.launch_rerun\n        envar_pattern = self.data.exclude_variables or \"$^\"\n        defect_type = self.data.defect_type or \"\"\n\n        attributes = [\n            {'key': key, 'value': value[0]} for key, value in self.step.plan._fmf_context.items()\n        ]\n        launch_attributes = self.construct_launch_attributes(suite_per_plan, attributes)\n\n        if suite_per_plan:\n            launch_description = self.data.launch_description or \"\"\n            suite_description = self.append_description(self.step.plan.summary or \"\")\n        else:\n            launch_description = self.step.plan.summary or \"\"\n            launch_description = self.append_description(launch_description)\n            suite_description = \"\"\n\n        # Check whether artifacts URL has been provided\n        if self.data.artifacts_url:\n            launch_description += f\"&lt;br&gt;{self.data.artifacts_url}\"\n            suite_description += f\"&lt;br&gt;{self.data.artifacts_url}\"\n\n        # Communication with RP instance\n        with tmt.utils.retry_session(\n            status_forcelist=(\n                429,  # Too Many Requests\n                500,  # Internal Server Error\n                502,  # Bad Gateway\n                503,  # Service Unavailable\n                504,  # Gateway Timeout\n            )\n        ) as session:\n            session.verify = self.data.ssl_verify\n\n            if create_launch:\n                # Create a launch\n                self.info(\"launch\", launch_name, color=\"cyan\")\n                response = self.rp_api_post(\n                    session=session,\n                    path=\"launch\",\n                    json={\n                        \"name\": launch_name,\n                        \"description\": launch_description,\n                        \"attributes\": launch_attributes,\n                        \"startTime\": launch_start_time,\n                        \"rerun\": launch_rerun,\n                    },\n                )\n                launch_uuid = yaml_to_dict(response.text).get(\"id\")\n\n            else:\n                # Get the launch_uuid or info to log\n                if suite_id:\n                    response = self.rp_api_get(session, f\"item/{suite_id}\")\n                    suite_uuid = yaml_to_dict(response.text).get(\"uuid\")\n                    suite_name = str(yaml_to_dict(response.text).get(\"name\"))\n                    launch_id = yaml_to_dict(response.text).get(\"launchId\")\n\n                if launch_id:\n                    response = self.rp_api_get(session, f\"launch/{launch_id}\")\n                    launch_uuid = yaml_to_dict(response.text).get(\"uuid\")\n\n            if launch_uuid and not launch_id:\n                response = self.rp_api_get(session, f\"launch/uuid/{launch_uuid}\")\n                launch_id = yaml_to_dict(response.text).get(\"id\")\n\n            # Print the launch info\n            if not create_launch:\n                launch_name = yaml_to_dict(response.text).get(\"name\") or \"\"\n                self.verbose(\"launch\", launch_name, color=\"green\")\n                self.verbose(\"id\", launch_id, \"yellow\", shift=1)\n\n            assert launch_uuid is not None\n            self.verbose(\"uuid\", launch_uuid, \"yellow\", shift=1)\n            self.data.launch_uuid = launch_uuid\n\n            launch_url = f\"{self.data.url}/ui/#{self.data.project}/launches/all/{launch_id}\"\n\n            if create_suite:\n                # Create a suite\n                suite_name = self.step.plan.name\n                self.info(\"suite\", suite_name, color=\"cyan\")\n                response = self.rp_api_post(\n                    session=session,\n                    path=\"item\",\n                    json={\n                        \"name\": suite_name,\n                        \"description\": suite_description,\n                        \"attributes\": attributes,\n                        \"startTime\": launch_start_time,\n                        \"launchUuid\": launch_uuid,\n                        \"type\": \"suite\",\n                    },\n                )\n                suite_uuid = yaml_to_dict(response.text).get(\"id\")\n                assert suite_uuid is not None\n\n            elif suite_name:\n                self.info(\"suite\", suite_name, color=\"green\")\n                self.verbose(\"id\", suite_id, \"yellow\", shift=1)\n\n            if suite_uuid:\n                self.verbose(\"uuid\", suite_uuid, \"yellow\", shift=1)\n                self.data.suite_uuid = suite_uuid\n\n            # The first test starts with the launch (at the worst case)\n            test_start_time = launch_start_time\n\n            for result, test_origin in self.step.plan.execute.results_for_tests(\n                self.step.plan.discover.tests()\n            ):\n                test = test_origin.test if test_origin else None\n\n                test_name = None\n                test_description = ''\n                test_link = None\n                test_id = None\n                env_vars = None\n\n                item_attributes = attributes.copy()\n                if result:\n                    serial_number = result.serial_number\n                    test_name = result.name\n\n                    # Use the actual timestamp or reuse the old one if missing\n                    test_start_time = result.start_time or test_start_time\n\n                    # for guests, save their primary address\n                    if result.guest.primary_address:\n                        item_attributes.append(\n                            {'key': 'guest_primary_address', 'value': result.guest.primary_address}\n                        )\n                    # for multi-host tests store also provision name and role\n                    if result.guest.name != 'default-0':\n                        item_attributes.append({'key': 'guest_name', 'value': result.guest.name})\n                    if result.guest.role:\n                        item_attributes.append({'key': 'guest_role', 'value': result.guest.role})\n\n                # update RP item with additional attributes if test details are available\n                if test:\n                    serial_number = test.serial_number\n                    if not test_name:\n                        test_name = test.name\n                    if test.author:\n                        item_attributes += [\n                            {'key': 'author', 'value': author} for author in test.author\n                        ]\n                    if test.contact:\n                        item_attributes += [\n                            {'key': 'contact', 'value': contact} for contact in test.contact\n                        ]\n                    if test.summary:\n                        test_description = test.summary\n                    if test.web_link():\n                        test_link = test.web_link()\n                    if test.id:\n                        test_id = test.id\n\n                    env_vars = [\n                        {'key': key, 'value': value}\n                        for key, value in test.environment.items()\n                        if not re.search(envar_pattern, key)\n                    ]\n\n                if create_test:\n                    if (\n                        self.data.upload_to_launch and launch_per_plan\n                    ) or self.data.upload_to_suite:\n                        test_description = self.append_description(test_description)\n\n                    if result and self.data.link_template:\n                        test_description = self.append_link_template(\n                            test_description,\n                            self.data.link_template,\n                            result,\n                        )\n\n                    # Create a test item\n                    self.info(\"test\", test_name, color=\"cyan\")\n                    response = self.rp_api_post(\n                        session=session,\n                        path=f\"item{f'/{suite_uuid}' if suite_uuid else ''}\",\n                        json={\n                            \"name\": test_name,\n                            \"description\": test_description,\n                            \"attributes\": item_attributes,\n                            \"parameters\": env_vars,\n                            \"codeRef\": test_link,\n                            \"launchUuid\": launch_uuid,\n                            \"type\": \"step\",\n                            \"testCaseId\": test_id,\n                            \"startTime\": test_start_time,\n                        },\n                    )\n\n                    item_uuid = yaml_to_dict(response.text).get(\"id\")\n                    assert item_uuid is not None\n                    self.verbose(\"uuid\", item_uuid, \"yellow\", shift=1)\n                    self.data.test_uuids[serial_number] = item_uuid\n                else:\n                    item_uuid = self.data.test_uuids[serial_number]\n\n                # If the result end-time is not defined, use the latest result start-time as\n                # default.\n                test_end_time = test_start_time\n\n                # Support for idle tests\n                item_status = \"SKIPPED\"\n                if result:\n                    # Shift the timestamp to the end of a test.\n                    test_end_time = result.end_time or test_end_time\n\n                    item_status = self.TMT_TO_RP_RESULT_STATUS[result.result]\n\n                    self.upload_result_logs(\n                        result=result,\n                        session=session,\n                        item_uuid=item_uuid,\n                        launch_uuid=launch_uuid,\n                        timestamp=test_end_time,\n                        write_out_failures=bool(item_status == \"FAILED\"),\n                    )\n\n                    # If upload of subresults is required, create (and *finish*) the child test\n                    # item for every tmt subresult and map it under the parent test item.\n                    if self.data.upload_subresults:\n                        for subresult in result.subresult:\n                            # Create a child item\n                            self.info(\"sub-test\", subresult.name, color=\"cyan\", shift=1)\n\n                            # Use the parent test start-time as a default\n                            subresult_start_time = subresult.start_time or test_start_time\n\n                            response = self.rp_api_post(\n                                session=session,\n                                path=f\"item/{item_uuid}\",\n                                json={\n                                    \"name\": subresult.name,\n                                    \"launchUuid\": launch_uuid,\n                                    \"type\": \"step\",\n                                    \"startTime\": subresult_start_time,\n                                },\n                            )\n\n                            child_item_uuid = yaml_to_dict(response.text).get(\"id\")\n                            assert child_item_uuid is not None\n\n                            child_item_status = self.TMT_TO_RP_RESULT_STATUS[subresult.result]\n                            subtest_end_time = subresult.end_time or test_end_time\n\n                            # Upload the subtest (child) logs\n                            self.upload_result_logs(\n                                result=subresult,\n                                session=session,\n                                item_uuid=child_item_uuid,\n                                launch_uuid=launch_uuid,\n                                timestamp=subtest_end_time,\n                                write_out_failures=bool(child_item_status == \"FAILED\"),\n                            )\n\n                            # Finish the child item\n                            response = self.rp_api_put(\n                                session=session,\n                                path=f\"item/{child_item_uuid}\",\n                                json={\n                                    \"launchUuid\": launch_uuid,\n                                    \"status\": child_item_status,\n                                    \"endTime\": subtest_end_time,\n                                },\n                            )\n\n                            self.verbose(\"uuid\", child_item_uuid, \"yellow\", shift=2)\n\n                # Finish the parent test item\n                response = self.rp_api_put(\n                    session=session,\n                    path=f\"item/{item_uuid}\",\n                    json={\n                        \"launchUuid\": launch_uuid,\n                        \"endTime\": test_end_time,\n                        \"status\": item_status,\n                        \"issue\": {\"issueType\": self.get_defect_type_locator(session, defect_type)},\n                    },\n                )\n\n                # The launch ends with the last test\n                launch_end_time = test_end_time\n\n            if create_suite:\n                # Finish the test suite\n                response = self.rp_api_put(\n                    session=session,\n                    path=f\"item{f'/{suite_uuid}' if suite_uuid else ''}\",\n                    json={\"launchUuid\": launch_uuid, \"endTime\": launch_end_time},\n                )\n\n            is_the_last_plan = self.step.plan == self.step.plan.my_run.plans[-1]\n            if is_the_last_plan:\n                self.data.defect_type = None\n\n            if (\n                launch_per_plan or (suite_per_plan and is_the_last_plan)\n            ) and not additional_upload:\n                # Finish the launch\n                response = self.rp_api_put(\n                    session=session,\n                    path=f\"launch/{launch_uuid}/finish\",\n                    json={\"endTime\": launch_end_time},\n                )\n                launch_url = str(yaml_to_dict(response.text).get(\"link\"))\n\n            assert launch_url is not None\n            self.info(\"url\", launch_url, \"magenta\")\n            self.data.launch_url = launch_url\n\n    def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n        \"\"\"\n        Report test results to the endpoint\n\n        Create a ReportPortal launch and its test items,\n        fill it with all parts needed and report the logs.\n        \"\"\"\n\n        super().go(logger=logger)\n\n        if not self.data.url:\n            raise tmt.utils.ReportError(\"No ReportPortal endpoint url provided.\")\n        self.data.url = self.data.url.rstrip(\"/\")\n\n        if not self.data.project:\n            raise tmt.utils.ReportError(\"No ReportPortal project provided.\")\n\n        if not self.data.token:\n            raise tmt.utils.ReportError(\"No ReportPortal token provided.\")\n\n        if not self.step.plan.my_run:\n            raise tmt.utils.ReportError(\"No run data available.\")\n\n        self.check_options()\n\n        # If SSL verification is disabled, do not print warnings with urllib3\n        warning_filter_action: ActionType = 'default'\n        if not self.data.ssl_verify:\n            warning_filter_action = 'ignore'\n            self.warn(\n                \"SSL verification is disabled for all requests being made to ReportPortal \"\n                f\"instance ({self.data.url}).\"\n            )\n\n        with catch_warnings_safe(\n            action=warning_filter_action, category=urllib3.exceptions.InsecureRequestWarning\n        ):\n            self.execute_rp_import()\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.append_description","title":"<code>append_description(curr_description)</code>","text":"<p>Extend text with the launch description (if provided)</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def append_description(self, curr_description: str) -&gt; str:\n    \"\"\"\n    Extend text with the launch description (if provided)\n    \"\"\"\n\n    if self.data.launch_description:\n        if curr_description:\n            curr_description += \"&lt;br&gt;\" + self.data.launch_description\n        else:\n            curr_description = self.data.launch_description\n    return curr_description\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.append_link_template","title":"<code>append_link_template(description, link_template, result)</code>","text":"<p>Extend text with rendered link template</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def append_link_template(\n    self,\n    description: str,\n    link_template: str,\n    result: tmt.result.Result,\n) -&gt; str:\n    \"\"\"\n    Extend text with rendered link template\n    \"\"\"\n\n    url = tmt.utils.templates.render_template(\n        link_template,\n        PLAN_NAME=self.step.plan.pathless_safe_name,\n        RESULT=result,\n    )\n    return f'{description}&lt;br&gt;{url}' if description else url\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.check_options","title":"<code>check_options()</code>","text":"<p>Check options for known troublesome combinations</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def check_options(self) -&gt; None:\n    \"\"\"\n    Check options for known troublesome combinations\n    \"\"\"\n\n    if self.data.launch_per_plan and self.data.suite_per_plan:\n        self.warn(\n            \"The options '--launch-per-plan' and '--suite-per-plan' are mutually exclusive. \"\n            \"Default option '--launch-per-plan' is used.\"\n        )\n        self.data.suite_per_plan = False\n\n    if self.data.launch_rerun and (self.data.upload_to_launch or self.data.upload_to_suite):\n        self.warn(\n            \"Unexpected option combination: \"\n            \"'--launch-rerun' is ignored when uploading additional tests.\"\n        )\n\n    if not self.data.suite_per_plan and self.data.launch_rerun:\n        self.warn(\n            \"Unexpected option combination: '--launch-rerun' \"\n            \"may cause an unexpected behaviour with launch-per-plan structure\"\n        )\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.execute_rp_import","title":"<code>execute_rp_import()</code>","text":"<p>Execute the import of test, results and subresults into ReportPortal</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def execute_rp_import(self) -&gt; None:\n    \"\"\"\n    Execute the import of test, results and subresults into ReportPortal\n    \"\"\"\n\n    assert self.step.plan.my_run is not None\n    # Use the current datetime as a default, but this is the worst case scenario\n    # and we should use timestamps from results log as much as possible.\n    launch_start_time = self.datetime\n\n    # Support for idle tests\n    executed = bool(self.step.plan.execute.results())\n    if executed:\n        # Launch time should be the earliest start time of all plans.\n        #\n        # The datetime *strings* are in fact sorted here, but finding the minimum will work,\n        # because the datetime in ISO format is designed to be lexicographically sortable.\n        launch_start_time = min(\n            r.start_time or self.datetime for r in self.step.plan.execute.results()\n        )\n\n    # Create launch, suites (if \"--suite_per_plan\") and tests;\n    # or report to existing launch/suite if its id is given\n    suite_per_plan = self.data.suite_per_plan\n    launch_per_plan = self.data.launch_per_plan\n    if not launch_per_plan and not suite_per_plan:\n        launch_per_plan = True  # by default\n\n    suite_id = self.data.upload_to_suite\n    launch_id = self.data.upload_to_launch\n\n    suite_uuid = self.data.suite_uuid\n    launch_uuid = self.data.launch_uuid\n    additional_upload = suite_id or launch_id or launch_uuid\n    is_the_first_plan = self.step.plan == self.step.plan.my_run.plans[0]\n    if not launch_uuid and suite_per_plan and not is_the_first_plan:\n        rp_phases = list(self.step.plan.my_run.plans[0].report.phases(ReportReportPortal))\n        if rp_phases:\n            launch_uuid = rp_phases[0].data.launch_uuid\n\n    create_test = not self.data.test_uuids\n    create_suite = suite_per_plan and not (suite_uuid or suite_id)\n    create_launch = not (launch_uuid or launch_id or suite_uuid or suite_id)\n\n    launch_name = self.data.launch or self.step.plan.name\n    suite_name = \"\"\n    launch_url = \"\"\n\n    launch_rerun = self.data.launch_rerun\n    envar_pattern = self.data.exclude_variables or \"$^\"\n    defect_type = self.data.defect_type or \"\"\n\n    attributes = [\n        {'key': key, 'value': value[0]} for key, value in self.step.plan._fmf_context.items()\n    ]\n    launch_attributes = self.construct_launch_attributes(suite_per_plan, attributes)\n\n    if suite_per_plan:\n        launch_description = self.data.launch_description or \"\"\n        suite_description = self.append_description(self.step.plan.summary or \"\")\n    else:\n        launch_description = self.step.plan.summary or \"\"\n        launch_description = self.append_description(launch_description)\n        suite_description = \"\"\n\n    # Check whether artifacts URL has been provided\n    if self.data.artifacts_url:\n        launch_description += f\"&lt;br&gt;{self.data.artifacts_url}\"\n        suite_description += f\"&lt;br&gt;{self.data.artifacts_url}\"\n\n    # Communication with RP instance\n    with tmt.utils.retry_session(\n        status_forcelist=(\n            429,  # Too Many Requests\n            500,  # Internal Server Error\n            502,  # Bad Gateway\n            503,  # Service Unavailable\n            504,  # Gateway Timeout\n        )\n    ) as session:\n        session.verify = self.data.ssl_verify\n\n        if create_launch:\n            # Create a launch\n            self.info(\"launch\", launch_name, color=\"cyan\")\n            response = self.rp_api_post(\n                session=session,\n                path=\"launch\",\n                json={\n                    \"name\": launch_name,\n                    \"description\": launch_description,\n                    \"attributes\": launch_attributes,\n                    \"startTime\": launch_start_time,\n                    \"rerun\": launch_rerun,\n                },\n            )\n            launch_uuid = yaml_to_dict(response.text).get(\"id\")\n\n        else:\n            # Get the launch_uuid or info to log\n            if suite_id:\n                response = self.rp_api_get(session, f\"item/{suite_id}\")\n                suite_uuid = yaml_to_dict(response.text).get(\"uuid\")\n                suite_name = str(yaml_to_dict(response.text).get(\"name\"))\n                launch_id = yaml_to_dict(response.text).get(\"launchId\")\n\n            if launch_id:\n                response = self.rp_api_get(session, f\"launch/{launch_id}\")\n                launch_uuid = yaml_to_dict(response.text).get(\"uuid\")\n\n        if launch_uuid and not launch_id:\n            response = self.rp_api_get(session, f\"launch/uuid/{launch_uuid}\")\n            launch_id = yaml_to_dict(response.text).get(\"id\")\n\n        # Print the launch info\n        if not create_launch:\n            launch_name = yaml_to_dict(response.text).get(\"name\") or \"\"\n            self.verbose(\"launch\", launch_name, color=\"green\")\n            self.verbose(\"id\", launch_id, \"yellow\", shift=1)\n\n        assert launch_uuid is not None\n        self.verbose(\"uuid\", launch_uuid, \"yellow\", shift=1)\n        self.data.launch_uuid = launch_uuid\n\n        launch_url = f\"{self.data.url}/ui/#{self.data.project}/launches/all/{launch_id}\"\n\n        if create_suite:\n            # Create a suite\n            suite_name = self.step.plan.name\n            self.info(\"suite\", suite_name, color=\"cyan\")\n            response = self.rp_api_post(\n                session=session,\n                path=\"item\",\n                json={\n                    \"name\": suite_name,\n                    \"description\": suite_description,\n                    \"attributes\": attributes,\n                    \"startTime\": launch_start_time,\n                    \"launchUuid\": launch_uuid,\n                    \"type\": \"suite\",\n                },\n            )\n            suite_uuid = yaml_to_dict(response.text).get(\"id\")\n            assert suite_uuid is not None\n\n        elif suite_name:\n            self.info(\"suite\", suite_name, color=\"green\")\n            self.verbose(\"id\", suite_id, \"yellow\", shift=1)\n\n        if suite_uuid:\n            self.verbose(\"uuid\", suite_uuid, \"yellow\", shift=1)\n            self.data.suite_uuid = suite_uuid\n\n        # The first test starts with the launch (at the worst case)\n        test_start_time = launch_start_time\n\n        for result, test_origin in self.step.plan.execute.results_for_tests(\n            self.step.plan.discover.tests()\n        ):\n            test = test_origin.test if test_origin else None\n\n            test_name = None\n            test_description = ''\n            test_link = None\n            test_id = None\n            env_vars = None\n\n            item_attributes = attributes.copy()\n            if result:\n                serial_number = result.serial_number\n                test_name = result.name\n\n                # Use the actual timestamp or reuse the old one if missing\n                test_start_time = result.start_time or test_start_time\n\n                # for guests, save their primary address\n                if result.guest.primary_address:\n                    item_attributes.append(\n                        {'key': 'guest_primary_address', 'value': result.guest.primary_address}\n                    )\n                # for multi-host tests store also provision name and role\n                if result.guest.name != 'default-0':\n                    item_attributes.append({'key': 'guest_name', 'value': result.guest.name})\n                if result.guest.role:\n                    item_attributes.append({'key': 'guest_role', 'value': result.guest.role})\n\n            # update RP item with additional attributes if test details are available\n            if test:\n                serial_number = test.serial_number\n                if not test_name:\n                    test_name = test.name\n                if test.author:\n                    item_attributes += [\n                        {'key': 'author', 'value': author} for author in test.author\n                    ]\n                if test.contact:\n                    item_attributes += [\n                        {'key': 'contact', 'value': contact} for contact in test.contact\n                    ]\n                if test.summary:\n                    test_description = test.summary\n                if test.web_link():\n                    test_link = test.web_link()\n                if test.id:\n                    test_id = test.id\n\n                env_vars = [\n                    {'key': key, 'value': value}\n                    for key, value in test.environment.items()\n                    if not re.search(envar_pattern, key)\n                ]\n\n            if create_test:\n                if (\n                    self.data.upload_to_launch and launch_per_plan\n                ) or self.data.upload_to_suite:\n                    test_description = self.append_description(test_description)\n\n                if result and self.data.link_template:\n                    test_description = self.append_link_template(\n                        test_description,\n                        self.data.link_template,\n                        result,\n                    )\n\n                # Create a test item\n                self.info(\"test\", test_name, color=\"cyan\")\n                response = self.rp_api_post(\n                    session=session,\n                    path=f\"item{f'/{suite_uuid}' if suite_uuid else ''}\",\n                    json={\n                        \"name\": test_name,\n                        \"description\": test_description,\n                        \"attributes\": item_attributes,\n                        \"parameters\": env_vars,\n                        \"codeRef\": test_link,\n                        \"launchUuid\": launch_uuid,\n                        \"type\": \"step\",\n                        \"testCaseId\": test_id,\n                        \"startTime\": test_start_time,\n                    },\n                )\n\n                item_uuid = yaml_to_dict(response.text).get(\"id\")\n                assert item_uuid is not None\n                self.verbose(\"uuid\", item_uuid, \"yellow\", shift=1)\n                self.data.test_uuids[serial_number] = item_uuid\n            else:\n                item_uuid = self.data.test_uuids[serial_number]\n\n            # If the result end-time is not defined, use the latest result start-time as\n            # default.\n            test_end_time = test_start_time\n\n            # Support for idle tests\n            item_status = \"SKIPPED\"\n            if result:\n                # Shift the timestamp to the end of a test.\n                test_end_time = result.end_time or test_end_time\n\n                item_status = self.TMT_TO_RP_RESULT_STATUS[result.result]\n\n                self.upload_result_logs(\n                    result=result,\n                    session=session,\n                    item_uuid=item_uuid,\n                    launch_uuid=launch_uuid,\n                    timestamp=test_end_time,\n                    write_out_failures=bool(item_status == \"FAILED\"),\n                )\n\n                # If upload of subresults is required, create (and *finish*) the child test\n                # item for every tmt subresult and map it under the parent test item.\n                if self.data.upload_subresults:\n                    for subresult in result.subresult:\n                        # Create a child item\n                        self.info(\"sub-test\", subresult.name, color=\"cyan\", shift=1)\n\n                        # Use the parent test start-time as a default\n                        subresult_start_time = subresult.start_time or test_start_time\n\n                        response = self.rp_api_post(\n                            session=session,\n                            path=f\"item/{item_uuid}\",\n                            json={\n                                \"name\": subresult.name,\n                                \"launchUuid\": launch_uuid,\n                                \"type\": \"step\",\n                                \"startTime\": subresult_start_time,\n                            },\n                        )\n\n                        child_item_uuid = yaml_to_dict(response.text).get(\"id\")\n                        assert child_item_uuid is not None\n\n                        child_item_status = self.TMT_TO_RP_RESULT_STATUS[subresult.result]\n                        subtest_end_time = subresult.end_time or test_end_time\n\n                        # Upload the subtest (child) logs\n                        self.upload_result_logs(\n                            result=subresult,\n                            session=session,\n                            item_uuid=child_item_uuid,\n                            launch_uuid=launch_uuid,\n                            timestamp=subtest_end_time,\n                            write_out_failures=bool(child_item_status == \"FAILED\"),\n                        )\n\n                        # Finish the child item\n                        response = self.rp_api_put(\n                            session=session,\n                            path=f\"item/{child_item_uuid}\",\n                            json={\n                                \"launchUuid\": launch_uuid,\n                                \"status\": child_item_status,\n                                \"endTime\": subtest_end_time,\n                            },\n                        )\n\n                        self.verbose(\"uuid\", child_item_uuid, \"yellow\", shift=2)\n\n            # Finish the parent test item\n            response = self.rp_api_put(\n                session=session,\n                path=f\"item/{item_uuid}\",\n                json={\n                    \"launchUuid\": launch_uuid,\n                    \"endTime\": test_end_time,\n                    \"status\": item_status,\n                    \"issue\": {\"issueType\": self.get_defect_type_locator(session, defect_type)},\n                },\n            )\n\n            # The launch ends with the last test\n            launch_end_time = test_end_time\n\n        if create_suite:\n            # Finish the test suite\n            response = self.rp_api_put(\n                session=session,\n                path=f\"item{f'/{suite_uuid}' if suite_uuid else ''}\",\n                json={\"launchUuid\": launch_uuid, \"endTime\": launch_end_time},\n            )\n\n        is_the_last_plan = self.step.plan == self.step.plan.my_run.plans[-1]\n        if is_the_last_plan:\n            self.data.defect_type = None\n\n        if (\n            launch_per_plan or (suite_per_plan and is_the_last_plan)\n        ) and not additional_upload:\n            # Finish the launch\n            response = self.rp_api_put(\n                session=session,\n                path=f\"launch/{launch_uuid}/finish\",\n                json={\"endTime\": launch_end_time},\n            )\n            launch_url = str(yaml_to_dict(response.text).get(\"link\"))\n\n        assert launch_url is not None\n        self.info(\"url\", launch_url, \"magenta\")\n        self.data.launch_url = launch_url\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.go","title":"<code>go(*, logger=None)</code>","text":"<p>Report test results to the endpoint</p> <p>Create a ReportPortal launch and its test items, fill it with all parts needed and report the logs.</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def go(self, *, logger: Optional[tmt.log.Logger] = None) -&gt; None:\n    \"\"\"\n    Report test results to the endpoint\n\n    Create a ReportPortal launch and its test items,\n    fill it with all parts needed and report the logs.\n    \"\"\"\n\n    super().go(logger=logger)\n\n    if not self.data.url:\n        raise tmt.utils.ReportError(\"No ReportPortal endpoint url provided.\")\n    self.data.url = self.data.url.rstrip(\"/\")\n\n    if not self.data.project:\n        raise tmt.utils.ReportError(\"No ReportPortal project provided.\")\n\n    if not self.data.token:\n        raise tmt.utils.ReportError(\"No ReportPortal token provided.\")\n\n    if not self.step.plan.my_run:\n        raise tmt.utils.ReportError(\"No run data available.\")\n\n    self.check_options()\n\n    # If SSL verification is disabled, do not print warnings with urllib3\n    warning_filter_action: ActionType = 'default'\n    if not self.data.ssl_verify:\n        warning_filter_action = 'ignore'\n        self.warn(\n            \"SSL verification is disabled for all requests being made to ReportPortal \"\n            f\"instance ({self.data.url}).\"\n        )\n\n    with catch_warnings_safe(\n        action=warning_filter_action, category=urllib3.exceptions.InsecureRequestWarning\n    ):\n        self.execute_rp_import()\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.handle_response","title":"<code>handle_response(response)</code>","text":"<p>Check the endpoint response and raise an exception if needed</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def handle_response(self, response: requests.Response) -&gt; None:\n    \"\"\"\n    Check the endpoint response and raise an exception if needed\n    \"\"\"\n\n    self.debug(\"Response code from the endpoint\", response.status_code)\n    self.debug(\"Message from the endpoint\", response.text)\n\n    if not response.ok:\n        raise tmt.utils.ReportError(\n            f\"Received non-ok status code {response.status_code} \"\n            f\"from ReportPortal: {response.text}\"\n        )\n</code></pre>"},{"location":"plugins/report/#tmt.steps.report.reportportal.ReportReportPortal.upload_result_logs","title":"<code>upload_result_logs(result, session, item_uuid, launch_uuid, timestamp, write_out_failures=True)</code>","text":"<p>Upload all result log files into the ReportPortal instance</p> Source code in <code>tmt/steps/report/reportportal.py</code> <pre><code>def upload_result_logs(\n    self,\n    result: Union[tmt.result.Result, tmt.result.SubResult],\n    session: requests.Session,\n    item_uuid: str,\n    launch_uuid: str,\n    timestamp: str,\n    write_out_failures: bool = True,\n) -&gt; None:\n    \"\"\"\n    Upload all result log files into the ReportPortal instance\n    \"\"\"\n\n    def upload_log(log_path: Path, is_yaml: bool = False, is_traceback: bool = False) -&gt; None:\n        try:\n            if is_yaml:\n                logs = tmt.utils.yaml_to_list(self.step.plan.execute.read(log_path))\n            else:\n                logs = [self.step.plan.execute.read(log_path)]\n        except (tmt.utils.FileError, tmt.utils.GeneralError) as error:\n            tmt.utils.show_exception_as_warning(\n                exception=error,\n                message=f\"Failed to read log file '{log_path}' for ReportPortal upload.\",\n                logger=self._logger,\n            )\n            return\n\n        filter_settings = LogFilterSettings(\n            size=self.data.traceback_size_limit if is_traceback else self.data.log_size_limit,\n            is_traceback=is_traceback,\n        )\n\n        for log in logs:\n            # Add file name to the log if it is not a traceback\n            if not is_traceback:\n                log = f'### `{log_path.name}`\\n{log}'\n            # Upload log\n            self.rp_api_post(\n                session=session,\n                path=\"log/entry\",\n                json={\n                    \"message\": _filter_log(log, filter_settings),\n                    \"itemUuid\": item_uuid,\n                    \"launchUuid\": launch_uuid,\n                    \"level\": \"ERROR\" if is_traceback else \"INFO\",\n                    \"time\": timestamp,\n                },\n            )\n\n    # Upload result logs\n    for log_path in result.log:\n        if any(pattern.search(log_path.name) for pattern in self.data.upload_log_pattern):\n            upload_log(log_path)\n\n    # Upload check result logs if the check failed\n    for check in result.check:\n        if check.result not in (ResultOutcome.FAIL, ResultOutcome.ERROR):\n            continue\n        for log_path in check.log:\n            if any(pattern.search(log_path.name) for pattern in self.data.upload_log_pattern):\n                upload_log(log_path, is_traceback=True)\n\n    # Upload failure logs\n    if write_out_failures:\n        for failure_log in result.failure_logs:\n            upload_log(failure_log, is_yaml=True, is_traceback=True)\n</code></pre>"}]}